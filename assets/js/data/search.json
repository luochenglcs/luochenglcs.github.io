[
  
  {
    "title": "community contribution",
    "url": "/posts/community-contribution/",
    "categories": "Package, community",
    "tags": "community",
    "date": "2024-03-14 06:10:00 +0000",
    





    
    "snippet": "bcc:https://github.com/iovisor/bcc/pull/4935procps-ng:https://gitlab.com/procps-ng/procps/-/merge_requests/222kernel:https://lore.kernel.org/linux-mm/?q=luochunshengnumactl (maintainer):https://git...",
    "content": "bcc:https://github.com/iovisor/bcc/pull/4935procps-ng:https://gitlab.com/procps-ng/procps/-/merge_requests/222kernel:https://lore.kernel.org/linux-mm/?q=luochunshengnumactl (maintainer):https://github.com/numactl/numactl/pulls?q=is%3Apr+author%3Aluochenglcslibhugetlbfs (maintainer):https://github.com/luochenglcs/libhugetlbfs/commits?author=luochenglcs"
  },
  
  {
    "title": "OpenEuler High-performance computing Kernel(HCK)",
    "url": "/posts/OpenEuler-%E6%95%B0%E6%8E%A7%E5%88%86%E7%A6%BBHCK/",
    "categories": "linux, High-performance",
    "tags": "HCK",
    "date": "2023-12-16 00:00:00 +0000",
    





    
    "snippet": "一、HPC场景OpnEuler22.09 白皮书：https://www.openeuler.org/whitepaper/openEuler-whitepaper-2209.pdf  数控分离HCK1&gt;  背景1、HPC介绍reference: https://www.ibm.com/cn-zh/topics/hpchttps://www.oracle.com/cn/cloud/hp...",
    "content": "一、HPC场景OpnEuler22.09 白皮书：https://www.openeuler.org/whitepaper/openEuler-whitepaper-2209.pdf  数控分离HCK1&gt;  背景1、HPC介绍reference: https://www.ibm.com/cn-zh/topics/hpchttps://www.oracle.com/cn/cloud/hpc/what-is-hpc/高性能计算: 并行工作的强大处理器集群，处理海量多维数据集（大数据），并以极高的速度解决复杂问题。  HPC利用的技术： 任务数据分割并行计算 + 集群（超级计算机）  HPC 使用场景: 基因组学 医疗卫生 航空航天 天气预报 气候建模 ….  HPC的基准测试套：HPCG（高性能共轭梯度） HPL(测试高性能计算集群系统浮点性能的基准)2&gt; HPC场景的难点并行计算BSP（Bulk Synchronous Parallel Computing Model）模型： 并发计算  -&gt; 通信 -&gt; 屏障系统噪声对HPC的影响http://www.caep-scns.ac.cn/yanjiuchengguo/1576981548.pdf通常HPC应用开发时，为了满足负载平衡需求，程序设计 人员需尽可能均匀地分割任务，保证每个进程具有相同的计算、通信、访存，从而使得所有 进程均在相同的时刻到达同步点、减少进程之间的相互等待。如下图：左边理想情况， 右边实际情况。由于集群规模变大，系统噪音干扰会导致HPC性能下降。系统噪声定义：系统噪声指的是业务运行中执行的非应用计算任务，包括：系统/用户态守护进程、内核守护进程、内存管理、系统调度开销、业务应用的非计算任务、资源竞争带来的噪声（cache miss, page fault）等。3&gt; 解决方案1、识别系统噪音linux: https://docs.kernel.org/trace/osnoise-tracer.html主要tracer：硬件中断:打断（interference）进程的执行软中断:（softirq）线程调度:被高优先级任务抢占，时间片到但是实际中我们基本已经知晓哪些系统噪声对应用会有影响，实际上我们是直接优化。但是有些RT场景，可以利用这个工具抓。2、消除系统噪音1&gt; intel mOS源码： https://github.com/intel/mOSmOS系统依然会基于Linux扩展而来，目前最新版0.8版使用的是Linux 5.4 LTS内核，但它又有自己的LWK轻量级内核，Linux内核管理少量部分CPU核心，以确保兼容性，LWK内核管理系统其他部分，类似Mutil-OS多OS。内核设计：1、CPU深度隔离-LWKCPU：系统启动后将cmdline指定的cpu进行深度隔离，1&gt; 内核线程迁移（percpu kthread)2&gt; 用户态进程不允许运行3&gt; 中断迁移（tick中断）2、调度: 新增支持RTC（run to complite）调度器，力求实现最简单的调度器3、内存管理LWKMEM:系统启动后将大部分内存从伙伴系统中隔离处理单独管理， 对单独隔离的内存使用新增的分配器。1&gt; mmap、munmap、brk流程走快速流程2&gt; 优先使用大页3&gt; 多级cache， 避免竞争4、SYSFS接口上述内存、CPU隔离资源通过sysfs接口进行申请。 并且提供用户态yod工具进行使用。example：https://github.com/intel/mOS/wiki/mOS-for-HPC-v0.8-Administrator's-Guide1、kernel cmdline: lwkcpu=xxx lwkmem=xxxhttps://github.com/intel/mOS/wiki/mOS-for-HPC-v0.8-Administrator's-Guide2、 yod yod-arguments program program-arguments //yod-argument指定使用什么资源，多少资源2&gt; openEuler HCK基本原理和mOS一致。隔离计算任务和噪声任务：将 HPC 计算任务运行在轻量级内核侧；将系统任务、中断处理、内核线程等运行在 Linux 内核侧， 从而减少系统噪声对 HPC 计算任务的干扰。通过系统调用代理调度，内核单独处理高负载系统调度，保障高负载任务的高效完成，且不影响其他系统服务。但是区别：1、架构支持arm64/x86 ，有部分实现要在arm64实现说起来跟mOS差不多，但是arm64实际实现中遇到很多性能波动问题，尤其在cpu上下线和内存分配这块。"
  },
  
  {
    "title": "OpenEuler Generalized Memory Management(Gmem) For Heterogeneous Device",
    "url": "/posts/openEuler-GMEM/",
    "categories": "linux, gmem",
    "tags": "Gmem",
    "date": "2023-12-15 00:00:00 +0000",
    





    
    "snippet": "openEuler 23.09 白皮书https://www.openeuler.org/whitepaper/openEuler%2023.09%20%E6%8A%80%E6%9C%AF%E7%99%BD%E7%9A%AE%E4%B9%A6.pdf 异构通用内存管理框架（GMEM）特性1&gt; 背景和问题在后摩尔时代，GPU、TPU 和 FPGA 等专用异构加速器设备正不断涌现，它们与 ...",
    "content": "openEuler 23.09 白皮书https://www.openeuler.org/whitepaper/openEuler%2023.09%20%E6%8A%80%E6%9C%AF%E7%99%BD%E7%9A%AE%E4%B9%A6.pdf 异构通用内存管理框架（GMEM）特性1&gt; 背景和问题在后摩尔时代，GPU、TPU 和 FPGA 等专用异构加速器设备正不断涌现，它们与 CPU 类似，需要将数据放在本地内存（例 如 LPDDR 或 HBM）中以提高计算速度。加速器厂商们也不可避免地需要开发复杂的内存管理系统。现行加速器内存管理方案存在诸多缺陷：• CPU 侧内存管理与加速器侧分离，数据显式搬移，加速器内存管理的易用性和性能难以平衡。• 大模型场景下加速器设备 HBM 内存（Hign BandWidth Memory）严重不足，现有的手动 swap 方案性能损耗大且 通用性差。• 搜推、大数据场景存在大量无效数据搬移，缺少高效内存池化方案。HMM设计初衷：设备有大量的板载内存，历来都是专有驱动的API管理，使得驱动程序的内存使用与常规应用内存使用断开，存在分裂。1、大型程序需要依赖大量的库，使得程序维护复杂2、复杂数据，例如：复杂数据集（列表、树……），在驱动与应用之间copy的话，由于重复的数据集和地址，这很容易出错并且程序更难调试。3、由于各种内存副本，大型项目会受到这种影响并浪费资源。复制每个库 API 以接受由每个设备特定分配器分配的输入或输出内存不是一个可行的选择。这将导致库入口点的组合爆炸。随着高级语言结构（在 C++ 中，但在其他语言中）的进步，编译器现在可以在没有程序员知识的情况下利用 GPU 和其他设备。某些编译器识别的模式仅适用于共享地址空间。对所有其他模式使用共享地址空间也更合理。Linux 现有的 HMM 框架，编程复杂度高且依赖人工调优，性能和可移植性差，引发OS社区反弹，最终导致HMM方案搁浅。异构加速器领域亟需高效的统一内存管理机制。https://gitee.com/openeuler/docs/blob/master/docs/zh/docs/GMEM/%E8%AE%A4%E8%AF%86GMEM.md //gitee上介绍https://gmem.tech/   //首页3&gt; 解决方案1&gt; HMM 异构内存管理共享地址空间及迁移Hmm提供两个功能：1、统一虚拟地址空间：通过复制设备页表中的 CPU 页表来共享地址空间，因此对于进程地址空间中的任何有效主内存地址，相同的地址指向相同的物理内存；2、ZONE_DEVICE 内存：它允许为设备内存的每个页面分配一个结构页面，管理设备内存。地址空间镜像1、页表同步：mmu_interval_notifier_insert2、设备驱动程序想要填充一个虚拟地址范围：hmm_range_fault内存迁移由于 CPU 无法直接访问设备内存，因此设备驱动程序必须使用硬件 DMA 或设备特定的加载/存储指令来迁移数据。migrate_vma_setup()、migrate_vma_pages() 和 migrate_vma_finalize() 函数旨在使驱动程序更易于编写并集中跨驱动程序的通用代码。简单来说：HMM提供一堆驱动上层API，异构设备根据规定的API进行实现，接入HMM的机制比较复杂。2&gt; OpenEuler GMEM 统一内存管理内存管理划分：1&gt; 虚拟地址分配（与硬件无关）2&gt; 物理映射创建（与硬件强相关）3&gt; 物理地址分配（与硬件无关）基本思想：将硬件无关抽离出来作为统一框架，与硬件相关的MMU操作、物理地址范围由驱动注册、pagefault触发机制；可以达成的目的：1&gt; 节省各家异构设备的重复代码开发，减少驱动开发工作量2&gt; 向用户程序提供统一的内存使用接口， 用户态可以提供统一的编程接口逻辑映射系统：为了屏蔽异构设备MMU的物理映射差异， 新增逻辑映射层（记录虚拟地址所映射的物理地址，是HOST内存，也可能是某个设备上的物理地址）。 在没有逻辑映射之前，内核通过虚拟地址查找物理地址，都只能通过walk pagetable, 与硬件强相关，而且性能极差。GMEM 建立了一套新的逻辑页表去维护这个统一虚拟地址空间，通过利用逻辑页表的信息，可以维护不同处理器、不同微架构间多份页表的一致性。基于逻辑页表的访存一致性机制，内存访问时，通过内核缺页流程即可将待访问内存在主机与加速器进行搬移。页表协同： mmu映射/接映射， tlb失效等硬件相关操作。并发缺页， 内存超分 – 优化项GMEM API： 向用户层提供统一的申请接口 mmap/hmadivse。基于GMEM框架，其中与硬件无关的的优化项， 内核优化（并发缺页， 内存超分）、用户态优化（统一虚拟地址空间， 应用prefetch优化，内存分配优化）可以快速扩展到不同的异构设备上。"
  },
  
  {
    "title": "GCC FDO",
    "url": "/posts/%E5%8F%8D%E9%A6%88%E5%BC%8F%E7%BC%96%E8%AF%91%E4%BC%98%E5%8C%96/",
    "categories": "OS, performance",
    "tags": "performance",
    "date": "2023-12-06 00:00:00 +0000",
    





    
    "snippet": "一、Cache/TLB根据空间局部性和时间局部性原理，cpu中会引入Cache/TLB, 来加速数据读取。但是因为大型应用中，由于多个重要硬件结构（包括缓存、TLB和分支预测器）面临巨大压力，大型二进制文件往往表现出较差的CPU性能。二、二进制编译优化1、主动Cahce优化Cache优化 (taodudu.cc)主动识别出可能导致cache miss的原因，对二进制的bss，data，tex...",
    "content": "一、Cache/TLB根据空间局部性和时间局部性原理，cpu中会引入Cache/TLB, 来加速数据读取。但是因为大型应用中，由于多个重要硬件结构（包括缓存、TLB和分支预测器）面临巨大压力，大型二进制文件往往表现出较差的CPU性能。二、二进制编译优化1、主动Cahce优化Cache优化 (taodudu.cc)主动识别出可能导致cache miss的原因，对二进制的bss，data，text段进行指定排布编译。2、反馈式优化openeuler 20.03版本支持以下优化选项的编译器下载地址：https://repo.huaweicloud.com/openeuler/openEuler-20.03-LTS/update/aarch64/Packages/https://repo.openeuler.org/openEuler-20.03-LTS-SP1/EPOL/update/aarch64/Packages/PGO(Profile-guided optimization)通常也叫做 FDO(Feedback-directed optimization)，它是一种编译优化技术，它的原理是编译器使用程序的运行时 profiling 信息，生成更高质量的代码，从而提高程序的性能。LTO （Link Time Optimization）和 PGO （Profile Guided Optimization）参考链接：字节跳动在PGO反馈优化技术上的探索与实践 - 掘金 (juejin.cn)【信创】 JED on 鲲鹏(ARM) 调优步骤与成果 - 知乎 (zhihu.com)开源选项-GCC for openEuler选项支持-用户指南 (GCC for openEuler)-…-文档首页-鲲鹏社区 (hikunpeng.com)1、FDOFeedback-directed optimization 反馈驱动优化（FDO），又成为Profiling引导优化（PGO）  依赖于基于instrumentation的profiling分析，这需要应用程序的特殊检测构建来收集概要数据对应的编译选项： -fauto-profile=参考链接：选项 -fauto-profile,-fprofile-correction-GCC for openEuler选项支持-用户指南 (GCC for openEuler)-…-文档首页-鲲鹏社区 (hikunpeng.com)Optimize Options (Using the GNU Compiler Collection (GCC))GCC编译器高效利用cache的原理和参数 - 知乎 (zhihu.com)-fprofile-use ¶-fprofile-use=pathEnable profile feedback-directed optimizations, and the following optimizations, many of which are generally profitable only with profile feedback available:-fbranch-probabilities  -fprofile-values-funroll-loops  -fpeel-loops  -ftracer  -fvpt-finline-functions  -fipa-cp  -fipa-cp-clone  -fipa-bit-cp-fpredictive-commoning  -fsplit-loops  -funswitch-loops-fgcse-after-reload  -ftree-loop-vectorize  -ftree-slp-vectorize-fvect-cost-model=dynamic  -ftree-loop-distribute-patterns-fprofile-reorder-functionsBefore you can use this option, you must first generate profiling information. See Program Instrumentation Options, for information about the -fprofile-generate option.By default, GCC emits an error message if the feedback profiles do not match the source code. This error can be turned into a warning by using -Wno-error=coverage-mismatch. Note this may result in poorly optimized code. Additionally, by default, GCC also emits a warning message if the feedback profiles do not exist (see -Wmissing-profile).If path is specified, GCC looks at the path to find the profile feedback data files. See -fprofile-dir.-fauto-profile-fauto-profile=pathEnable sampling-based feedback-directed optimizations, and the following optimizations, many of which are generally profitable only with profile feedback available:-fbranch-probabilities  -fprofile-values-funroll-loops  -fpeel-loops  -ftracer  -fvpt-finline-functions  -fipa-cp  -fipa-cp-clone  -fipa-bit-cp-fpredictive-commoning  -fsplit-loops  -funswitch-loops-fgcse-after-reload  -ftree-loop-vectorize  -ftree-slp-vectorize-fvect-cost-model=dynamic  -ftree-loop-distribute-patterns-fprofile-correctionpath is the name of a file containing AutoFDO profile information. If omitted, it defaults to fbdata.afdo in the current directory.Producing an AutoFDO profile data file requires running your program with the perf utility on a supported GNU/Linux target system. For more information, see https://perf.wiki.kernel.org/.E.g.perf record -e br_inst_retired:near_taken -b -o perf.data \\    -- your_programThen use the create_gcov tool to convert the raw profile data to a format that can be used by GCC.  You must also supply the unstripped binary for your program to this tool. See https://github.com/google/autofdo.E.g.create_gcov --binary=your_program.unstripped --profile=perf.data \\    --gcov=profile.afdoThe following options control compiler behavior regarding floating-point arithmetic. These options trade off between speed and correctness. All must be specifically enabled.2、LTOLink Time Optimization 链接时优化（LTO）参考链接：LTO (GNU Compiler Collection (GCC) Internals)Optimize Options (Using the GNU Compiler Collection (GCC))-flto[=n]This option runs the standard link-time optimizer. When invoked with source code, it generates GIMPLE (one of GCC’s internal representations) and writes it to special ELF sections in the object file. When the object files are linked together, all the function bodies are read from these ELF sections and instantiated as if they had been part of the same translation unit.To use the link-time optimizer, -flto and optimization options should be specified at compile time and during the final link. It is recommended that you compile all the files participating in the same link with the same options and also specify those options at link time. For example:gcc -c -O2 -flto foo.cgcc -c -O2 -flto bar.cgcc -o myprog -flto -O2 foo.o bar.oThe first two invocations to GCC save a bytecode representation of GIMPLE into special ELF sections inside foo.o and bar.o. The final invocation reads the GIMPLE bytecode from foo.o and bar.o, merges the two files into a single internal image, and compiles the result as usual. Since both foo.o and bar.o are merged into a single image, this causes all the interprocedural analyses and optimizations in GCC to work across the two files as if they were a single one. This means, for example, that the inliner is able to inline functions in bar.o into functions in foo.o and vice-versa.3、BOLTBinary Optimization and Layout Tool：一个建立在LLVM框架之上的链接后优化器该优化复用编译器中来自插桩反馈优化或自动反馈优化的profile，将其转换为BOLT格式的profile并调用BOLT，自动完成链接后优化。它表明编译时间、链接时间和链接后时间FDO都不能取代其他FDO，而是互补的。优化代码布局(code layout) 是一项对于性能提升的重要优化，目前在编译时和链接时都有对应可行的优化手段。而 BOLT(Binary Optimization and Layout Tool) 则是链接后优化(post-link optimizer)，使用基于采样的 profile 信息，甚至可以对已经进行过 FDO(feedback-driven optimization) 和 LTO(link-time optimization) 之后的二进制，再次提升其运行性能，所以这是一个可作为补充的优化手段。参考链接：BOLT:二进制优化器 - 知乎 (zhihu.com)选项-fauto-bolt,-fbolt-use,-fbolt-target,-fbolt-option-GCC for openEuler选项支持-用户指南 (GCC for openEuler)-…-文档首页-鲲鹏社区 (hikunpeng.com)BOLT: 链接后优化技术简介 - 知乎 (zhihu.com)大规模C++编译性能优化系统OMAX介绍-CSDN博客  安装llvm-boltAutoBOLT模式：该模式必须和选项-fauto-profile或-fprofile-use共同使用，必须增加-Wl,-q保留重定位信息。以test程序为例：gcc -g -O2 -o test test.c -fauto-profile=test.gcda -fauto-bolt -Wl,-q或gcc -g -O2 -o test test.c -fprofile-use -fauto-bolt -Wl,-qBOLT use模式：该模式需要提前准备好BOLT优化所需要的profile。该profile可以使用AutoBOLT模式获取，也可以使用perf2bolt工具获取。gcc -g -O2 -o test test.c -fbolt-use=dafa.fdata -Wl,-q4、fprefetch-loop-arrays预取优化 + 反馈式预取优化参考链接：鲲鹏社区-官网丨凝心聚力 共创行业新价值 (hikunpeng.com)Optimize Options (Using the GNU Compiler Collection (GCC))原生：-fprefetch-loop-arrays If supported by the target machine, generate instructions to prefetch memory to improve the performance of loops that access large arrays.This option may generate better or worse code; results are highly dependent on the structure of loops within the source code.Disabled at level -Os.openeuler gcc增强：-fprefetch-loop-arrays=0：原始预取算法（无赋值，默认为0）；-fprefetch-loop-arrays=1：简化分支的预取距离算法；-fprefetch-loop-arrays=2：分支加权的预取距离算法；-fprefetch-loop-arrays=[value] -fauto-profile=xxx.gcov -fcache-misses-profile=xxx.gcov：反馈式软件预取；可配置参数：--param param-prefetch-func-topn=n：筛选前n个热点函数，默认值：3--param param-prefetch-ref-topn=n：筛选前n个热点访存对象，默认值：5--param param-high-loop-execution-rate=n：筛选执行率高于n%的循环，默认值：95%5、others参考链接： 鲲鹏社区-官网丨凝心聚力 共创行业新价值 (hikunpeng.com)选项 -fipa-reorder-fields:内存空间布局优化，根据结构体中成员的占用空间大小，将成员从大到小排列，以减少边界对齐引入的padding，来减少结构体整体占用的内存大小，以提高cache的命中率。-fipa-struct-reorg: 内存空间布局优化，将结构体成员在内存中的排布进行新的排列组合，来提高cache的命中率。三、性能影响1、numa场景避免线程在多核上调度，出现 1&gt; L1 cache频繁失效 2&gt;可能跨numa，导致性能下降常见手段：绑核、绑numa代码段副本2、减少TLB miss常见手段:TLB miss3、减少调度常见手段：核隔离4、内存分配器常见手段：tcmalloc5、应用优化常见手段：perf热点函数，消减热点6、编译器优化常见手段：PGO 反馈式编译优化"
  },
  
  {
    "title": "userspace lock introduce",
    "url": "/posts/%E7%94%A8%E6%88%B7%E6%80%81%E9%94%81/",
    "categories": "OS, lock",
    "tags": "lock",
    "date": "2023-11-30 00:00:00 +0000",
    





    
    "snippet": "锁介绍多线程下为了保护共享数据，需要同步机制。互斥：多线程中互斥是指多个线程访问同一资源时同时只允许一个线程对其进行访问，具有唯一性和排它性。但互斥无法限制访问者对资源的访问顺序，即访问是无序的；同步：多线程同步是指在互斥的基础上（大多数情况），通过其它机制实现访问者对资源的有序访问。在大多数情况下，同步已经实现了互斥，特别是所有写入资源的情况必定是互斥的。少数情况是指可以允许多个访问者同时...",
    "content": "锁介绍多线程下为了保护共享数据，需要同步机制。互斥：多线程中互斥是指多个线程访问同一资源时同时只允许一个线程对其进行访问，具有唯一性和排它性。但互斥无法限制访问者对资源的访问顺序，即访问是无序的；同步：多线程同步是指在互斥的基础上（大多数情况），通过其它机制实现访问者对资源的有序访问。在大多数情况下，同步已经实现了互斥，特别是所有写入资源的情况必定是互斥的。少数情况是指可以允许多个访问者同时访问资源。reference：https://zhuanlan.zhihu.com/p/608618791互斥锁介绍在多任务操作系统中，同时运行的多个任务可能都需要使用同一种资源。为了同一时刻只允许一个任务访问资源，需要用互斥锁对资源进行保护。互斥锁是一种简单的加锁的方法来控制对共享资源的访问，互斥锁只有两种状态,即上锁( lock )和解锁( unlock )。锁特性      原子性：互斥锁是一个原子操作，操作系统保证如果一个线程锁定了一个互斥锁，那么其他线程在同一时间不会成功锁定这个互斥锁        唯一性：如果一个线程锁定了一个互斥锁，在它解除锁之前，其他线程不可以锁定这个互斥锁        非忙等待：如果一个线程已经锁定了一个互斥锁，第二个线程又试图去锁定这个互斥锁，则第二个线程将被挂起且不占用任何CPU资源，直到第一个线程解除对这个互斥锁的锁定为止，第二个线程则被唤醒并继续执行，同时锁定这个互斥锁    PS：对互斥锁进行加锁后，任何其他试图再次对互斥锁加锁的线程将会被阻塞，直到锁被释放  使用#include &lt;pthread.h&gt;pthread_mutex_t mutex; //锁定义pthread_mutexattr_t mattr; //属性//glibc sysdeps/nptl/pthread.hpthread_mutexattr_init (&amp;mattr);pthread_mutexattr_settype (&amp;mattr, PTHREAD_MUTEX_ERRORCHECK);int pthread_mutex_init(pthread_mutex_t *restrict mutex,const pthread_mutexattr_t *restrict attr);//锁初始化pthread_mutex_lock(pthread_mutex_t *); //上锁pthread_mutex_trylock(pthread_mutex_t *mutex)pthread_mutex_unlock(pthread_mutex_t *mutex); //解锁自旋锁介绍自旋锁与互斥锁功能相同，唯一不同的就是互斥锁阻塞后休眠不占用CPU，而自旋锁阻塞后不会让出CPU，会一直忙等待，直到得到锁锁特性  忙等  自旋锁在用户态较少用，而在内核态使用的比较多  自旋锁的使用场景：锁的持有时间比较短，或者说小于2次上下文切换的时间 //如果临界区时间大于线程切换时间，那就得不偿失，会浪费大量的CPU资源使用自旋锁在用户态的函数接口和互斥量一样，把pthread_mutex_lock()/pthread_mutex_unlock()中mutex换成spin，如：pthread_spin_init()。读写锁（pthread_rwlock）介绍与前面介绍的互斥量，信号量类似，用于多线程/进程间同步控制，但与它们的不同之处在于，读写锁可以区分读加锁和写加锁，也就是说一把锁有两种不同的加锁方式，那么对于两种加锁方式下的并发控制也是不同。  读写锁允许更高的并行性，也叫共享互斥锁。互斥量要么是加锁状态，要么就是解锁状态，而且一次只有一个线程可以对其加锁。读写锁可以有3种状态：读模式下加锁状态、写模式加锁状态、不加锁状态。一次只有一个线程可以占有写模式的读写锁，但是多个线程可以同时占有读模式的读写锁,即允许多个线程读但只允许一个线程写。  当读操作较多，写操作较少时，可用读写锁提高线程读并发性锁特性      读写锁，有两种加锁方式：    （1）加读锁，也就是共享锁，多个并发可以同步加此种锁，同时可以访问临界区。（2）加写锁，也就是独占锁，只有一个并发可以成功的加写锁，此时其它并发既不能加写锁，也不能加读锁，这就是独占的意义。      使用    #include &lt;pthread.h&gt;    int phtread_rwlock_init(pthread_rwlock_t *restrict rwlock, const pthread_rwlockattr_t *restrict attr); //rwlock：读写锁，attr：读写锁属性    int pthread_rwlock_destroy(pthread_rwlock_t *rwlock);    /** 加读锁 */    int pthread_rwlock_rdlock(pthread_rwlock_t *rwlock);    /** 加写锁 */    int pthread_rwlock_wrlock(pthread_rwlock_t *rwlock);    /** 释放锁 */    int pthread_rwlock_unlock(pthread_rwlock_t *rwlock);信号量介绍信号量用于进程或线程间的同步和互斥，信号量本质上是一个非负的整数计数器，它被用来控制对公共资源的访问。编程时可根据操作信号量值的结果判断是否对公共资源具有访问的权限，当信号量值大于0时，则可以访问，否则将阻塞。使用#include &lt;semaphore.h&gt;// 初始化信号量int sem_init(sem_t *sem, int pshared, unsigned int value);// 信号量P操作（减 1）int sem_wait(sem_t *sem);// 以非阻塞的方式来对信号量进行减1操作int sem_trywait(sem_t *sem);// 信号量V操作（加 1）int sem_post(sem_t *sem);// 获取信号量的值int sem_getvalue(sem_t *sem, int *sval);// 销毁信号量int sem_destroy(sem_t *sem);条件变量介绍  条件变量用来阻塞一个线程，直到条件发生。通常条件变量和互斥锁同时使用。条件变量使线程可以睡眠等待某种条件满足。条件变量是利用线程间共享的全局变量进行同步的一种机制。  条件变量的逻辑：一个线程挂起去等待条件变量的条件成立，而另一个线程使条件成立。使用线程在改变条件状态之前先锁住互斥量。如果条件为假，线程自动阻塞，并释放等待状态改变的互斥锁。如果另一个线程改变了条件，它发信号给关联的条件变量，唤醒一个或多个等待它的线程。如果两进程共享可读写的内存，条件变量可以被用来实现这两进程间的线程同步pthread_cond_t pthread_cond_waitpthread_cond_signalRCU锁（userspace-rcu）"
  },
  
  {
    "title": "userspace rcu lock",
    "url": "/posts/userspace-rcu%E9%94%81/",
    "categories": "OS, lock",
    "tags": "lock",
    "date": "2023-11-29 00:00:00 +0000",
    





    
    "snippet": "RCU介绍Read-copy update (RCU) is a synchronization mechanism that was added to the Linux kernel in October of 2002. RCU achieves scalability improvements by allowing reads to occur concurrently with ...",
    "content": "RCU介绍Read-copy update (RCU) is a synchronization mechanism that was added to the Linux kernel in October of 2002. RCU achieves scalability improvements by allowing reads to occur concurrently with updates.RCU利用一种Publish-Subscribe的机制，在Writer端增加一定负担，使得Reader端几乎可以Zero-overhead。RCU适合用于同步基于指针实现的数据结构（例如链表，哈希表等），同时由于他的Reader 0 overhead的特性，特别适用用读操作远远大与写操作的场景。RCU适合数据库吗？http://linuxcpp.0voice.com/?id=111082Linux内核RCU的应用场景包括：网络协议栈：网络协议栈需要高效地处理大量的数据包，而且在访问共享数据时需要避免锁竞争。使用RCU可以减少锁竞争带来的性能开销，提高网络协议栈的吞吐量。文件系统：文件系统需要频繁地读写文件，并且多个进程可能会同时访问同一个文件。使用RCU可以在不影响并发性的情况下保护共享数据结构，从而提高文件系统的性能。数据库管理系统：数据库管理系统需要高效地处理大量的并发事务，而且在访问共享数据时需要保证一致性和隔离性。使用RCU可以在不阻塞其他事务的情况下更新共享数据结构，从而提高数据库管理系统的并发能力。虚拟化技术：虚拟化技术需要快速地创建、删除和移动虚拟机，并且在多个虚拟机之间共享物理资源。使用RCU可以减少锁竞争带来的开销，从而提高虚拟化技术的效率。大规模分布式系统：大规模分布式系统需要同时处理大量请求，并且在多个节点之间共享状态信息。使用RCU可以减少锁竞争带来的开销，从而提高分布式系统的性能和可扩展性。总之，RCU是一种高效的读写锁技术，在访问共享数据时可以提供更好的并发性和性能，因此在需要处理大量并发请求和频繁访问共享数据的场景下被广泛应用。"
  },
  
  {
    "title": "glibc 读写锁pthread_rw_lock",
    "url": "/posts/glibc-%E8%AF%BB%E5%86%99%E9%94%81/",
    "categories": "glibc, lock",
    "tags": "lock",
    "date": "2023-11-29 00:00:00 +0000",
    





    
    "snippet": "读写锁介绍  读写锁允许更高的并行性，也叫共享互斥锁。互斥量要么是加锁状态，要么就是解锁状态，而且一次只有一个线程可以对其加锁。读写锁可以有3种状态：读模式下加锁状态、写模式加锁状态、不加锁状态。一次只有一个线程可以占有写模式的读写锁，但是多个线程可以同时占有读模式的读写锁,即允许多个线程读但只允许一个线程写。  当读操作较多，写操作较少时，可用读写锁提高线程读并发性具体实现：以pthrea...",
    "content": "读写锁介绍  读写锁允许更高的并行性，也叫共享互斥锁。互斥量要么是加锁状态，要么就是解锁状态，而且一次只有一个线程可以对其加锁。读写锁可以有3种状态：读模式下加锁状态、写模式加锁状态、不加锁状态。一次只有一个线程可以占有写模式的读写锁，但是多个线程可以同时占有读模式的读写锁,即允许多个线程读但只允许一个线程写。  当读操作较多，写操作较少时，可用读写锁提高线程读并发性具体实现：以pthread_rwlock_rdlock为例，其他同理实际有个互斥锁，保护读写锁的数据。//arm64typedef union{  struct  {    int __lock;    unsigned int __nr_readers;    unsigned int __readers_wakeup;    unsigned int __writer_wakeup;    unsigned int __nr_readers_queued;    unsigned int __nr_writers_queued;    int __writer;    int __shared;    unsigned long int __pad1;    unsigned long int __pad2;    unsigned int __flags;  } __data;  char __size[__SIZEOF_PTHREAD_RWLOCK_T];  long int __align;} pthread_rwlock_t;获取读锁：x86://nptl/sysdeps/unix/sysv/linux/x86_64/pthread_rwlock_rdlock.S//逻辑与arm64的一致arm64:基于glibc-2.17的代码分析：//nptl/pthread_rwlock_rdlock.c/* * 1 锁住rwlock.data.lock互斥锁 * 2 判断当前是否有写者，实现不同路径 *    1&gt; 如果没有写者，并且是读者优先，即使有写者在等锁，也优先把锁给读者； \t      ----&gt;结束 *    2&gt; 如果有写者，释放rwlock.data.lock互斥锁， 阻塞等待写者释放锁后的唤醒。 *        -----&gt;获取rwlock.data.lock互斥锁, 重新获取读锁 *//* Acquire read lock for RWLOCK.  */int__pthread_rwlock_rdlock (rwlock)     pthread_rwlock_t *rwlock;{    ...    /* Make sure we are alone.  */    lll_lock (rwlock-&gt;__data.__lock, rwlock-&gt;__data.__shared);    while (1)  {      /* Get the rwlock if there is no writer...  */       if (rwlock-&gt;__data.__writer == 0      /* ...and if either no writer is waiting or we prefer readers.  */      &amp;&amp; (!rwlock-&gt;__data.__nr_writers_queued          || PTHREAD_RWLOCK_PREFER_READER_P (rwlock))) {           ++rwlock-&gt;__data.__nr_readers; //增加读者           break; //结束       }       ++rwlock-&gt;__data.__nr_readers_queued; //读写入等待队列       /* Free the lock.  */      lll_unlock (rwlock-&gt;__data.__lock, rwlock-&gt;__data.__shared);       /* Wait for the writer to finish.  */      lll_futex_wait (&amp;rwlock-&gt;__data.__readers_wakeup, waitval,\t\t      rwlock-&gt;__data.__shared);      /* Get the lock.  */      lll_lock (rwlock-&gt;__data.__lock, rwlock-&gt;__data.__shared);      --rwlock-&gt;__data.__nr_readers_queued; //读者等待队列自减，再重新去获取锁    }    lll_unlock(rwlock-&gt;__data.__lock);}//nptl/pthread_rwlock_wrlock.c/* Acquire write lock for RWLOCK.  */int__pthread_rwlock_wrlock (rwlock)     pthread_rwlock_t *rwlock;{//nptl/pthread_rwlock_unlock.c/* Unlock RWLOCK.  */int__pthread_rwlock_unlock (pthread_rwlock_t *rwlock){      lll_lock (rwlock-&gt;__data.__lock, rwlock-&gt;__data.__shared); //获取rwlock数据保护的互斥锁  if (rwlock-&gt;__data.__writer) //判断是读者 or 写者    rwlock-&gt;__data.__writer = 0; //写着释放, 将写者的线程号  else    --rwlock-&gt;__data.__nr_readers;//读者自减  if (rwlock-&gt;__data.__nr_readers == 0) //判断是否还有读者？ 两种情况：1、 写者持锁，当前释放，存在读者等待 2、读者持锁，所有读者都释放锁，存在写者等待    { \t\t\t\t\t\t\t\t//没有读者      if (rwlock-&gt;__data.__nr_writers_queued) //判断是否有写者等待？\t{\t  ++rwlock-&gt;__data.__writer_wakeup; //存在读者等待，唤醒写者\t  lll_unlock (rwlock-&gt;__data.__lock, rwlock-&gt;__data.__shared);\t  lll_futex_wake (&amp;rwlock-&gt;__data.__writer_wakeup, 1,\t\t\t  rwlock-&gt;__data.__shared); //唤醒一个写者，写者抢锁\t  return 0;\t}      else if (rwlock-&gt;__data.__nr_readers_queued) //此时写者unlock，存在读者等待。\t{\t  ++rwlock-&gt;__data.__readers_wakeup; //唤醒读者\t  lll_unlock (rwlock-&gt;__data.__lock, rwlock-&gt;__data.__shared);\t  lll_futex_wake (&amp;rwlock-&gt;__data.__readers_wakeup, INT_MAX,\t\t\t  rwlock-&gt;__data.__shared); //唤醒所有读者，并发读\t  return 0;\t}    }  lll_unlock (rwlock-&gt;__data.__lock, rwlock-&gt;__data.__shared); //释放rwlock数据保护的互斥锁  return 0;}性能测试测试方案：总结对锁性能来看：1、"
  },
  
  {
    "title": "MMDB (memory database)",
    "url": "/posts/%E5%86%85%E5%AD%98%E6%95%B0%E6%8D%AE%E5%BA%93/",
    "categories": "db, mmdb",
    "tags": "mmdb",
    "date": "2023-11-13 00:00:00 +0000",
    





    
    "snippet": "内存数据库redo log &amp;&amp; undo log &amp;&amp; bin logACID:数据库事务执行的四要素：atomicity原子性，consistency一致性，isolation隔离性，durability持久性。reference: https://blog.csdn.net/weixin_47786582/article/details/13270128...",
    "content": "内存数据库redo log &amp;&amp; undo log &amp;&amp; bin logACID:数据库事务执行的四要素：atomicity原子性，consistency一致性，isolation隔离性，durability持久性。reference: https://blog.csdn.net/weixin_47786582/article/details/132701284而事务的原子性、一致性和持久性由事务的 redo 日志和 undo 日志来保证。REDO LOG 称为 重做日志 ，提供再写入操作，恢复提交事务修改的页操作，用来保证事务的持久性。UNDO LOG 称为 回滚日志 ，回滚行记录到某个特定版本，用来保证事务的原子性、一致性。redo log : 是存储引擎层(innodb)生成的日志, 记录的是” 物理级别 “上的页修改操作, 比如页号×××, 偏移量yyy, 写入了’zzz’数据. 主要为了保证数据的可靠性;undo log : 是存储引擎层(innodb)生成的日志, 记录的是 逻辑操作 日志, 比如对某一行数据进行了INSERT语句操作, 那么undo log就记录一条与之相反的delete操作. 主要用于 事务的回滚 (undo log 记录的是每个修改操作的 逆操作 ) 和 一致性非锁定读 (undo log回滚行记录到某种特定的版本– MVCC, 即多版本并发控制)redo日志持久性：对于一个已经提交的事务，在事务提交后即使系统发生了崩溃，这个事务对数据库中所做的更改也不能丢失。  设计初衷：​\t1 由于cache/buff的存在，会导致expection，crash时没有及时刷盘或者flush cache，从而导致提交数据丢失。​\t2 为了保证持久性，那就要及时刷盘/cache​\t这样会造成flush频繁，IO/Cache flush成为性能瓶颈。​\t引入Redo日志：InnoDB引擎：WAL Write-Ahead Logging。当发生crash但数据未刷到内存/磁盘文件中，可以通过redo来恢复。​\texample: 记录哪些东西被修改：事务A将表空间xx页表xx处内容改成xx值。      优势    降低刷盘频率    占用空间小        特点    redo日志顺序记录，使用顺序IO？？？？？？    事务执行过程中不断记录  Mini-Transaction对底层页表的一次原子访问。事务-&gt; 语句 -&gt; Mini-Transaction -&gt; redo日志。Undo日志原子性和一致性：原子性：原原子性保证了在一个事务中,多个数据库操作,要么全部成功,要么全部失败,不允许出现部分成功,部分失败的情况。引入原因：可能发生异常情况，导致事务处理一半：example1：事务执行过程中可能遇到各种错误，比如 服务器本身的错误 ， 操作系统错误 ，甚至是突然 断电 导致的错误。example2：程序员可以在事务执行过程中手动输入 ROLLBACK 语句结束当前事务的执行。引入Undo日志，为了回滚而记录的内容。PS：1、查询操作select不会产生Undo日志 2、Undo日志本身的持久性由Redo日志完成。功能：      回滚数据        MVCC    InnoDB存储引擎中MVCC通过Undo日志完成。 当用户读取一行记录，若该记录已经被其他事务占用，当前事务可以通过undo读取之前的行版本信息，以此实现非锁定读取。  Undo日志 -&gt; 回滚段， 回滚段的分类：1、Uncommitted undo infomation2、Committed undo infomation 已提交但未过期数据3、expired undo information 已提交并且过期数据事务提交后并不能马山删除undo log和对应的页。因为其他事务需要通过undo log来得到行记录之前的版本。提交时放到undo log链表，等待purge线程来回收。Undo日志分类：      insert undo log    insert操作的记录，对事务本身可见，对其他事务不可见 - 事务隔离性。 所以在事务提交后，可以直接删除。不需要等待purge操作。        update undo log    delete update操作，MVCC机制，对其他事务可见，所以提交时放到undo log链表，等待purge线程来回收。  数据库设计reference：https://baijiahao.baidu.com/s?id=1766408092127630197&amp;wfr=spider&amp;for=pc      需求分析    应用场景(人员管理、商品管理) 数据类型(数字、字符、日期) 数据量(规划数据容量) 数据访问(访问频率和方式） 数据安全(加密） 系统可用性(可靠性，容灾)        概念设计    确定数据模型和实体关系图。    数据模型：实体与属性之间的关系。    实体关系：实体之间的关系， 1N, MN    主键和外键：确定每个实体的主键和外键，以保证数据的完整性和唯一性。    约束条件：实体之间的约束条件 完整性约束，域完整性约束    性能优化：数据分区，索引优化。        逻辑设计    数据库表：在逻辑设计中，将实体转化为数据库表，并确定表的结构和属性，确保表的设计符合数据库设计规范，例如第一范式、第二范式、第三范式等。    数据库架构：根据数据管理系统的预计使用情况，设计合适的数据库架构，包括单机版、集群版、分布式版等。    数据库索引：设计合理的数据库索引，提高查询效率和数据访问速度。    数据库存储过程和触发器：设计存储过程和触发器，用于处理复杂的业务逻辑，在数据库层面实现数据处理。    安全性优化：考虑安全性优化，例如加密、权限管理等。        物理设计    数据库分区：设计合理的数据库分区方案，提高数据管理系统的容量和性能。    存储优化：设计合理的存储安排，优化数据存储结构，提高存储空间利用率。    备份和恢复：设计合理的备份和恢复方案，保证数据的连续性和完整性。    性能监控：设计合理的性能监控和调优方案，保持数据管理系统的稳定性和高效性。    总之，进行数据库设计需要经过需求分析、概念设计、逻辑设计和物理设计等多个阶段，每个阶段都需要认真思考和设计，确保数据管理系统的高效性、可扩展性、易用性和安全性。同时，还需要根据业务需求进行持续优化和调整，以保证数据管理系统始终处于最佳状态。数据库表：在逻辑设计中，将实体转化为数据库表，并确定表的结构和属性，确保表的设计符合数据库设计规范，例如第一范式、第二范式、第三范式等。  数据库知识： 表、记录、索引、关联关系 -表记录索引索引跳表数据库索引和主键、外键的关系？？关联关系sqlite3SQLite is a C-language library that implements a small, fast, self-contained,high-reliability, full-featured, SQL database engine. SQLite is the most useddatabase engine in the world. SQLite is built into all mobile phones and mostcomputers and comes bundled inside countless other applications that peopleuse every day.It also include lemon and sqlite3_analyzer and tcl tools.SQLite，是一款轻型的数据库，是遵守ACID的关系型数据库管理系统，它包含在一个相对小的C库中。它是D.RichardHipp建立的公有领域项目。它的设计目标是嵌入式的，而且已经在很多嵌入式产品中使用了它，它占用资源非常的低，在嵌入式设备中，可能只需要几百K的内存就够了。它能够支持Windows/Linux/Unix等等主流的操作系统，同时能够跟很多程序语言相结合，比如 Tcl、C#、PHP、Java等，还有ODBC接口，同样比起Mysql、PostgreSQL这两款开源的世界著名数据库管理系统来讲，它的处理速度比他们都快。PostgreSQL增强"
  },
  
  {
    "title": "Hundsun Lightos",
    "url": "/posts/HUNDSUN-LightOS/",
    "categories": "",
    "tags": "",
    "date": "2023-10-30 00:00:00 +0000",
    





    
    "snippet": "title: LightOSauthor: luochunshengdate: 2023-10-01categories: [OS, Low Latency]tags: [OS]render_with_liquid: falseimg_path: ‘/posts’—一、LigthOS简介1、LightOS介绍• 恒生LightOS操作系统是基于国内openEuler开源社区构建的企业级操作系...",
    "content": "title: LightOSauthor: luochunshengdate: 2023-10-01categories: [OS, Low Latency]tags: [OS]render_with_liquid: falseimg_path: ‘/posts’—一、LigthOS简介1、LightOS介绍• 恒生LightOS操作系统是基于国内openEuler开源社区构建的企业级操作系统，具备高效、稳定、安全的特性，致力于为企业级的数据库、大数据、云计算、人工智能平台提供安全稳定的运行基础。• 恒生电子基于金融业务需求对openEuler的核心应用进行改造优化。比如针对清算等场景,LightOS将在操作系统的内核裁剪、文件系统优化、CPU内存优化等方面进行改造。再如极速交易场景,网络交互是核心卡点,LightOS将在网卡以及RDMA进行调优适配,以实现低延时和高吞吐。• 在适配兼容方面,LightOS已针对金融主流的国产软硬件厂商进行生态适配,包括鲲鹏、海光等主流芯片和相关主机以及主流数据库、中间件、应用等产品,充分满足自主可控需求。• 恒生电子也推出了基于Visual Studio Code的迁移评估工具sys2light,为开发者提供进行软件迁移分析的轻量级端到端工具,支持软件评估、配置收集与评估以及硬件评估,以解决客户软件迁移评估中分析投入大、准确率低、整体效率低下的痛点。• 恒生电子自主创新的LIGHT金融基础设施底座,包含分布式数据库LightDB,分布式中间件Light-JRES和Light-LDP,以及操作系统LightOS。2、LightOS优势内核优化：• 针对场景优化：在通用内核的基础上，特别针对大数据场景、低延迟场景等做了特别优化内核，可以根据不同场景的应用特点定制化更换更加优化的系统内核；• I/O优化：通过优化系统I/O调度策略及文件系统元数据回写时机，大幅提升I/O效率，提升大数据分析的业务吞吐量；• 中断优化：通过引入中断线程化等优化组件，大大提升进程切换效率，优化系统在高并发负载下的运行效率；• 网络优化：通过进入用户态网络协议，大大提升网络吞吐量，优化Redis、数据库等应用的吞吐效率；场景优化：• 操作系统深度裁剪：保证应用生态前提下，针对证券交易场景进行深度裁剪，提升系统部署效率、运维效率与安全性；• 证券交易场景深度优化： 针对恒生JRES、LDP两个底座平台进行了专门优化，使包括IAR网关、Redis、Kafka、低延迟消息总线等组件吞吐量大幅提高、延迟进一步降低；• 网络延迟深度优化：内核级优化网络接口性能（AF_UNIX增强），降低多并发场景下，连接时延和CPU占用率。提升证券量化交易场景下客户体验；• 国密全栈支持优化：针对证券国产化需求，对系统关键安全特性进行国密算法支持，为上层应用提供国密算法库、国密证书、国密安全传输协议等密码服务reference:https://baijiahao.baidu.com/s?id=1762209983043234935&amp;wfr=spider&amp;for=pchttps://gitee.com/openeuler/openEuler-portal/issueshttps://www.hs.net/openplat-front/service/serviceDetail/1680二、 LightOS使用从https://uplus.hundsun.com/LightOS/LightOS1.0/index.html下载进行安装LightOS提供kernel与kernel-rtkernel-rt主要合入了RT-PREEMPT的补丁：https://www.kernel.org/pub/linux/kernel/projects/rt/三、特性分析"
  },
  
  {
    "title": "Rtlinux",
    "url": "/posts/RTlinux/",
    "categories": "OS, realtime",
    "tags": "OS",
    "date": "2023-10-01 00:00:00 +0000",
    





    
    "snippet": "1、国产RTlinux？2、相比linux在各个子系统做了那些优化？",
    "content": "1、国产RTlinux？2、相比linux在各个子系统做了那些优化？"
  },
  
  {
    "title": "进程保存和恢复",
    "url": "/posts/process-checkpoint-restore/",
    "categories": "sched, checkpoint, restore",
    "tags": "sched",
    "date": "2023-09-28 00:00:00 +0000",
    





    
    "snippet": "1、当前已有进程保存和恢复机制2、能做到线程级别3、线程的保存和恢复结合svm能做什么？",
    "content": "1、当前已有进程保存和恢复机制2、能做到线程级别3、线程的保存和恢复结合svm能做什么？"
  },
  
  {
    "title": "struct folio",
    "url": "/posts/linux-struct-folio/",
    "categories": "MM, struct folio",
    "tags": "mm",
    "date": "2023-09-27 00:00:00 +0000",
    





    
    "snippet": "介绍linux内核新引入的struct folio1、为什么引入？2、带来什么好处？3、基于这个机制会带来什么变化？",
    "content": "介绍linux内核新引入的struct folio1、为什么引入？2、带来什么好处？3、基于这个机制会带来什么变化？"
  },
  
  {
    "title": "Userspace Memory Management",
    "url": "/posts/userspace-memory-management/",
    "categories": "MM, Userspace",
    "tags": "mm",
    "date": "2023-09-25 00:00:00 +0000",
    





    
    "snippet": "用户态内存管理器分析对比1、jemalloc2、tcmalloc3、ptmalloc",
    "content": "用户态内存管理器分析对比1、jemalloc2、tcmalloc3、ptmalloc"
  },
  
  {
    "title": "NVMe Introduction",
    "url": "/posts/NVMe-Introduction/",
    "categories": "Study, NVMe",
    "tags": "NVMe",
    "date": "2023-07-31 00:00:00 +0000",
    





    
    "snippet": "1、NVMe转自https://www.netapp.com/cn/info/what-is-nvme.aspxNVMe（Nonvolatile Memory Express，非易失性内存标准）是一种闪存和下一代固态驱动器 (SSD) 的全新存储访问和传输协议，可为所有类型的企业工作负载提供最高的吞吐量和最快的响应速度。如今，消费者应用程序和企业应用程序的用户都期待越来越快的响应速度，虽然应...",
    "content": "1、NVMe转自https://www.netapp.com/cn/info/what-is-nvme.aspxNVMe（Nonvolatile Memory Express，非易失性内存标准）是一种闪存和下一代固态驱动器 (SSD) 的全新存储访问和传输协议，可为所有类型的企业工作负载提供最高的吞吐量和最快的响应速度。如今，消费者应用程序和企业应用程序的用户都期待越来越快的响应速度，虽然应用程序本身复杂性大幅提高且越来越依赖于资源。为帮助提供高带宽低延迟的用户体验，NVMe 协议可通过 PCI Express (PCIe) 总线访问闪存存储；该总线支持数以万计的并行命令队列，因此比受限于单个命令队列的硬盘和传统全闪存架构要快得多。NVMe 规范可利用各种计算环境中的非易失性存储，而且适应未来需要，可扩展，并能够与尚未发明的永久性内存技术搭配使用。NVMe 数据存储的优势NVMe 存储成为企业级数据中心的重磅新闻指日可待，因为它可以节省时间。  与机械式硬盘驱动器时代设计的协议不同，NVMe 不仅利用了固态存储，还利用了当今的多核 CPU 和 GB 级内存。  NVMe 存储还利用简化的命令集，高效地解析和操控数据。NVMe 用例NVMe 存储已经应用于毫秒必争的企业场景中：  实时客户互动，例如金融、电子商务和软件销售代理  人工智能 (AI)、机器学习 (ML)、大数据和高级分析应用  开发运营，支持您在更短时间内运行更多迭代基于网络结构的 NVMe (NVMe over Fabrics, NVMe-oF)NVMe 不仅仅是速度更快的闪存存储，还是一种支持各个存储系统和服务器之间高效得多的数据传输的端到端标准。  基于网络结构的 NVMe 将 NVMe 的性能和延迟优势扩展到以太网、光纤通道和 InfiniBand 等各个网络结构。  通过 Data Fabric 提供从主机软件堆栈到存储阵列的更高 IOPS 和更低延迟。基于光纤通道的 NVMe (NVMe over Fibre Channel, NVMe/FC)随着最近 NetApp®ONTAP® 的发布，NetApp 数据管理平台现在可提供对基于光纤通道的 NVMe 的支持。由于光纤通道的性能和稳定性及其对基于网络结构的分区和名称服务的支持，许多企业都围绕光纤通道构建了其整个基础架构。与使用 FCP（带有底层光纤通道连接的 SCSI 协议）相比，数据库等应用程序在使用 NVMe/FC 协议时的运行速度要快得多。ONTAP NVMe/FC 流量可以与 FCP 流量一起驻留在相同的光纤通道网络结构中，因此 NVMe/FC 采用起来非常轻松。对于许多使用 ONTAP AFF 系统的客户而言，这纯粹就是一次无中断的软件升级。转自:https://zh.wikipedia.org/wiki/NVM_ExpressNVM Express（缩写NVMe），或称非易失性内存主机控制器接口规范（英语：Non-Volatile Memory Host Controller Interface Specification，缩写：NVMHCIS），是一个逻辑设备接口规范。它是与AHCI类似的、基于设备逻辑接口的总线传输协议规范（相当于通讯协议中的应用层），用于访问通过PCI Express（PCIe）总线附加的非易失性存储器介质（例如采用闪存的固态硬盘驱动器），虽然理论上不一定要求PCIe总线协议。NVMe是一种协议，是一组允许SSD使用PCIe总线的软硬件标准；而PCIe是实际的物理连接通道。NVM代表非易失性存储器（non-volatile memory）的首字母缩略字，这是固态硬盘（SSD）的常见的闪存形式。此规范主要是为基于闪存的存储设备提供一个低延时、内部并发化的原生界面规范，也为现代CPU、电脑平台及相关应用提供原生存储并发化的支持[1]，令主机硬件和软件可以充分利用固态存储设备的并行化存储能力。相比此前机械硬盘驱动器（HDD）时代的AHCI，NVMe/NVMHCI降低了I/O操作等待时间、提升同一时间内的操作数、更大容量的操作队列等。依托于PCIe总线，NVMe设备可适用于各种支持PCIe总线的物理插槽上，包括标准尺寸的PCIe扩展卡（一般是4个PCIe通道）[2]、采用U.2物理连接界面（SFF-8639）的2.5英寸/3.5英寸标准尺寸固态硬盘驱动器、[3][4]SATA Express总线（兼容于PCIe）的设备、M.2规格扩展卡等。[5]此规范由NVMHCIS工作组负责管理。NVMe标准对比AHCI标准：  当数据从存储传输到服务器主机时，会进入一行或队列。传统的SATA连接只能支持一个队列，一次只能接收32条数据。而NVMe存储支持最多64000个队列，每个队列有64000个条目。  NVMe使用原生PCI-e通道与CPU直连，免去了SATA与SAS接口的外置控制器（PCH）与CPU通信所带来的延时。NVMe标准的延时只有AHCI的一半不到：NVMe精简了调用方式，执行命令时不需要读取寄存器；而AHCI每条命令则需要读取4次寄存器，一共会消耗8000次CPU循环，从而造成大概2.5微秒的延迟。  NVMe支持同时从多核处理器接受命令和优先处理请求，这在企业级的重负载时优势明显。  NVMe加入了自动功耗状态切换和动态能耗管理功能。设备从Power State 0闲置50ms后可以切换到Power State 1；继续闲置的话，在500ms后又会进入功耗更低的Power State 2，切换时会有短暂延迟。SSD在闲置时可以非常快速的控制在极低的水平，在功耗管理上NVMe标准的SSD会比现在主流的AHCI SSD拥有较大优势。"
  },
  
  {
    "title": "Deep Learning Basics",
    "url": "/posts/Deep-Learning-Basics/",
    "categories": "Study, Deep Learning",
    "tags": "Deep Learning",
    "date": "2023-06-01 00:00:00 +0000",
    





    
    "snippet": "Reference: https://cloud.tencent.com/developer/article/1695022深度学习中使用的batchsize, step(iteration), epoch 含义以及其关系发布于 2020-09-10 11:16:001.6K0举报            变量      含义                  epoch      一个epo...",
    "content": "Reference: https://cloud.tencent.com/developer/article/1695022深度学习中使用的batchsize, step(iteration), epoch 含义以及其关系发布于 2020-09-10 11:16:001.6K0举报            变量      含义                  epoch      一个epoch表示所有训练样本运算学习一遍              iteration/step      表示每运行一个iteration/step，更新一次参数权重，即进行一次学习，每一次更新参数需要batch size个样本进行运算学习，根据运算结果调整更新一次参数。              batch size      1次迭代所使用的样本量      其关系为：iteration=exampleNums∗epoch/batchsize举例： 假设有20000个样本，batch size 为200，epoch为1， 则iteration=20000∗1200=100"
  },
  
  {
    "title": "Input-Output Memory Management Unit",
    "url": "/posts/linux-iommu/",
    "categories": "linux, IOMMU",
    "tags": "IOMMU",
    "date": "2023-02-20 00:00:00 +0000",
    





    
    "snippet": "Intel IOMMU Introduction https://kernelgo.org/intel_iommu.htmlhttps://blog.csdn.net/21cnbao/article/details/106293976对于Intel的硬件辅助虚拟化方案而言核心的两大技术分别是VT-x和VT-d。 其中VT-x中主要引入了non-root模式(VMCS)以及EPT页表等技术，主...",
    "content": "Intel IOMMU Introduction https://kernelgo.org/intel_iommu.htmlhttps://blog.csdn.net/21cnbao/article/details/106293976对于Intel的硬件辅助虚拟化方案而言核心的两大技术分别是VT-x和VT-d。 其中VT-x中主要引入了non-root模式(VMCS)以及EPT页表等技术，主要关注于vCPU的虚拟化和内存虚拟化。 而VT-d的引入则是重点关注设备直通(passthrough)方面（即IO虚拟化）。VT-x中在non-root模式下，MMU直接使用EPT page table来完成GPA-&gt;HVA-&gt;HPA的两级翻译， VT-d中在non-root模式下，则由IOMMU来使用Context Table和IOMMU page table完成设备DMA请求过程中的HPA-&gt;HVA-&gt;GPA的翻译． 二者极为相似，唯一的不同之处在于CPU访问内存（直通设备IO Memory）是通过MMU查找EPT页表完成地址翻译， 而直通设备访问内存的请求则是通过IOMMU查找IOMMU页表来完成地址翻译的。本文重点来探索一下Intel IOMMU的工作机制。非根模式是Guest CPU的执行环境，根模式是Host CPU的执行环境  IOMMU - vt-d intel virtualization Technology for Directed I/O  ARMv8 Virtualization Overview https://kernelgo.org/armv8-virt-guide.htmlhttps://blog.csdn.net/21cnbao/article/details/105480147  以Intel的IOMMU来分析：一、虚拟地址1、虚拟地址空间：iova domainiommu probe时，初始化iova domain1&gt;初始化保留区域dmar_init_reserved_ranges 初始化reserved_iova_list 初始化保留的区域。detect_intel_iommu    |-&gt; pci_iommu_init    \t|-&gt;intel_iommu_init:5148    \t\t|-&gt;dmar_init_reserved_ranges    \t\t\t|-&gt;init_iova_domain &amp;reserved_iova_list  reserved_iova_list reserve部分，DMA不可用的地址下面两种range是需要保留的：1 IOAPIC 0xfee00000~0xfeefffff APIC的寄存器地址：0xfee000002 所有PCI设备的MMIO空间 IORESOURCE_MEM2&gt; 按iommu_group做iova domain申请domain_allocintel_iommu_init: 5187    |-&gt;probe_acpi_namespace_devices\t\t|-&gt;iommu_probe_device    \t\t|-&gt;iommu_alloc_default_domain    \t\t\t|-&gt;__iommu_domain_alloc    \t\t\t\t|-&gt; intel_iommu_domain_alloc / domain_alloc    \t\t\t\t\t|-&gt;intel_init_iova_domain if IOMMU_DOMAIN_DMA2、虚拟地址分配：1&gt; alloc_iova//dma_alloc dma_mapintel_dma_ops.map_page    |-&gt;intel_alloc_iova //if dev-&gt;dmamask &gt; 32, 先32bit以下,申请不到使用dev-&gt;dmamask     \t|-&gt;alloc_iova_fast        \t|-&gt;__iova_rcache_get //从rcache申请，fast路径    \t\t -&gt;alloc_iova if rcache not get //从iova_domian-&gt;rbroot中获取空闲在rbtree中查找合适的位置，赋值给IOVA，并将其插入到rbtree中。static int __alloc_and_insert_iova_range(struct iova_domain *iovad,\t\tunsigned long size, unsigned long limit_pfn,\t\t\tstruct iova *new, bool size_aligned){\t...\t/* Walk the tree backwards */\tspin_lock_irqsave(&amp;iovad-&gt;iova_rbtree_lock, flags);\t...\tcurr = __get_cached_rbnode(iovad, limit_pfn);\tcurr_iova = rb_entry(curr, struct iova, node);\tdo {\t\tlimit_pfn = min(limit_pfn, curr_iova-&gt;pfn_lo);\t\tnew_pfn = (limit_pfn - size) &amp; align_mask;\t\tprev = curr;\t\tcurr = rb_prev(curr);\t\tcurr_iova = rb_entry(curr, struct iova, node);\t} while (curr &amp;&amp; new_pfn &lt;= curr_iova-&gt;pfn_hi);\t...\t/* pfn_lo will point to size aligned address if size_aligned is set */\tnew-&gt;pfn_lo = new_pfn;\tnew-&gt;pfn_hi = new-&gt;pfn_lo + size - 1;\t/* If we have 'prev', it's a valid place to start the insertion. */\tiova_insert_rbtree(&amp;iovad-&gt;rbroot, new, prev);\t__cached_rbnode_insert_update(iovad, new);\t...}alloc_iova是最简单的分配机制，没有guard区域。申请的iova地址就是连续的。验证：static __init int test_module_init(void){        struct iova_domain *test_iovad;        struct iova *iova1, *iova2;        test_iovad = kmalloc(sizeof(struct iova_domain), GFP_KERNEL);        init_iova_domain(test_iovad, 1UL &lt;&lt; 12, 0);        iova1 = alloc_iova(test_iovad, 1UL &lt;&lt; 12, 1UL &lt;&lt; 32, 1UL &lt;&lt; 12);        iova2 = alloc_iova(test_iovad, 1UL &lt;&lt; 12, 1UL &lt;&lt; 32, 1UL &lt;&lt; 12);        printk(\"iova1 %lx %lx\\n\", iova1-&gt;pfn_lo, iova1-&gt;pfn_hi);        printk(\"iova2 %lx %lx\\n\", iova2-&gt;pfn_lo, iova2-&gt;pfn_hi);        __free_iova(test_iovad, iova1);        __free_iova(test_iovad, iova2);        kfree(test_iovad);        return 0;}[  110.267837] iova1 fffff000 ffffffff[  110.267838] iova2 ffffe000 ffffefff2&gt; free_iova//dma_unmapfree_iova_fast    |-&gt;iova_rcache_insert //can insert rcache? if true, insert and return;     -&gt; free_iova if can not insert rcache //从iova_domian-&gt;rbroot 删除对应项3&gt; split_and_remove_iova有功能实现，但无调用关系，也未导出。总结：1、虚拟地址空间      虚拟地址有不可用的空间，需要被预留        2、按照iommu_group分别独立虚拟地址空间  2、虚拟地址分配  rcache层做快速分配128K以下  rbtree记录已申请部分，进行分配一、疑问1、硬件无关的内存管理部分但有与具体功能(或者特殊限制等等因素)导致不同硬件存在差异怎么处理？  struct inte_iommu：iommu硬件在驱动层所对应的概念  struct iommu_group: 一个group下面可以对应多个或者一个硬件设备,使用相同的streamid  struct dmar_domain: dmar_domain里面存储的是iova-&gt;hpa的转换页表，一个dmar_domain可以为多个或者一个设备服务。  struct iommu_domain: 一个iommu_domain里面可以有多个iommu_group，然后每个iommu_group通过iommu_domain最终找到dmar_domain进行转换。二、逻辑映射iova_to_phys对于IOMMU的iova_to_phys是必要，驱动需要获取phys做访问。linux的实现都是遍历页表获取对应phys。1、SMMUarm_lpae_iova_to_physstruct iommu_ops arm_smmu_ops.iova_to_phys\t+-&gt; arm_smmu_iova_to_phys    \t+-&gt;struct io_pgtable_ops.iova_to_phys  //arm_lpae_alloc_pgtable函数installed            +-&gt;arm_lpae_iova_to_phys //在内存上做多级页表遍历，获取最后的phys2、intel IOMMU:struct iommu_ops intel_iommu_ops.iova_to_phys    +-&gt;intel_iommu_iova_to_phys    \t+-&gt;pfn_to_dma_pte //走页表，如果没有映射，分配页添加映射三、SMMU与Intel IOMMU的页表管理1、SMMU的页表：reference: SMMUv3_architecture_specification_IHI0070B3.13.5 HTTU with two stages of translationWhen two stages of translation exist, multiple TTDs determine the translation, that is the stage 1 TTD, the stage 2TTDs mapping all steps of the stage 1 walk, and finally the stage 2 TTD mapping the IPA output of stage 1.Therefore one access might result in several TTD updatesStage1和Stage2同时支持AArch32(LPAE: Large Page Address Extension) 显而易见：1&gt;SMMU/IOMMU的页表存在主存上2&gt;SMMU的页表级数为4级3&gt;支持page size:  IDR5_GRAN4K&lt;4K 2M 1G&gt;;  IDR5_GRAN16K&lt;16K 32M&gt;; IDR5_GRAN64K&lt;64k 512M&gt;Smmu的页表walk函数：arm_lpae_iova_to_physIO pagetable TLB flush函数：io_pgtable_tlb_flush_all、io_pgtable_tlb_add_flush、io_pgtable_tlb_sync1、map 页表SMMU的嵌套翻译：stage1 + stage2.TT - Translation table, synonymous with Page Table, as used by ARM architectureTTD - Translation table descriptor, synonymous with Page Table Entry, as used by the ARM architectureLPAE - Large Physical Address Extension//iommu_dma_ops  arm_smmu_opsio_pgtable_init_table     -&gt;io_pgtable_arm_64_lpae_s1_init_fns.alloc //arm_64_lpae_alloc_pgtable_s1 钩子1 硬件    \t-&gt;__arm_lpae_alloc_pages//cfg-&gt;arm_lpae_s1_cfg.ttbr[0] = virt_to_phys(data-&gt;pgd) //iommu_domain-&gt;ops-&gt;maparm_lpae_alloc_pgtable\t-&gt;data-&gt;iop.opsdma_map_single    -&gt; iommu_dma_ops.map_page// __iommu_dma_map 钩子2 DMA框架    \t-&gt;iommu_map    \t\t-&gt;iommu_domain-&gt;ops-&gt;map //arm_smmu_map 钩子3 IMMU框架\t\t\t\t-&gt;arm_lpae_map2、TLB flush函数arm64 SMMU: arm_smmu_flush_ops通过cmdQ发送TLBI命令，是对应的TLB无效化。可参考SMMU spec 4.4章节//io_pgtable_tlb_add_flushstatic void arm_smmu_tlb_inv_range_nosync(unsigned long iova, size_t size,\t\t\t\t\t  size_t granule, bool leaf, void *cookie) {    if (smmu_domain-&gt;stage == ARM_SMMU_DOMAIN_S1) {\t\tcmd.opcode\t= smmu-&gt;features &amp; ARM_SMMU_FEAT_E2H ?\t\t\t\t  CMDQ_OP_TLBI_EL2_VA : CMDQ_OP_TLBI_NH_VA;  \t\tcmd.tlbi.asid\t= smmu_domain-&gt;s1_cfg.cd0-&gt;tag;\t} else {\t\tcmd.opcode\t= CMDQ_OP_TLBI_S2_IPA;\t\tcmd.tlbi.vmid\t= smmu_domain-&gt;s2_cfg.vmid;\t}\tdo {\t\tarm_smmu_cmdq_issue_cmd(smmu, &amp;cmd); //cmd S1: TLBI命令\t\tcmd.tlbi.addr += granule;\t} while (size -= granule);}2、intel IOMMU:vt-directed-io-spec.pdf参考vt-directed-io-spec.pdf的第3.5章节： Hierarchical Translation StructuresIOMMU:1&gt; 支持4K 2M 1G的page size。1、map页表仅贴上4K，其他查看对应章节。4K table&lt;9 9 9 9 12&gt;intel_iommu_ops.map    -&gt;intel_iommu_map    \t-&gt;domain_mapping2、flush tlb      ASID-based IOTLB Invalidate Descriptor &lt;DID +  PASID + [start ] + [end]&gt;        Device-TLB Invalidate Descriptor &lt;Source-ID (SID) + [PASOID] + [start] + [end]&gt;    Source-ID (SID): The SID field indicates the source-id of the endpoint device whose Device-TLBneeds to be invalidated.        GLOBAL FLUSH &lt; DID&gt;  IOMMU刷新tlb：__iommu_flush_iotlb or dmar_enable_qi//__iommu_flush_iotlb \t\tcase DMA_TLB_GLOBAL_FLUSH:\t\t/* global flush doesn't need set IVA_REG */\t\tval = DMA_TLB_GLOBAL_FLUSH|DMA_TLB_IVT;\t\tbreak;\tcase DMA_TLB_DSI_FLUSH:\t\tval = DMA_TLB_DSI_FLUSH|DMA_TLB_IVT|DMA_TLB_DID(did);\t\tbreak;\tcase DMA_TLB_PSI_FLUSH:\t\tval = DMA_TLB_PSI_FLUSH|DMA_TLB_IVT|DMA_TLB_DID(did);\t\t/* IH bit is passed in as part of address */\t\tval_iva = size_order | addr;\t\tbreak;dmar_enable_qi支持按照地址和order来flush。嵌套翻译：stage 1和stage 2同时使用的嵌套翻译。3、amd iommu1 domain-&gt;id是怎么用的，为什么能在iotlb flush的时候用上。然后搞清楚kpi中要不要给pmap_create增加参数2 pmap_create在创建pmap时，应该增加一个自定义的参数，还是以gm_dev_create时增加的dev性质作为参考，不需要增加自定义的参数，即：以gm_dev_cap_t传入，还是架构上需要pmap_create时传入动态的自定义参数3 增加一个遗留问题，iommu的iotlb coalesced invl的技术需要探索分iommu address space来invlprotection_domain_initPDE： page directoryiommu_bus_notifier    -&gt;iommu_probe_devicebus_set_iommu    -&gt;iommu_bus_init\t\t-&gt;bus_iommu_probe    \t\t-&gt;probe_iommu_group//IOMMU_ENABLED -&gt;amd_iommu_init_pci1 -&gt; iommu_group_alloc_default_domain    -&gt;__iommu_domain_alloc2 -&gt; __iommu_attach_device     -&gt; set_dte_entry    \t-&gt;amd_iommu_dev_table&lt;变量&gt;//IOMMU_ACPI_FINISHED    -&gt; iommu_set_device_tableIOMMU_ACPI_FINISHED\t-&gt;IOMMU_ENABLED\tcase IOMMU_ACPI_FINISHED:\t\tearly_enable_iommus();\t\tx86_platform.iommu_shutdown = disable_iommus;\t\tinit_state = IOMMU_ENABLED;\t\tbreak;\tcase IOMMU_ENABLED:需要入参struct device + iommu_domain?dev_iommu_priv_setprobe_device\t-&gt;| iommu_init_device\t\t-&gt;| devid = get_device_id() 总线 + 设备功能号四、 ATSARM系列 – SMMU（二）PCIe地址转换服务（ATS）详解PCIe的ATS机制1、ATS机制想要解决的问题            ​      对于IO设备往CPU的数据流，其IOMMU/SMMU/VT-d的查表性能在整个IO性能中显得极为关键，查表性能的好坏至今影响IO性能的好坏；                  ​      能够分担主机（CPU）侧的查表压力，特别是大带宽、大拓扑下的IO数据流，CPU侧的IOMMU/SMMU/VT-d的查表将会成为性能瓶颈，而ATS机制正好可以提供将这些查表压力卸载到不同的设备中。      2、地址翻译过程1 PCIE Device首先通过本地ATC查找某页地址的转换，未成功则通过ATS发起针对页地址的translation request2 SMMU收到RC的地址转换请求，查找本地TLB，如果没有，硬件进行page table walk,若页表不存在或者页不在内存中，则需要返回translationfault给PCIE device.3 PCIE PRI 发起page request给RC，携带streamID,substreamID,地址等信息4 SMMU获得该信息后组成数据格式包放入PRI queue ，并产生中断通知CPU（OS）5 OS 内存管理子系统将缺页补上，即处理IO Page fault handling6 SMMU(RC)通过response告知device,发送page response,页处理完成，该内存页已经准备好，可进行DMA操作7 PCIE Device发起DMA操作五、昇腾SMMU和MMU共页表？PASID is an optional feature that enables sharing of a single Endpoint device across multiple processes while providing each process a complete 64-bit virtual address space. In practice, this feature adds support for a TLP prefix that contains a 20-bit address space that can be added to memory transaction TLPs.一、由AMD的SVA方案开始reference:IOMMU_TUTORIAL_ASPLOS_2016.pdf48882_IOMMU_3.05_PUB.pdfSharing AMD64 Processor and IOMMU Page Tables—GPA-to-SPAIf software requires 64-bit processor virtual addresses to be identical to I/O virtual addresses, including negative addresses, software needs to configure the IOMMU with the 6-level paging structure illustrated in Figure 13, where 4 extra 4-Kbyte page tables (shaded) at levels 6, 5, and 4 are used solely by the IOMMU, and sharing with processor page tables occurs only at levels 3 and below.二、推到社区的SVAreference：Shared Virtual Addressing for the IOMMUSVA mostly aims at simplifying DMA management.补丁列表：2017/11/17https://www.spinics.net/lists/kernel/msg2651481.htmlhttps://www.spinics.net/lists/arm-kernel/msg609771.htmlSharing process address spaces with devices allows to rely on core kernelmemory management for DMA, removing some complexity from application anddevice drivers. After binding to a device, applications can instruct it toperform DMA on buffers obtained with malloc.    The device, buses and the IOMMU must support the following features:* Multiple address spaces per device, for example using the PCI PASID  (Process Address Space ID) extension. The IOMMU driver allocates a  PASID and the device uses it in DMA transactions.    * I/O Page Faults (IOPF), for example PCI PRI (Page Request Interface) or  Arm SMMU stall. The core mm handles translation faults from the IOMMU.* MMU and IOMMU implement compatible page table formats.This series requires to support all three features. I tried tofacilitate using only a subset of them but enabling it requires morework. Upcoming patches will enable private PASID management, whichallows device driver to use an API similar to classical DMA,map()/unmap() on PASIDs. In the future device drivers should also beable to use SVA without IOPF by pinning all pages, or without PASID bysharing the single device address space with a process.Although we don't have any performance measurement at the moment, SVAwill likely be slower than classical DMA since it relies on page faults,whereas classical DMA pins all pages in memory. SVA mostly aims atsimplifying DMA management, but also improves security by isolatingaddress spaces in devices.Intel and AMD IOMMU drivers already offer slightly differing publicfunctions that bind process address spaces to devices. Because they don'tgo through an architecture-agnostic API, only integrated devices coulduse them so far.referecence: Linux SVA特性分析(未完)这个特性的补丁涉及到IOMMU, PCI, 内存管理(MM),SMMU, VFIO, 虚拟化，DT, ACPI等方面的修改，所以补丁比较分散sva.c     Hardware tables describing this configuration in the IOMMU would typically * look like this: * *                                PASID tables *                                 of domain A *                              .-&gt;+--------+ *                             / 0 |        |-------&gt; io_pgtable *                            /    +--------+ *            Device tables  /   1 |        |-------&gt; pgd X *              +--------+  /      +--------+ *      00:00.0 |      A |-'     2 |        |--. *              +--------+         +--------+   \\ *              :        :       3 |        |    \\ *              +--------+         +--------+     --&gt; pgd Y *      00:01.0 |      B |--.                    / *              +--------+   \\                  | *      00:01.1 |      B |----+   PASID tables  | *              +--------+     \\   of domain B  | *                              '-&gt;+--------+   | *                               0 |        |-- | --&gt; io_pgtable *                                 +--------+   | *                               1 |        |   | *                                 +--------+   | *                               2 |        |---' *                                 +--------+ *                               3 |        | *                                 +--------+ * * With this model, a single call binds all devices in a given domain to an * address space. Other devices in the domain will get the same bond implicitly. * However, users must issue one bind() for each device, because IOMMUs may * implement SVA differently. Furthermore, mandating one bind() per device * allows the driver to perform sanity-checks on device capabilities. * * On Arm and AMD IOMMUs, entry 0 of the PASID table can be used to hold * non-PASID translations. In this case PASID 0 is reserved and entry 0 points * to the io_pgtable base. On Intel IOMMU, the io_pgtable base would be held in * the device table and PASID 0 would be available to the allocator. */linux 4.19代码//sva.c__iommu_sva_bind_devicestruct device *dev, struct mm_struct *mm, int *pasid, unsigned long flags, void *drvdata    +-&gt;io_mm_alloc    \t+-&gt;iommu_ops.mm_alloc //arm_smmu_ops.mm_alloc = arm_smmu_mm_alloc    \t\t\t+-&gt;iommu_pasid_table_ops.alloc_shared_entry //    \t\t\t\t+-&gt;arm_smmu_alloc_shared_cd //cd-&gt;ttbr\t= virt_to_phys(mm-&gt;pgd); cd保存页表入口\t\t\t     -&gt;io_mm_attach    \t+-&gt;arm_smmu_mm_attach    \t\t+-&gt;ops-&gt;set_entry //arm_smmu_set_cd    \t\t\t+-&gt;arm_smmu_write_ctx_desc //将mm-&gt;pgd刷到对应pasid ttrb中     //至此device n的SMMU页表与进程A的MMU页表已经share，共同使用了    //后面都是通过pagefault调用handle_mm_fault来处理缺页流程。//sva.c 注册IOMMU page fault evt处理函数iommu_sva_device_init //iommu_register_device_fault_handler dev iommu_queue_iopf 注册设备的io page fault处理函数    //io-pgfault.c//处理evtiommu_queue_iopf    +1-&gt; list_add(fault, group)//等待将group的所有fault evt     2-&gt;INIT_WORK(work, iopf_handle_group) //初始化pgfault处理worker//fault处理workeriopf_handle_group    -&gt;iopf_handle_single for group-&gt;faults //对group fault遍历处理 //iopf_handle_single&gt; evt pgfault request: pasid addr perm权限1、mm = iommu_sva_find(pasid)： evt pgfault request的pasid -&gt; mm2、vma = find_extend_vma(mm, addr)3、handle_mm_fault(vma, prm-&gt;addr, fault_flags, NULL); //处理page faultlinux 5.10：//设备绑定进程iommu_sva_bind_device(struct device *dev, struct mm_struct *mm, void *drvdata)    +-&gt;iommu_group_do_bind_dev for group dev         +-&gt;intel_iommu_ops.sva_bind //intel_svm_bind        \t+-&gt;intel_svm_bind_mm        \t\t+1-&gt;intel_iommu_enable_pasid //1.使能pasid        \t\t 2-&gt;ioasid_alloc //申请pasid        \t\t 3-&gt;mmu_notifier_register //注册mmu通知链，处理页表变化支持flush操作        \t\t 4-&gt;intel_pasid_setup_first_level(iommu, dev, pgd, pasid, did, flags) //将进程pgd设置到pasid的第一级页表中//处理pagefaultinit_dmars //intel iommu probe    +-&gt;intel_svm_enable_prq //CONFIG_INTEL_IOMMU_SVM=y &amp;&amp; 支持pasid &amp;&amp; 支持 prs  page request support    \t+-&gt;thread_create(prq_event_thread) //dmar%d-prq内核线程处理iommu的page fault事件    \t\t+-&gt;1 ioasid_find(pasid) //从pasid获取svm    \t\t -&gt;2 find_extend_vma(svm-&gt;mm, addr) //从mm和addr获取vma    \t\t -&gt;3 handle_mm_fault(vma, addr,x, x)//处理pagefaultExtended Capability Register: 《vt-directed-io-spec.pdf 》11.4.3 Extended Capability Register"
  },
  
  {
    "title": "Kenrel autonuma",
    "url": "/posts/linux-autonuma/",
    "categories": "linux, autonuma",
    "tags": "autonuma",
    "date": "2023-02-03 00:00:00 +0000",
    





    
    "snippet": "https://lwn.net/ml/linux-kernel/20201027063217.211096-2-ying.huang@intel.com/解决快速内存和慢速内存共存场景下的内存使用问题：1、识别hot/cold页，将hot页迁移到快速内存2、快速内存内存紧张时，换出cold内存。",
    "content": "https://lwn.net/ml/linux-kernel/20201027063217.211096-2-ying.huang@intel.com/解决快速内存和慢速内存共存场景下的内存使用问题：1、识别hot/cold页，将hot页迁移到快速内存2、快速内存内存紧张时，换出cold内存。"
  },
  
  {
    "title": "Kernel Data Access Monitor",
    "url": "/posts/linux-damon/",
    "categories": "linux, damon",
    "tags": "damon",
    "date": "2023-01-31 00:00:00 +0000",
    





    
    "snippet": "DAMON：Linux Kernel官方的内存访问频次监控统计框架DAMON（Data Access MONitor）是linux kernel的内存访问频次监控统计框架。在5.15进入了Kernel主线，一直在迭代（去看看）。DAMON可以做虚拟内存和物理内存的访问监控，监控的结果是数据的访问频繁程度，可以通过回调函数（比如利用MADV），对冷热内存做很多内存优化的操作，包括冷内存的swa...",
    "content": "DAMON：Linux Kernel官方的内存访问频次监控统计框架DAMON（Data Access MONitor）是linux kernel的内存访问频次监控统计框架。在5.15进入了Kernel主线，一直在迭代（去看看）。DAMON可以做虚拟内存和物理内存的访问监控，监控的结果是数据的访问频繁程度，可以通过回调函数（比如利用MADV），对冷热内存做很多内存优化的操作，包括冷内存的swap out和将热页组织为大页等。虚拟内存监控和物理内存监控都是通过检查PTE的accessed bit来做访问监控的。虚拟内存监控，是直接访问目标虚拟地址空间的页表即可。物理内存则是，访问每个映射到目标物理地址空间的页表。检查和重置accessed bit可能对内存的回收和idle page track机制造成干扰，damon使用PG_idle 和 PG_young page 标志来避免。监控原理：1、基于region的采样#把一个完整的监控区域划分为小的region，region是多个内存页的集合。假设同一个region的页，访问频率是相同的（基于此，可以只统计大的region中一个页的access bit来代替整个region，达到减小扫描代价的目的）。基于这个假设，damon只需要检查任意一个PTE（页表项上的flags）的accessed bit，就可以确定一个region的访问频率。监控精度和开销是一对tradeoff。监控精度和开销主要通过设置采样间隔和结果聚合间隔来控制。每个采样间隔（sampling interval），damon会检查一次region的访问情况。每个聚合间隔（aggregation interval），damon汇总所有采样间隔结果。为了防止随着监控区域的增大，开销会无限制的增大。然而，damon采样的region数目是有最大最小值的（ minimum number of regions, and maximum number of regions），这样就很好的控制住了开销。2、自适应的region调整#随着系统的运行，不同数据的访问频繁模式是动态变化的，就需要自适应的调整region，包括分割和合并region。合并的是，那些聚合统计后，相邻region访问频繁模式差距小，就合并他们成一个更大的region。保证region数目不超过上限的前提下，在每次聚合统计清理标记时候，尝试分割一个region成两个到三个。3、基于VMA的虚拟地址监控#我们知道，虚拟地址空间大部分是没有映射的，监控这些unmap的区域完全是浪费。因此，damon应该自适应的去除这些未映射区域。基于这个原因，初始化的时候，damon利用VMA划分了三个大的region：堆、栈、mmap。不去监控两个大的gap（1、heap和mmap上界之间。2、mmap下界和stack之间。）为了应对程序运行过程中，动态的内存地址map和unmap。damon在每个regions update interval（一个可配置参数）之后重新初始化。进程虚拟地址空间：    &lt;heap&gt;    &lt;BIG UNMAPPED REGION 1&gt;    &lt;uppermost mmap()-ed region&gt;    (small mmap()-ed regions and munmap()-ed regions)    &lt;lowermost mmap()-ed region&gt;    &lt;BIG UNMAPPED REGION 2&gt;    &lt;stack&gt;一点看法#扫描页表项flag上的access bit是内存访问频次统计的通行做法，DAMON的主要贡献在于通过由region的自适应采样，把性能损耗降低到可以忽略不计。https://github.com/awslabs/damohttps://damonitor.github.io/doc/html/latest-damon/admin-guide/mm/damon/guide.htmlhttps://blog.csdn.net/zqh1630/article/details/109954910"
  },
  
  {
    "title": "Kernel Virtual Function I/O",
    "url": "/posts/linux-vfio/",
    "categories": "linux, VFIO",
    "tags": "VFIO",
    "date": "2022-12-13 00:00:00 +0000",
    





    
    "snippet": "一、vfioVirtual Function I/O (VFIO) 是一种现代化的设备直通方案，它充分利用了VT-d/AMD-Vi技术提供的DMA Remapping和Interrupt Remapping特性， 在保证直通设备的DMA安全性同时可以达到接近物理设备的I/O的性能。 用户态进程可以直接使用VFIO驱动直接访问硬件，并且由于整个过程是在IOMMU的保护下进行因此十分安全， 而且...",
    "content": "一、vfioVirtual Function I/O (VFIO) 是一种现代化的设备直通方案，它充分利用了VT-d/AMD-Vi技术提供的DMA Remapping和Interrupt Remapping特性， 在保证直通设备的DMA安全性同时可以达到接近物理设备的I/O的性能。 用户态进程可以直接使用VFIO驱动直接访问硬件，并且由于整个过程是在IOMMU的保护下进行因此十分安全， 而且非特权用户也是可以直接使用。 换句话说，VFIO是一套完整的用户态驱动(userspace driver)方案，因为它可以安全地把设备I/O、中断、DMA等能力呈现给用户空间。为了达到最高的IO性能，虚拟机就需要VFIO这种设备直通方式，因为它具有低延时、高带宽的特点，并且guest也能够直接使用设备的原生驱动。 这些优异的特点得益于VFIO对VT-d/AMD-Vi所提供的DMA Remapping和Interrupt Remapping机制的应用。 VFIO使用DMA Remapping为每个Domain建立独立的IOMMU Page Table将直通设备的DMA访问限制在Domain的地址空间之内保证了用户态DMA的安全性， 使用Interrupt Remapping来完成中断重映射和Interrupt Posting来达到中断隔离和中断直接投递的目的。在了解VFIO之前需要了解3个基本概念：device, group, container，它们在逻辑上的关系如上图所示。  Group 是IOMMU能够进行DMA隔离的最小硬件单元，一个group内可能只有一个device，也可能有多个device，这取决于物理平台上硬件的IOMMU拓扑结构。 设备直通的时候一个group里面的设备必须都直通给一个虚拟机。 不能够让一个group里的多个device分别从属于2个不同的VM，也不允许部分device在host上而另一部分被分配到guest里， 因为就这样一个guest中的device可以利用DMA攻击获取另外一个guest里的数据，就无法做到物理上的DMA隔离。 另外，VFIO中的group和iommu group可以认为是同一个概念。  Device 指的是我们要操作的硬件设备，不过这里的“设备”需要从IOMMU拓扑的角度去理解。如果该设备是一个硬件拓扑上独立的设备，那么它自己就构成一个iommu group。 如果这里是一个multi-function设备，那么它和其他的function一起组成一个iommu group，因为多个function设备在物理硬件上就是互联的， 他们可以互相访问对方的数据，所以必须放到一个group里隔离起来。值得一提的是，对于支持PCIe ACS特性的硬件设备，我们可以认为他们在物理上是互相隔离的。  Container 是一个和地址空间相关联的概念，这里可以简单把它理解为一个VM Domain的物理内存空间。从上图可以看出，一个或多个device从属于某个group，而一个或多个group又从属于一个container。 如果要将一个device直通给VM，那么先要找到这个设备从属的iommu group，然后将整个group加入到container中即可。+-------------------------------------------+|                                           ||             VFIO Interface                ||                                           |+---------------------+---------------------+|                     |                     ||     vfio_iommu      |      vfio_pci       ||                     |                     |+---------------------+---------------------+|                     |                     ||    iommu driver     |    pci_bus driver   ||                     |                     |+---------------------+---------------------+例子：vfio的样例：#include &lt;stdio.h&gt;#include &lt;unistd.h&gt;#include &lt;sys/types.h&gt;#include &lt;sys/stat.h&gt;#include &lt;fcntl.h&gt;#include &lt;linux/vfio.h&gt;#include &lt;sys/mman.h&gt;#include &lt;sys/ioctl.h&gt;#include &lt;string.h&gt;#include &lt;stdlib.h&gt;#define VFIO_PATH \"/dev/vfio/vfio\"#define DEVICE_ID \"0000:ba:00.0\" // BDF of the device taken over by vfio.static int vfio_get_group_num(const char *linkname, int *iommu_group_num){\tchar filename[256];\tchar *group_tok, *end;\tint ret;\tmemset(filename, 0, sizeof(filename));\tret = readlink(linkname, filename, sizeof(filename));\t/* if the link doesn't exist, no VFIO for us */\tif (ret &lt; 0)\t\treturn 0;\tprintf(\"%s\\n\", filename);\tend = strtok(filename, \"/\");\twhile (end != NULL) {\t\tgroup_tok = end;\t\tend = strtok(NULL, \"/\");\t}\t/* IOMMU group is always the last token */\t*iommu_group_num = strtol(group_tok, NULL, 10);\treturn 1;}int main(){\tint container, group, device, i;\tstruct vfio_group_status group_status =\t    {.argsz = sizeof(group_status) };\tstruct vfio_iommu_type1_info iommu_info = {.argsz = sizeof(iommu_info)\t};\tstruct vfio_iommu_type1_dma_map dma_map = {.argsz = sizeof(dma_map) };\tstruct vfio_device_info device_info = {.argsz = sizeof(device_info) };\tint ret;\t/* Create a new container */\tcontainer = open(\"/dev/vfio/vfio\", O_RDWR);\tif (container &lt; 0) {\t\tprintf(\"Error container.\\n\");\t\treturn -1;\t}\t/* Unknown API version */\tif (ioctl(container, VFIO_GET_API_VERSION) != VFIO_API_VERSION) {\t\tprintf(\"Error: Unknown VFIO API version.\\n\");\t\treturn -1;\t}\t/* Doesn't support the IOMMU driver we want. */\tif (!ioctl(container, VFIO_CHECK_EXTENSION, VFIO_TYPE1_IOMMU)) {\t\tprintf(\"Error: Doesn't support the IOMMU driver we want.\\n\");\t\treturn -1;\t}\t/* Get the device's group index *sys/bus/pci/devices/0000\\:60\\:00.0/iommu_group*/\tchar *sys_path = \"/sys/bus/pci/devices/\" DEVICE_ID \"/iommu_group\";\tint group_num;\tchar group_name[20];\tmemset(group_name, 0, sizeof(group_name));\tvfio_get_group_num(sys_path, &amp;group_num);\tprintf(\"group_num=%d\\n\", group_num);\tsnprintf(group_name, sizeof(group_name), \"/dev/vfio/%d\", group_num);\t/* Open the group */\tgroup = open(group_name, O_RDWR);\t/* Test the group is viable and available */\tioctl(group, VFIO_GROUP_GET_STATUS, &amp;group_status);\t/* Group is not viable (ie, not all devices bound for vfio) */\tif (!(group_status.flags &amp; VFIO_GROUP_FLAGS_VIABLE)) {\t\tprintf(\"Error: Group is not viable.\\n\");\t\treturn -1;\t}\t/* Add the group to the container */\tret = ioctl(group, VFIO_GROUP_SET_CONTAINER, &amp;container);\tif (ret &lt; 0) {\t\tprintf(\"Error: VFIO_GROUP_SET_CONTAINER.\\n\");\t\treturn -1;\t}\t/* Enable the IOMMU model we want */\tret = ioctl(container, VFIO_SET_IOMMU, VFIO_TYPE1_IOMMU);\tif (ret &lt; 0) {\t\tprintf(\"Error: VFIO_SET_IOMMU.\\n\");\t\treturn -1;\t}\t/* Get addition IOMMU info */\tret = ioctl(container, VFIO_IOMMU_GET_INFO, &amp;iommu_info);\tif (ret &lt; 0) {\t\tprintf(\"Error: VFIO_IOMMU_GET_INFO.\\n\");\t\treturn -1;\t}\tprintf\t    (\"iommu_info.flags=0x%x, iommu_info.iova_pgsizes=0x%lx\\n\",\t     iommu_info.flags, iommu_info.iova_pgsizes);\t/* Allocate some space and setup a DMA mapping */\tdma_map.vaddr =\t    (unsigned long long)mmap(0, 1024 * 1024, PROT_READ | PROT_WRITE,\t\t\t\t     MAP_PRIVATE | MAP_ANONYMOUS, 0, 0);\tdma_map.size = 1024 * 1024;\tdma_map.iova = 0;\t/* 1MB starting at 0x0 from device view */\tdma_map.flags = VFIO_DMA_MAP_FLAG_READ | VFIO_DMA_MAP_FLAG_WRITE;\tret = ioctl(container, VFIO_IOMMU_MAP_DMA, &amp;dma_map);\tif (ret &lt; 0) {\t\tprintf(\"Error: VFIO_IOMMU_MAP_DMA.\\n\");\t\treturn -1;\t}\t/* Get a file descriptor for the device */\tdevice = ioctl(group, VFIO_GROUP_GET_DEVICE_FD, DEVICE_ID);\tif (device &lt; 0) {\t\tprintf(\"Error: VFIO_GROUP_GET_DEVICE_FD.\\n\");\t\treturn -1;\t}\t/* Test and setup the device */\tret = ioctl(device, VFIO_DEVICE_GET_INFO, &amp;device_info);\tif (ret &lt; 0) {\t\tprintf(\"Error: VFIO_DEVICE_GET_INFO.\\n\");\t\treturn -1;\t}\tprintf\t    (\"device_info.flags=0x%x\\t, device_info.num_regions=0x%x\\t, device_info.num_irqs=0x%x\\n\",\t     device_info.flags, device_info.num_regions, device_info.num_irqs);\t/* index 0~5: bar space; can read/write/mmap\t * index 6  : rom space; \t * index 7  : config space; can read/write */\tfor (i = 0; i &lt; device_info.num_regions; i++) {\t\tstruct vfio_region_info reg = {.argsz = sizeof(reg) };\t\treg.index = i;\t\t/* Setup mappings... read/write offsets, mmaps\t\t * For PCI devices, config space is a region */\t\tret = ioctl(device, VFIO_DEVICE_GET_REGION_INFO, &amp;reg);#if 0\t\tif (ret &lt; 0) {\t\t\tprintf(\"Error: VFIO_DEVICE_GET_REGION_INFO.\\n\");\t\t\treturn -1;\t\t}#endif\t\tprintf\t\t    (\"index=%u, reg.flags=0x%x, cap_offset=0x%x, size=0x%lx\\n\",\t\t     reg.index, reg.flags, reg.cap_offset, reg.size);\t}\tfor (i = 0; i &lt; device_info.num_irqs; i++) {\t\tstruct vfio_irq_info irq = {.argsz = sizeof(irq) };\t\tirq.index = i;\t\tret = ioctl(device, VFIO_DEVICE_GET_IRQ_INFO, &amp;irq);\t\t/* Setup IRQs... eventfds, VFIO_DEVICE_SET_IRQS */\t\tif (ret &lt; 0) {\t\t\tprintf(\"Error: VFIO_DEVICE_GET_IRQ_INFO.\\n\");\t\t\treturn -1;\t\t}\t\tprintf(\"irq.flags=0x%x,irq.index=%u\\t, irq.count=%u\\n\", irq.flags, irq.index, irq.count);\t}\t/* Gratuitous device reset and go... */\tioctl(device, VFIO_DEVICE_RESET);}1、/dev/vfio/vfio  containerinsmod vfio.kostatic struct miscdevice vfio_dev = {\t.minor = VFIO_MINOR,\t.name = \"vfio\",\t.fops = &amp;vfio_fops,\t.nodename = \"vfio/vfio\",\t.mode = S_IRUGO | S_IWUGO,};static const struct file_operations vfio_fops = {\t.owner\t\t= THIS_MODULE,\t.open\t\t= vfio_fops_open,\t.release\t= vfio_fops_release,\t.read\t\t= vfio_fops_read,\t.write\t\t= vfio_fops_write,\t.unlocked_ioctl\t= vfio_fops_unl_ioctl,\t.compat_ioctl\t= compat_ptr_ioctl,\t.mmap\t\t= vfio_fops_mmap,};.open: struct vfio_container *container; filep-&gt;private_data = container; 申请个container;.read: container-&gt;iommu_driver-&gt;ops-&gt;read() vfio_iommu_driver的read, 需要VFIO_SET_IOMMU之后才有效.write: container-&gt;iommu_driver-&gt;ops-&gt;write() vfio_iommu_driver的write.ioctl: | VFIO_GET_API_VERSION： 查看版本信息        | VFIO_CHECK_EXTENSION： check是否支持VFIO_TYPE1_IOMMU        | VFIO_SET_IOMMU： 给container设置iommu操作        | default： driver-&gt;ops-&gt;ioctl(data, cmd, arg); 转到IOMMU的cmd操作list_for_each_entry(driver, &amp;vfio.iommu_drivers_list, vfio_next) {    if (driver-&gt;ops-&gt;ioctl(NULL, VFIO_CHECK_EXTENSION, arg) &lt;= 0) { //从注册到的iommu_drivers_list中的所有iommu驱动中，找到支持arg的类型的iommu\t\t\tmodule_put(driver-&gt;ops-&gt;owner);\t\t\tcontinue;\t\t}\t\tdata = driver-&gt;ops-&gt;open(arg);}  vfio iommu drivervfio_iommu_type1_init\t-&gt;vfio_register_iommu_driver(&amp;(vfio_iommu_driver_ops_type1.ops)); //为了VFIO_SET_IOMMUstatic const struct vfio_iommu_driver_compat_ops vfio_iommu_driver_ops_type1 = {\t.ops = {\t\t.name\t\t\t= \"vfio-iommu-type1\",\t\t.owner\t\t\t= THIS_MODULE,\t\t.open\t\t\t= vfio_iommu_type1_open,\t\t.release\t\t= vfio_iommu_type1_release,\t\t.ioctl\t\t\t= vfio_iommu_type1_ioctl,\t\t.attach_group\t\t= vfio_iommu_type1_attach_group,\t\t.detach_group\t\t= vfio_iommu_type1_detach_group,\t\t.pin_pages\t\t= vfio_iommu_type1_pin_pages,\t\t.unpin_pages\t\t= vfio_iommu_type1_unpin_pages,\t\t.register_notifier\t= vfio_iommu_type1_register_notifier,\t\t.unregister_notifier\t= vfio_iommu_type1_unregister_notifier,\t\t.dma_rw\t\t\t= vfio_iommu_type1_dma_rw,\t},\t.notify\t\t\t\t= vfio_iommu_type1_notify,};ioctl:\tswitch (cmd) { //除了VFIO_CHECK_EXTENSION之外，都能对应上iommu的ops\tcase VFIO_CHECK_EXTENSION: //支持哪些iommu driver type, 为了VFIO_SET_IOMMU来查看\tcase VFIO_IOMMU_GET_INFO: //获取iommu的信息\tcase VFIO_IOMMU_MAP_DMA: //dma映射\tcase VFIO_IOMMU_UNMAP_DMA://dma解映射\tcase VFIO_IOMMU_DIRTY_PAGES://支持iommu dirty\tcase VFIO_IOMMU_BIND: //支持iommu sva的bind\tcase VFIO_IOMMU_UNBIND: //支持iommu sva的unbind\tcase VFIO_IOMMU_SET_PASID_TABLE: //attach a pasid table\tcase VFIO_IOMMU_CACHE_INVALIDATE://invalidate translation caches\tcase VFIO_IOMMU_SET_MSI_BINDING: //provides a stage1 giova/gpa MSI doorbell mapping\tdefault:\t\treturn -ENOTTY;\t}2、/dev/vfio/$(iommu_group_id)//vfio_pci.cstatic const struct file_operations vfio_group_fops = {\t.owner\t\t= THIS_MODULE,\t.unlocked_ioctl\t= vfio_group_fops_unl_ioctl,\t.compat_ioctl\t= compat_ptr_ioctl,\t.open\t\t= vfio_group_fops_open,\t.release\t= vfio_group_fops_release,};vfio_group_fops_unl_ioctl:\tVFIO_GROUP_GET_STATUS: //获取group的状态，是否visable，有没有绑定container    VFIO_GROUP_SET_CONTAINER： //group绑定vfio container    VFIO_GROUP_UNSET_CONTAINER //group解绑定vfio container\tVFIO_GROUP_GET_DEVICE_FD //根据device id获取struct vfio_device的fd，可以操作device3、device fdvfio_pci_probe    -&gt;| vfio device-&gt;ops = ops; //vfio_pci_ops       vfio device-&gt;dev = dev; //pci struct device\t   vfio device-&gt;drvdata = vdev;        pci device-&gt;drvdata = vfio device;VFIO_GROUP_GET_DEVICE_FD //根据设备id match获得struct vfio_device    -&gt;|struct vfio_device    -&gt;|ret = vfio_device-&gt;ops-&gt;open(device-&gt;device_data); if (ret) return ret    -&gt;| if device-&gt;ops-&gt;open失败了，分配个不使用的fd，创建anon_inode文件，挂上vfio_device_fops的ops, return fd.\t//vfio_device_fops vs vfio_pci_ops    vfio_device_fops 执行vfio_device-&gt;ops-&gt;xxx = vfio_pci_opsvfio_pci_opsstatic const struct vfio_device_ops vfio_pci_ops = {\t.name\t\t= \"vfio-pci\",\t.open\t\t= vfio_pci_open,\t.release\t= vfio_pci_release,\t.ioctl\t\t= vfio_pci_ioctl,\t.read\t\t= vfio_pci_read,\t.write\t\t= vfio_pci_write,\t.mmap\t\t= vfio_pci_mmap,\t.request\t= vfio_pci_request,\t.match\t\t= vfio_pci_match,};ioctl:    VFIO_DEVICE_GET_INFO:    VFIO_DEVICE_GET_REGION_INFO: {        VFIO_PCI_CONFIG_REGION_INDEX        VFIO_PCI_BAR0_REGION_INDEX ... VFIO_PCI_BAR5_REGION_INDEX        VFIO_PCI_ROM_REGION_INDEX        VFIO_PCI_VGA_REGION_INDEX        }\tVFIO_DEVICE_GET_IRQ_INFO: {       \tVFIO_PCI_INTX_IRQ_INDEX,        VFIO_PCI_MSI_IRQ_INDEX,        VFIO_PCI_MSIX_IRQ_INDEX,        VFIO_PCI_ERR_IRQ_INDEX,        VFIO_PCI_REQ_IRQ_INDEX,     }\tVFIO_DEVICE_SET_IRQS:\tVFIO_DEVICE_RESET:\tVFIO_DEVICE_GET_PCI_HOT_RESET_INFO:        mmap:    request:二、设备透传实现在前面介绍VFIO的使用实例时，核心思想就是IOVA经过IOMMU映射出的物理地址与HVA经过MMU映射出的物理地址是同一个。对于设备透传的情况，先上图，然后看图说话。这段话可以慢慢理解一下先来分析一下设备的DMA透传的工作流程，一旦设备透传给了虚机，虚机在配置设备DMA时直接使用GPA。此时GPA经由EPT会映射成HPA1，GPA经由IOMMU映射的地址为HPA2，此时的HPA1和HPA2必须相等，设备的透传才有意义。下面介绍在配置IOMMU时如何保证HPA1和HPA2相等，在VFIO章节讲到了VFIO_IOMMU_MAP_DMA这个命令就是将iova通过IOMMU映射到vaddr对应的物理地址上去。对于IOMMU来讲，此时的GPA就是iova，我们知道GPA经由EPT会映射为HPA1，对于VMM来讲，这个HPA1对应的虚机地址为HVA，那样的话在传入VFIO_IOMMU_MAP_DMA命令时讲hva作为vaddr，IOMMU就会将GPA映射为HVA对应的物理地址及HPA1，即HPA1和HPA2相等。上述流程帮助理清整个映射关系，实际映射IOMMU的操作很简单，前面提到了qemu维护了GPA和HVA的关系，在映射IOMMU的时候也可以派上用场。注：IOMMU的映射在虚机启动时就已经建立好了，映射要涵盖整个GPA地址范围，同时虚机的HPA对应的物理页都不会交换出去（设备DMA交换是异步的）。reference:vfio概述(vfio/iommu/device passthrough)https://www.cnblogs.com/yi-mu-xi/p/12370626.htmlvfio直通介绍https://luohao-brian.gitbooks.io/interrupt-virtualization/content/vfio-she-bei-zhi-tong-jian-jie.htmlVFIO demohttps://blog.csdn.net/qq_42138566/article/details/127573967VFIO概述https://blog.csdn.net/hx_op/article/details/104029622VFIO(Virtual Function IO)研究https://blog.csdn.net/21cnbao/article/details/115683410Linux内核：VFIO 内核文档 (实例，API，bus驱动API)https://rtoax.blog.csdn.net/article/details/110845720内核文档: Documentation/driver-api/vfio.rsthttps://elixir.bootlin.com/linux/latest/source/Documentation/driver-api/vfio.rstMSI: message signal interrupt"
  },
  
  {
    "title": "linux Slab",
    "url": "/posts/linux-slab/",
    "categories": "linux, Slab",
    "tags": "Slab",
    "date": "2022-12-08 00:00:00 +0000",
    





    
    "snippet": "一、slabhttps://zhuanlan.zhihu.com/p/166649492 Linux内存管理：slub分配器https://www.jianshu.com/p/95d68389fbd1 slab分配器细节拉满，80 张图带你一步一步推演 slab 内存池的设计与实现https://segmentfault.com/a/1190000043626203  ​\t内核中的物理内存由...",
    "content": "一、slabhttps://zhuanlan.zhihu.com/p/166649492 Linux内存管理：slub分配器https://www.jianshu.com/p/95d68389fbd1 slab分配器细节拉满，80 张图带你一步一步推演 slab 内存池的设计与实现https://segmentfault.com/a/1190000043626203  ​\t内核中的物理内存由伙伴系统(buddy system)进行管理，它的分配粒度是以物理页帧(page)为单位的，但内核中有大量的数据结构只需要若干bytes的空间，倘若仍按页来分配，势必会造成大量的内存被浪费掉。slab分配器的出现就是为了解决内核中这些小块内存分配与管理的难题。slab分配器是基于buddy页分配器，在它上面实现了一层面向对象的缓存管理机制。1) 主要数据结构1 struct kmem_cachestruct kmem_cache {  \t  /*per-cpu变量，用来实现每个CPU上的slab缓存。好处如下：        1.促使cpu_slab-&gt;freelist可以无锁访问，避免了竞争，提升分配速度        2.使得本地cpu缓存中分配出的objects被同一cpu访问，提升TLB对object的命中率        (因为一个page中有多个object，他们共用同一个PTE)        */        struct kmem_cache_cpu __percpu *cpu_slab;        slab_flags_t flags;        /* 下面这些是初始化kmem_cache时会设置的一些变量         分配时会用到的flags */        unsigned long min_partial;/*kmem_cache_shrink缩减partial slabs时，        将被保有slab的最小值。set_min_partial(s, ilog2(s-&gt;size)/2)设置。*/        unsigned int size; /*object的实际大小，包含元数据和对齐的空间*/        unsigned int object_size;\t/*object中payload的大小，即目标数据结构的实际大小*/        unsigned int offset;/*每个free object中都存了next free object的地址，但是并未        存储在object的首地址，而是首地址加上offset的地方*/        struct kmem_cache_order_objects oo; /*此结构体实际是个unsigned int,         page_order &lt;&lt; 16 || slab_object_num &amp; 0xFFFF */        /* Allocation and freeing of slabs */        struct kmem_cache_order_objects max;        struct kmem_cache_order_objects min;        gfp_t allocflags;       /* gfp flags to use on each alloc 标准gfp掩码，        用于从buddy分配页面时 */        int refcount;           /* Refcount for slab cache destroy */        void (*ctor)(void *); \t/*object的构造函数，通常不使用*/        unsigned int inuse;    \t/*object中到metadata的偏移*/        unsigned int align;    \t/*对齐大小。澄清：slab中对齐方式通常有两种。        1是按处理器字长对齐;2是按照cacheline大小对齐。*/        unsigned int red_left_pad;      /* Left redzone padding size         若flags中使用REDZONE时有意义*/    \tconst char *name;/*对象名称，例：mm_struct task_struct*/    \tstruct list_head list; \t/*kmem_cache的链表结构，通过此成员串在slab_caches链表上*/\t\t/*下面两个成员用于表示对象内部的一块空间，使userspace可以访问其中的内容。具体可以看kmem_cache_create_usercopy的实现*/        unsigned int useroffset;   /* 类似offsetof(struct ext4_inode_info, i_data), ext4_inode_info-&gt;i_data用户态可访问 */        unsigned int usersize;    /* sizeof_field(struct ext4_inode_info, i_data) */        struct kmem_cache_node *node[MAX_NUMNODES];\t/*每个node对应一个数组项，kmem_cache_node中包含partial slab链表*/};struct kmem_cache_cpu {        void **freelist;      /*指向下面page指向的slab中的第一个free object*/    \t/* Globally unique transaction id */        unsigned long tid;              struct page *page; /*指向当前正在使用的slab*/             struct page *partial; /*本地slab缓存池中的partial slab链表*/};struct kmem_cache_node {        spinlock_t list_lock;   \t/*kmem_cache_node数据结构的自选锁，可能涉及到多核访问*/        unsigned long nr_partial;    \t/*node中slab的数量*/        struct list_head partial;    \t/*指向partial slab链表*/};crash&gt; struct kmem_cache -x ffff8001f8e80800struct kmem_cache {  cpu_slab = 0xfffefdfe40f4d3d0,   flags = 0x40002000,   min_partial = 0x5,   size = 0x680,   object_size = 0x640,   offset = 0x640,   cpu_partial = 0x6,   oo = {    x = 0x30013  },   max = {    x = 0x30013  },   min = {    x = 0x2  },   allocflags = 0x4000,   refcount = 0x1,   ctor = 0xffff000000aba000,   inuse = 0x640,   align = 0x40,   red_left_pad = 0x0,   name = 0xffff8001facd7d00 \"slab_test_cachep\",   list = {    next = 0xffff8000fee71260,     prev = 0xffff000081308bb0 &lt;slab_caches&gt;  },   kobj = {    name = 0xffff8001facd7c00 \"slab_test_cachep\",     entry = {      next = 0xffff8000fc8ba800,       prev = 0xffff8000fee71278    },     parent = 0xffff8000fc8ba818,     kset = 0xffff8000fc8ba800,     ktype = 0xffff000081311898 &lt;slab_ktype&gt;,     sd = 0xffff8001f94cba18,     kref = {      refcount = {        refs = {          counter = 0x1        }      }    },     state_initialized = 0x1,     state_in_sysfs = 0x1,     state_add_uevent_sent = 0x1,     state_remove_uevent_sent = 0x0,     uevent_suppress = 0x0,     kabi_reserved1 = 0x0,     kabi_reserved2 = 0x0,     kabi_reserved3 = 0x0,     kabi_reserved4 = 0x0  },   kobj_remove_work = {    data = {      counter = 0xfffffffe0    },     entry = {      next = 0xffff8001f8e808d8,       prev = 0xffff8001f8e808d8    },     func = 0xffff00008033f4d8 &lt;sysfs_slab_remove_workfn&gt;,     kabi_reserved1 = 0x0,     kabi_reserved2 = 0x0,     kabi_reserved3 = 0x0,     kabi_reserved4 = 0x0  },   memcg_params = {    root_cache = 0x0,     {      {        memcg_caches = 0x0,         __root_caches_node = {          next = 0xffff8000fee71320,           prev = 0xffff000081308ba0 &lt;slab_root_caches&gt;        },         children = {          next = 0xffff8001f8e80930,           prev = 0xffff8001f8e80930        },         dying = 0x0      },       {        memcg = 0x0,         children_node = {          next = 0xffff8000fee71320,           prev = 0xffff000081308ba0 &lt;slab_root_caches&gt;        },         kmem_caches_node = {          next = 0xffff8001f8e80930,           prev = 0xffff8001f8e80930        },         deact_fn = 0x0,         {          deact_rcu_head = {            next = 0x0,             func = 0x0          },           deact_work = {            data = {              counter = 0x0            },             entry = {              next = 0x0,               prev = 0x0            },             func = 0x0,             kabi_reserved1 = 0x0,             kabi_reserved2 = 0x0,             kabi_reserved3 = 0x0,             kabi_reserved4 = 0x0          }        }      }    }  },   max_attr_size = 0x0,   memcg_kset = 0x0,   remote_node_defrag_ratio = 0x3e8,   random_seq = 0xffff8001facd7800,   useroffset = 0x0,   usersize = 0x0,   node = {0xffff8000fbaab180, 0xffff8001fb802580, 0xffffffffffffffff, 0xffffffffffffffff, 0xffffffffffffffff, 0xffffffffffffffff, 0xffffffffffffffff, 0xffffffffffffffff, 0xffffffffffffffff, 0xffffffffffffffff, 0xffff000080f980a0, 0x400c0000, 0x5, 0x8000000088, 0x1e00000080, 0x1e0000001e}}PS:每个物理页都对应一个struct page结构体，结构体中有个联合体，其中定义了一些slab分配器要用到的成员。若该page用于slab，则下面成员将生效并被使用，代码如下。需要注意的是这里也有个freelist，它指向所属slab的第一个free object, 不能和kmem_cache中freelist混淆。2) 常用函数1 kmem_cache_create创建一个缓存管理描述符kmem_cache;*name是一個字符串，存放kmem_cache緩存的名字；size是緩存所存放的對象的大小；align是slab內第一個對象的偏移；flag是可選的配置項，用來控制緩存的行爲。最後一個參數ctor是對象的構造函數，一般是不需要的，以NULL來代替。kmem_cache_create()成功執行之後會返回一個指向所創建的緩存的指針，否則返回NULL。kmem_cache_create()可能會引起阻塞（睡眠），因此不能在中斷上下文中使用。crash&gt; kmem -s slab_test_cachepCACHE             OBJSIZE  ALLOCATED     TOTAL  SLABS  SSIZE  NAMEffff8001fb843600     1600          0         0      0    32k  slab_test_cachep2 kmem_cache_alloc申请object//1个slabs,申请8x4K, 1个slab有19个object， 目前被申请走2个， object的真实大小为1600bytes.crash&gt; kmem -s slab_test_cachepCACHE             OBJSIZE  ALLOCATED     TOTAL  SLABS  SSIZE  NAMEffff8001f8e80800     1600          2        19      1    32k  slab_test_cachepobject的分配通过kmem_cache_alloc()接口，实际分配object的过程会存在以下几种情形：1&gt; fast path即可直接从本地cpu缓存中的freelist拿到可用objectkmem_cache_alloc  slab_alloc    slab_alloc_node      --&gt;object = c-&gt;freelist                                  //本地cpu缓存的freelist有可用的object      --&gt;void *next_object=get_freepointer_safe(s, object);    //获取next object的地址，用于后面更新freelist      --&gt;this_cpu_cmpxchg_double                               //更新cpu_slab-&gt;freelist和cpu_slab-&gt;tid      --&gt;prefetch_freepointer(s, next_object);                 //优化语句，将next object的地址放入cacheline，提高后面用到时的命中率      --&gt;stat(s, ALLOC_FASTPATH);                              //设置状态为ALLOC_FASTPATH2&gt; slow path本地cpu缓存中的freelist为NULL，但本地cpu缓存中的partial中有未满的slabkmem_cache_alloc  slab_alloc    slab_alloc_node      __slab_alloc                                                                //分配过程关闭了本地中断        ___slab_alloc          --&gt;page = c-&gt;page为NULL的情况下                 //即本地cpu缓存中当前在使用的slab的free object已经分完          --&gt;goto new_slab;                             //跳转到new_slab，从本地缓存池的partial取一个slab赋给page，并跳转到redo          --&gt;freelist = get_freelist(s, page)           //获取page中的freelist(注意：此freelist为strcut page中的，并非本地cpu缓存的freelist)          --&gt;c-&gt;freelist = get_freepointer(s, freelist) //将freelist重新赋给kmem_cache_cpu中的freelist     3&gt; very slow path本地cpu缓存中的freelist为NULL，且本地cpu缓存中的partial也无slab可用。kmem_cache_alloc  slab_alloc    slab_alloc_node      __slab_alloc         //分配过程关闭了本地中断        ___slab_alloc          --&gt;page = c-&gt;page为NULL的情况下  //即本地cpu缓存中当前在使用的slab的free object已经分完                                      --&gt;goto new_slab;   //跳转到new_slab，通过slub_percpu_partial(c)检查到本地cpu缓存池中partial无slab可用。          --&gt;freelist = new_slab_objects(s, gfpflags, node, &amp;c); //此函数中会出现两种情况：情况           //1.当前node对应的kmem_cache_node中有可用partial slab，并从中获取slab分给本地cpu缓冲池。          // 情况2.当前node对应的kmem_cache_node无可用的partial slab,过new_slab-&gt;allocate_slab-&gt;alloc_slab_page-&gt;alloc_pages从buddy分配器申请内存并创建新的 slab。两种情况最终都会返回一个可用的freelist          --&gt;c-&gt;freelist = get_freepointer(s, freelist)  //将freelist重新赋给kmem_cache_cpu中的freelist 3 kmem_cache_free释放object4 kmem_cache_destory销毁kmem_cache調用kmem_cache_destroy()之前應該滿足下面幾個條件：首先，cachep所指向的緩存中所有slab都爲空閒，否則的話是不可以撤銷的；其次在調用kmem_cache_destroy()過程中以及調用之後，調用者需要確保不會再訪問這個緩存；最後，該函數也可能會引起阻塞，因此不能在中斷上下文中使用。二、slab_debug/straceReference:http://www.wowotech.net/memory_management/427.html SLUB DEBUG机制1 slab_debug机制CONFIG_SLUB=yCONFIG_SLUB_DEBUG=yCONFIG_SLUB_DEBUG_ON=ySLUB内存检测功能在某些情况下不能立刻检测出来，必须主动触发，因此我们需要借助slabinfo命令触发SLUB allocator检测功能.CONFIG_SLUB_DEBUG_ON:kmem_cache的flag = SLAB_CONSISTENCY_CHECKS | SLAB_RED_ZONE|SLAB_POISON | SLAB_STORE_USERSLUBU DEBUG关闭的情况下, free pointer是内嵌在object之中的, 但是SLUB DEBUG打开之后, free pointer是在object, 将FP后移就是因为为了检测use-after-free问题, 当free object时会在将object填充magic num(0x6b)。如果不后移的话，岂不是破坏了object之间的单链表关系。#define SLUB_RED_INACTIVE   0xbb#define SLUB_RED_ACTIVE     0xcc/* ...and for poisoning */#define POISON_INUSE         0x5a    /* for use-uninitialised poisoning */#define POISON_FREE          0x6b    /* for use-after-free poisoning */#define POISON_END           0xa5    /* end-byte of poisoning */2 slab debug使用Reference:http://linuxperf.com/?p=184 如何诊断SLUB问题https://blog.csdn.net/thwack/article/details/79865758  slab_trace1)  slab trace1&gt;观察slabinfo启动后记录下slabinfo。运行一段时间，再观察slabinfo。找到增长比较大的slab。cat /proc/slabinfo2&gt;打开slab traceecho 1 &gt; /sys/kernel/slab/&lt;leaking_slab&gt;/tracesleep 60echo 0 &gt; /sys/kernel/slab/&lt;leaking_slab&gt;/trace3&gt;   3) 打开以后slab trace会向console打印。串口/dmesg日志输出如果console是串口的话很有可能把系统打的无响应。最好写一个脚本。运行一段时间后关闭slab[ 2144.128477] INFO: Slab 0x000000004afbdf16 objects=19 used=1 fp=0x00000000e8006aea flags=0x7ffff0000008100[ 2144.128483] CPU: 3 PID: 31658 Comm: rmmod Tainted: G    B      OE     4.19.90-vhulk2103.1.0.h469.eulerosv2r10.aarch64 #1[ 2144.128485] Hardware name: QEMU KVM Virtual Machine, BIOS 0.0.0 02/06/2015[ 2144.128487] Call trace:[ 2144.128496]  dump_backtrace+0x0/0x198[ 2144.128499]  show_stack+0x24/0x30[ 2144.128504]  dump_stack+0xb0/0x100[ 2144.128510]  slab_err+0xc0/0xe8[ 2144.128513]  __kmem_cache_shutdown+0x1c0/0x408[ 2144.128517]  shutdown_cache+0x20/0x1d8[ 2144.128519]  kmem_cache_destroy+0x26c/0x2e0[ 2144.128527]  kmem_cache_create_exit+0x14/0xfd8 [kmem_create][ 2144.128532]  __arm64_sys_delete_module+0x1a4/0x2b8[ 2144.128535]  el0_svc_common+0x80/0x1c0[ 2144.128538]  el0_svc_handler+0x78/0xe0[ 2144.128541]  el0_svc+0x10/0x260[ 2144.128546] INFO: Object 0x0000000076a78344 @offset=4992[ 2144.128549] kmem_cache_destroy slab_test_cachep: Slab cache still has objects2) slab debug3) slab merge三、kmemleak"
  },
  
  {
    "title": "The Kernel Memory Sanitizer (KMSAN)",
    "url": "/posts/linux-kmsan/",
    "categories": "linux, KMSAN",
    "tags": "KMSAN",
    "date": "2022-12-08 00:00:00 +0000",
    





    
    "snippet": "一、kmsanhttps://github.com/google/kmsan/blob/master/Documentation/dev-tools/kmsan.rstKMSAN is a dynamic error detector aimed at finding uses of uninitialized values. It is based on compiler instrume...",
    "content": "一、kmsanhttps://github.com/google/kmsan/blob/master/Documentation/dev-tools/kmsan.rstKMSAN is a dynamic error detector aimed at finding uses of uninitialized values. It is based on compiler instrumentation, and is quite similar to the userspace MemorySanitizer tool.An important note is that KMSAN is not intended for production use, because it drastically increases kernel memory footprint and slows the whole system down.1、插桩 __no_kmsan_checks2、 metadata  shadow byteLinux 内核的 KMSAN 补丁，有助于捕获未初始化的内存问题  One of the Linux patch series that has been in the works for years in conjunction with Clang compiler side changes and already being responsible for exposing hundreds of kernel bugs is the KernelMemorySanitizer (KMSAN). Sent out today was the latest patch series working on the kernel infrastructure for catching uninitialized memory issues.KernelMemorySanitizer (KMSAN) 这个补丁已经开发了好几年了，这个补丁配合 Clang 编译器端的修改，而 Clang KMSAN 代码可以追溯到 2018 年。虽然该补丁还未被合入主线，但在两者相互配合下，已经帮助我们找出了内核中数百个错误。26 日来自 Google 的 Alexander Potapenko，也是 KMSAN 补丁的作者，又发布了一个新的版本，可以用于捕获未初始化的内存问题。Potapenko 指出， \"KMSAN has reported more than 300 bugs in the past few years, most of them with the help of syzkaller. Such bugs keep getting introduced into the kernel despite new compiler warnings and other analyses (the 5.16 cycle already resulted in several KMSAN-reported bugs). Mitigations like total stack and heap initialization are unfortunately very far from being deployable. The proposed patchset contains KMSAN runtime implementation together with small changes to other subsystems needed to make KMSAN work.\"。KMSAN 在过去几年中报告了 300 多个错误，其中大多数是在 syzkaller 的帮助下。尽管有新的编译器警告和其他分析支持，但针对栈和堆初始化的检测还未支持。这次新提交的补丁包含 KMSAN 运行时的实现以及对其他子系统的小改动。这包括了超过四千行新代码。对 KernelMemorySanitizer 感兴趣的人可以阅读 Alexander Potapenko 的这个 2020 年的 PDF slids（https://clangbuiltlinux.github.io/CBL-meetup-2020-slides/glider/Fighting_uninitialized_memory_%40_CBL_Meetup_2020.pdf）更多介绍请阅读新闻出处，“KMSAN Patches For The Linux Kernel Updated For Catching Uninitialized Memory Problems”: https://www.phoronix.com/scan.php?page=news_item&amp;px=KernelMemorySanitizer-2022。"
  },
  
  {
    "title": "Kernel Electric Fence (kfence)",
    "url": "/posts/linux-kfence/",
    "categories": "linux, kfence",
    "tags": "kfence",
    "date": "2022-12-07 00:00:00 +0000",
    





    
    "snippet": "一、kfenceKfence (Kernel Electric Fence) 是 Linux 内核引入的一种低开销的内存错误检测机制，因为是低开销的所以它可以在运行的生产环境中开启，同样由于是低开销所以它的功能相比较 Kasan 会偏弱。Kfence 的基本原理非常简单，它创建了自己的专有检测内存池 kfence_pool。在 data page 的两边加上了 fence page 电子栅栏...",
    "content": "一、kfenceKfence (Kernel Electric Fence) 是 Linux 内核引入的一种低开销的内存错误检测机制，因为是低开销的所以它可以在运行的生产环境中开启，同样由于是低开销所以它的功能相比较 Kasan 会偏弱。Kfence 的基本原理非常简单，它创建了自己的专有检测内存池 kfence_pool。在 data page 的两边加上了 fence page 电子栅栏，利用 MMU 的特性把 fence page 设置成不可访问。如果对 data page 的访问越过了 page 边界， 就会立刻触发异常。Kfence 的主要特点如下：            item      Kfence      Kasan                  检测密度      抽样法，默认每 100ms 提供一个可检测的内存      对所有内存访问进行检测              检测粒度      核心的检测粒度为 page      检测粒度为字节      Kernel Electric-Fence (KFENCE)是5.12版本内核新引入的内存使用错误检测机制。它可以检查的错误有：  内存访问越界  释放后使用  无效释放显然，它可以检测的内存错误类型不如KASAN多。但与KASAN相比，它最大的优势是运行时小Overhead，可以直接用在生产环境中。因此在X86，ARM64，RISCV等平台上均默认开启。  在Arch对应的defconfig中使用CONFIG_HAVE_ARCH_KFENCE开启。架构及原理Kfence的原理比较简单，如下图：初始化  初始化过程中，KFENCE向Memblock申请一段内存，作为KFENCE内存池。  这个内存池的大小配置为CONFIG_KFENCE_NUM_OBJECTS  即，预留两个页面作为保护页（Guard Page），接着为每一个用于分配的内存页分配一个Guard Page。因此总大小为：#define KFENCE_POOL_SIZE ((CONFIG_KFENCE_NUM_OBJECTS + 1) * 2 * PAGE_SIZE)  初始化一个Delayed Worker，定期（CONFIG_KFENCE_SAMPLE_INTEVAL）重置kfence_alloc_gate值为0。  这个值可以通过sysfs修改分配  kfence_alloc_gate值为0时，使用kmem_cache_alloc所作的内存分配从KFENCE内存池中分配，并增加kfence_alloc_gate的值。kfence_alloc_gate值大于等于1时，直接从SLUB中分配。由此可以看出，kfence是基于采样的内存检测。  大于一个Page(4K)的分配不会从KFENCE Pool中分配  每次通过KFENCE进行内存分配时，都会从KFENCE内存池分配一个内存页和一个Guard Page，并在实际使用内存的两端内存填充Canary数据。  解释一下为什么保护数据叫Canary。这是因为在19世纪，金丝雀在采矿业中常用的毒气检测方法，因为它们比人类对毒气更为敏感反应也更快。  如果KFENCE内存池中没有可用内存，则直接从SLAB中分配。释放  释放时，检查Canary数据，将所用内存放回KFENCE内存池。检测报错在以下情况，会检测报错：  释放时发现Canary数据不对。  当KFENCE内存池的内存区域发生Page Fault时，它或者是因为越界访问、或者是释放后使用。  无效释放：当一段KFENCE内存没有被标记分配，但对齐释放时，会有相应报错提示。总结开源社区总能带来新的idea。KFENCE，克服了KASAN等工具需要占用大量内存且影响运行时性能的缺点，是一个有效地运行时内存访问错误检测工具。当然，因为它所针对的内存区域仅仅是KFENCE内存池，且其是周期性进行采样，检测效果还不得而知。其又有可以动态开关、参数可调节等优点，这些劣势或许也不是问题。后续若有时间可以研究分析对比其和KASAN的检测效果。"
  },
  
  {
    "title": "The Kernel Address Sanitizer (KASAN)",
    "url": "/posts/linux-kasan/",
    "categories": "linux, KASAN",
    "tags": "KASAN",
    "date": "2022-12-06 00:00:00 +0000",
    





    
    "snippet": "Reference:https://cloud.tencent.com/developer/article/1381068  KASAN实现原理一、KASAN概念KASAN是一个动态检测内存错误的工具。KASAN可以\t。功能比SLUB DEBUG齐全并且支持实时检测。CONFIG_SLUB_DEBUG=yCONFIG_KASAN=y二、KASAN检测机制在代码运行时，每一次memory ac...",
    "content": "Reference:https://cloud.tencent.com/developer/article/1381068  KASAN实现原理一、KASAN概念KASAN是一个动态检测内存错误的工具。KASAN可以\t。功能比SLUB DEBUG齐全并且支持实时检测。CONFIG_SLUB_DEBUG=yCONFIG_KASAN=y二、KASAN检测机制在代码运行时，每一次memory access都会检测对应的shawdow memory的值是否valid。这就需要编译器为我们做些工作。编译的时候，在每一次memory access前编译器会帮我们插入__asan_load##size()或者__asan_store##size()函数调用（size是访问内存字节的数量）。这也是要求更新版本gcc的原因，只有更新的版本才支持自动插入。mov x0, #0x5678movk x0, #0x1234, lsl #16movk x0, #0x8000, lsl #32movk x0, #0xffff, lsl #48mov w1, #0x5bl __asan_store1 //对x0进行checkstrb w1, [x0]1)如何根据shadow memory的值判断内存访问操作是否valid？__asan_load1/2/4/8/16  __asan_store1/2/4/8/16    -&gt;|check_memory_region_inline //write=false/truecheck_memory_region_inline    -&gt; addr &lt; kasan_shadow_start? kasan_report : continue;    -&gt; memory_is_poisoned(addr, size) ? kasan_report: return;static __always_inline bool memory_is_poisoned(unsigned long addr, size_t size){    if (__builtin_constant_p(size)) { // 判断一个值是否为编译时常量        switch (size) {        case 1:            return memory_is_poisoned_1(addr);        case 2:        case 4:        case 8:            return memory_is_poisoned_2_4_8(addr, size);        case 16:             return memory_is_poisoned_16(addr);        default:            BUILD_BUG();        }       }       return memory_is_poisoned_n(addr, size);  //编译时非常量}static __always_inline bool memory_is_poisoned_n(unsigned long addr, size_t size){    unsigned long ret;    ret = memory_is_nonzero(kasan_mem_to_shadow((void *)addr), kasan_mem_to_shadow((void *)addr + size - 1) + 1);    if (unlikely(ret)) {        unsigned long last_byte = addr + size - 1;        s8 *last_shadow = (s8 *)kasan_mem_to_shadow((void *)last_byte);        //KASAN_SHADOW_MASK = 2^KASAN_SHADOW_SCALE_SHIFT(3) - 1 = 7        //1. 前面整8bytes非全0， 不可访问，直接true， report        //2. if (*shadow &amp;&amp; *shadow &lt; ((unsigned long)addr &amp; 7) + N); //N = 1, 校验最后1bytes是否可访问？ true repore        if (unlikely(ret != (unsigned long)last_shadow ||            ((long)(last_byte &amp; KASAN_SHADOW_MASK) &gt;= *last_shadow)))            return true;    }    return false;}memory_is_poisoned_16    -&gt; addr aligned 8 ? *(u16*)shadow_addr ： (*shadow_addr || memory_is_poisoned_1(addr + 15)) //addr 8对齐，2个shadow memory。不对齐，3个shadow memory      memory_is_poisoned_2_4_8      -&gt; (addr + size - 1)&amp;KASAN_SHADOW_MASK &gt;= size - 1 ? memory_is_poisoned_1(addr + size - 1) : *shadow_addr || memory_is_poisoned_1(addr + size - 1) // 如果end_addr &amp; 7 &gt; size, 说明不跨shadow memory.      memory_is_poisoned_1    -&gt;shadow_value ?  (addr&amp;KASAN_SHADOW_MASK &gt; shadow_value) : false //shadow_value = 0, ok; shadow_memory &lt; addr&amp;KASAN_SHADOW_MASK, report; 当前free的小于 addr的地址, 表明该地址used状态，不能load/store, kasan_report2) shadow memory内存如何分配？1 arm64虚拟地址布局VA_BITS配置成48。那么kernel space空间大小是256TB，因此shadow memory的内存需要32TB。我们需要在虚拟地址空间为KASAN shadow memory分配地址空间.2 如何建立shadow memory的映射关系shadow_addr = (kaddr &gt;&gt; 3) + KASAN_SHADOW_OFFSE  (KASAN_SHADOW_OFFSET=0xdfff200000000000)3) 伙伴系统shadow memory填充什么数据检查?1 伙伴系统alloc后填充0伙伴系统alloc后填充0,表明该区域可读写。2 伙伴系统free#define KASAN_FREE_PAGE         0xFF  /* page was freed */伙伴系统free后填充ff,表明该区域已经free，依然访问内存的话，此时KASAN根据shadow memory的值是0xFF就可以断use-after-free问题。4)slab对象shadow memory填充什么数据检查？#define KASAN_PAGE_REDZONE      0xFE  /* redzone for kmalloc_large allocations */#define KASAN_KMALLOC_REDZONE   0xFC  /* redzone inside slub object */#define KASAN_KMALLOC_FREE      0xFB  /* object was freed (kmem_cache_free/kfree) */#define KASAN_GLOBAL_REDZONE    0xFA  /* redzone for global variable */1 打开slab_debug2 kmem_cache_create填充FC当我们第一次创建slab缓存池的时候，系统会调用kasan_poison_slab()函数初始化shadow memory为下图的模样。整个slab对应的shadow memory都填充0xFC。3 kmem_cache_alloc填充0kmem_cache_alloc填充0，表明该内存访问vaild。kmalloc(20) – 00 00 04 FC   32bytes中20bytes可访问。4 kmem_cache_free填充FBkmem_cache_free填充FB，表明该内存已经free。5) 全局变量填充FA方便定位全局变量越界写的，增加额外信息记录全局变量的模块、文件、行号等信息。__asan_register_globals    \t-&gt;register_global/* The layout of struct dictated by compiler */struct kasan_global {\tconst void *beg;\t\t/* Address of the beginning of the global variable. */ \tsize_t size;\t\t\t/* Size of the global variable. */\tsize_t size_with_redzone;\t/* Size of the variable + size of the red zone. 32 bytes aligned */\tconst void *name;\tconst void *module_name;\t/* Name of the module where the global variable is declared. */\tunsigned long has_dynamic_init;\t/* This needed for C++ */#if KASAN_ABI_VERSION &gt;= 4\tstruct kasan_source_location *location;#endif#if KASAN_ABI_VERSION &gt;= 5\tchar *odr_indicator;#endif};/* The layout of struct dictated by compiler */struct kasan_source_location {\tconst char *filename;  //记录变量的文件\tint line_no; //记录变量的行号\tint column_no;  //记录变量的列号};5)栈分配变量的readzone是如何分配的？"
  },
  
  {
    "title": "mmap_lock debugger",
    "url": "/posts/ebpf-tracepoint-mmap-lock/",
    "categories": "linux, mmap_lock",
    "tags": "mmap_lock",
    "date": "2022-11-02 00:00:00 +0000",
    





    
    "snippet": "一、背景通过内核的新增的mmap_lock tracepoint结合ebpf，实现对mmap_lock的调测，监控线程持锁时间二、实现1、社区在mmap_lock增加tracepointhttps://github.com/torvalds/linux/commit/2b5067a8143e34aa3fa57a20fb8a3c40d905f942https://github.com/torv...",
    "content": "一、背景通过内核的新增的mmap_lock tracepoint结合ebpf，实现对mmap_lock的调测，监控线程持锁时间二、实现1、社区在mmap_lock增加tracepointhttps://github.com/torvalds/linux/commit/2b5067a8143e34aa3fa57a20fb8a3c40d905f942https://github.com/torvalds/linux/commit/10994316089c9682f2fbe0be0b1e82bcaf5f4e8chttps://github.com/torvalds/linux/commit/2f1aaf3ea666b737ad717b3d88667225aca23149在down/up read/write位置增加tracepoint点，可通过tracepoint来统计跟踪down up流程与持锁时间来做维测。2、ebpf实现用户态跟踪https://zhuanlan.zhihu.com/p/347241870https://zhuanlan.zhihu.com/p/450571608  //bpf hello/* read trace logs from debug fs */void read_trace_pipe(void){    int trace_fd;    trace_fd = open(DEBUGFS \"trace_pipe\", O_RDONLY, 0);    if (trace_fd &lt; 0)        return;    while (1) {        static char buf[4096];        ssize_t sz;        sz = read(trace_fd, buf, sizeof(buf) - 1);        if (sz&gt; 0) {            buf[sz] = 0;            puts(buf);        }    }}https://nakryiko.com/posts/bpf-tips-printk/bpfprint小技巧：/* Helper macro to print out debug messages */#define bpf_printk(fmt, ...)                            \\({                                                      \\        char ____fmt[] = fmt;                           \\        bpf_trace_printk(____fmt, sizeof(____fmt),      \\                         ##__VA_ARGS__);                \\})https://lwn.net/Articles/818714/  Dumping kernel data structures with BPF BPF iterator机制合入了，可以利用kernel的dump机制把数据结构dump到user space。4月份的文章介绍过tools/testing/selftests/bpf/progs/bpf_iter_task_stack.c //kernel代码中的示例https://github.com/iovisor/bcc/blob/master/docs/reference_guide.md#3-attach_tracepointhttps://www.brendangregg.com/blog/2016-01-18/ebpf-stack-trace-hack.html//保存stack信息https://github.com/iovisor/bcc/blob/master/tools/old/memleak.py    int depth = 0;    u64 bp = ctx-&gt;bp;    if (!(info-&gt;callstack[depth++] = get_frame(&amp;bp))) return depth;https://man7.org/linux/man-pages/man7/bpf-helpers.7.htmlbpf helper.bpf_get_stackbpf_get_task_stack       // long bpf_get_task_stack(struct task_struct *task, void *buf, u32 size, u64 flags)bpf_ktime_get_ns\t\t// u64 bpf_ktime_get_ns(void)bpf_get_current_pid_tgid//生成ebpf的头文件bpftool gen skeleton mmap_lock_bpfclang -g -O2 -target bpf  -c mmap_lock.bpf.c -o mmap_lock_bpfllvm-strip -g mmap_lock_bpf    [root@localhost bazel-bin]# llvm-objdump -t *.bpf.o    clang -g -O2 -target bpf -D__TARGET_ARCH_x86 -I . -I bazel-out/aarch64-fastbuild/bin/external/linux/libbpf/include -c third_party/bpf/schedlat.bpf.c -o bazel-out/aarch64-fastbuild/bin/third_party/bpf/schedlat_bpf.o &amp;&amp; llvm-strip -g bazel-out/aarch64-fastbuild/bin/third_party/bpf/schedlat_bpf.ohttps://facebookmicrosites.github.io/bpf/blog/2020/02/20/bcc-to-libbpf-howto-guide.html //bcc与libbpf写法的转化https://www.ebpf.top/post/kernel_btf/   //kernel btfebpf程序编译： clang -g -O2 -target bpf -D__TARGET_ARCH_x86 -I . -I bazel-out/aarch64-fastbuild/bin/external/linux/libbpf/include -c third_party/bpf/schedlat.bpf.c -o bazel-out/aarch64-fastbuild/bin/third_party/bpf/schedlat_bpf.o &amp;&amp; llvm-strip -g bazel-out/aarch64-fastbuild/bin/third_party/bpf/schedlat_bpf.o'  bpftool gen skeleton   /usr/bin/gcc -U_FORTIFY_SOURCE -fstack-protector -Wall -Wunused-but-set-parameter -Wno-free-nonheap-object -fno-omit-frame-pointer -MD -MF bazel-out/aarch64-fastbuild/bin/_objs/schedlat/schedlat.pic.d '-frandom-seed=bazel-out/aarch64-fastbuild/bin/_objs/schedlat/schedlat.pic.o' -fPIC -iquote . -iquote bazel-out/aarch64-fastbuild/bin -iquote external/bazel_tools -iquote bazel-out/aarch64-fastbuild/bin/external/bazel_tools -isystem bazel-out/aarch64-fastbuild/bin/external/linux/libbpf/include -Wno-sign-compare -DGHOST_LOGGING -Wl,-I/home/csluo/ld-linux-aarch64.so.1 -g -fno-canonical-system-headers -Wno-builtin-macro-redefined '-D__DATE__=\"redacted\"' '-D__TIMESTAMP__=\"redacted\"' '-D__TIME__=\"redacted\"' -c bpf/user/schedlat.c -o bazel-out/aarch64-fastbuild/bin/_objs/schedlat/schedlat.pic.o  gcc -o schedlat -Wl,-S -fuse-ld=gold -Wl,-no-as-needed -Wl,-z,relro,-z,now -B/usr/bin -pass-exit-codes  -lstdc++ -lm _objs/schedlat/schedlat.pic.o /home/ghost-userspace/bazel-out/aarch64-fastbuild/bin/external/linux/libbpf/lib/libbpf.a -lelf -lz   gcc -o schedla _objs/schedlat/schedlat.pic.o -lbpf -lelf     /usr/bin/gcc -U_FORTIFY_SOURCE -fstack-protector -Wall -Wunused-but-set-parameter -Wno-free-nonheap-object -fno-omit-frame-pointer -Wno-sign-compare -DGHOST_LOGGING -Wl,-I/home/csluo/ld-linux-aarch64.so.1 -g -fno-canonical-system-headers -Wno-builtin-macro-redefined '-D__DATE__=\"redacted\"' '-D__TIMESTAMP__=\"redacted\"' '-D__TIME__=\"redacted\"' -c loader.c -o loader.pic.o     gcc -o mmap_lock_debug loader.pic.o -lbpf -lelf1&gt; 基于BCC的实现2&gt; 基于libbpf的实现3、内核ko实现tracepoint跟踪三、其他知识1、ebpf程序分类https://blog.csdn.net/weixin_41036447/article/details/106473865 //ebpf程序分类"
  },
  
  {
    "title": "Distributed Shared Memory",
    "url": "/posts/Distributed-Shared-Memory/",
    "categories": "linux, DSM",
    "tags": "DSM",
    "date": "2022-07-12 00:00:00 +0000",
    





    
    "snippet": "一、Popcorn DSM:distributed shared memoryhttps://www.ssrg.ece.vt.edu/papers/icdcs20.pdf(0) Migrating Execution Contexts    要跨计算机边界迁移线程，我们需要获取描述原始节点上线程当前状态的执行上下文。幸运的是，现代操作系统维护这样    的执行上下文，以在系统调用和上下文切换...",
    "content": "一、Popcorn DSM:distributed shared memoryhttps://www.ssrg.ece.vt.edu/papers/icdcs20.pdf(0) Migrating Execution Contexts    要跨计算机边界迁移线程，我们需要获取描述原始节点上线程当前状态的执行上下文。幸运的是，现代操作系统维护这样    的执行上下文，以在系统调用和上下文切换之间保留线程状态。特别是，Linux使用结构pt regs和结构mm_struct分别    在系统调用和上下文交换机之间保留寄存器和虚拟地址状态。我们利用这些机制来获取执行上下文。\tDEX通过消息层在节点之间传输执行上下文（有关详细信息，请参见第III-E节）。我们将引用创建进程线程的节点作为    线程的原点。进程中的所有线程都具有相同的起源，即第一次创建进程的节点。我们将将线程迁移到的节点称为远程节    点。例如，在图1中，节点1是线程的起源，节点0是线程0的远程，节点2是线程2和3的远程。在将执行上下文发送到远程    后，源端的原始线程等待来自远程的配对线程的传入请求。    \t在远程节点，DEX从接收到的执行上下文重建原始线程。它首先创建一个使用接收到的上下文初始化的远程线程。然后，    远程线程被放入作业调度程序的运行队列中，以便最终可以调度它。请注意，DEX仅传输在远程开始执行线程所必需的最    小执行上下文；应用程序的虚拟内存数据在此阶段不传输。\t远程线程可以要求其相应的原始线程代表其在原点工作。例如，远程线程可能需要来自源的虚拟内存区域（VMA）信息来    复制其地址空间，如图1中的3所示。当远程线程向源发送工作请求时，请求将被调度到迁移或处理最后一个工作请求后处    于睡眠状态的原始线程。原始线程被唤醒，在原始线程的上下文中处理请求，并返回结果。原始线程再次进入睡眠状态，    等待来自对等远程线程的下一个请求。\t此工作委托设计最大限度地减少了对内核的更改，但透明地支持分布式环境中的有状态操作系统功能。实际上，重新实现    所有操作系统功能（如futex和文件I/O）以支持分布式执行环境是不可行的。相反，DEX通过工作委托重用现有实现。当    远程线程需要有状态内核功能时，请求将移交给原始线程，在源端执行，只有其结果才会传回远程线程。从内核的角度来    看，这与处理来自本地线程的请求相同。通过这种方式，DEX可以透明地向分布式线程提供许多操作系统功能，而无需进    行重大的内核修改。例如，DEX支持futex（快速用户空间互斥体），这是Linux [18]上实现线程同步原语的核心机制。    当远程线程调用线程同步操作时，该操作将有效地转换为一个或多个futex系统调用。futex操作被转发到其原始线程，    并通过原始futex实现在原点处理。因此，应用程序可以使用基于futex的线程同步原语，而不管它们的位置如何。\t尽管为工作委派配对线程，DEX仍然需要远程处的额外线程来处理节点范围的操作。考虑原点上的线程收缩VMA的情况。更    新应应用于所有远程线程，以防止非法内存访问操作。但是，从源的角度来看，不清楚哪个远程线程应该更新每个远程节    点上的VMA。因此，DEX为每个远程节点中的每个分布式进程创建一个名为远程工作程序的线程。节点范围的操作，如VMA    修改和，原始进程退出，将传递给远程工作进程，并在远程工作进程的上下文中处理。    迁移的执行也可以带回原点。这种向后迁移几乎与正向迁移相同；DEX在远程收集远程线程的执行上下文，将上下文传输    到源，用最新的上下文更新原始线程的上下文，并恢复原始线程的执行。远程线程在向后迁移完成后退出。恢复的原始线    程可以继续到原点，也可以再次迁移到任何节点。    \t在当前实现中，正向和反向迁移都是由系统调用启动的。我们相信，它可以很容易地扩展，以便操作系统调度程序或用户    空间库自动启动迁移。当进程中的线程首次迁移到节点时，DEX使用给定的地址空间信息启动远程工作程序，并使用克隆    线程从远程工作程序分叉远程线程，允许它们共享地址空间。来自同一进程的后续迁移请求可以通过简单地从远程工作线    程分叉来处理。通过这种方式，DEX以较低的开销处理多次和重复迁移，这通常在具有多个并行执行区域的应用程序中找    到。DSM： &gt; 前置条件：(1) 只支持sequential memory consistency model(2) 由于线程共享相同的虚拟地址空间，因此所有线程必须具有相同的内存视图。&gt; Popcorn限制1. 编译CONFIG的限制```c//https://github.com/ssrg-vt/popcorn-kernel/wiki/VM-SetupYou can use your own configuration file, but MAKE SURE that the following configurations are disabled:    CONFIG_SWAP    CONFIG_TRANSPARENT_HUGEPAGE    CONFIG_CMA    CONFIG_MIGRATION    CONFIG_COMPACTION    CONFIG_KSM    CONFIG_MEM_SOFT_DIRTYPage should be 4 KB.    ARM should select ARM64_4K_PAGES    PPC should use CONFIG_PPC_4K_PAGES.  代码编写限制       //https://github.com/ssrg-vt/popcorn-kernel/wiki/Compiler-Setup   Limitations   1.Bring back migrated-away threads to their original node before exiting from the program.   //1.在migrate到远程节点的线程回迁之前， 进程不能退出。   2.A migrated thread should be brought back to the original node to be relocated to other node.    For example, to migrate a thread which was created at node 0 and is running at node 1, the thread    should be migrated back to node 0 before it is migrated to node 2 again.   //2.线程不能直接从node1迁到node2，需要先将node1线程迁回node0（origin）后，从node0迁移到node2;   3.You can do file I/O at any location, but file descriptors are not synchronized between migrated    threads. This means, console is not migrated and printf() might not work neither. To check the    execution progress, we recommend to open() a file at an absolute path, write() to the file, and    close() for each print-out. File operations (e.g., fopen(), fwrite()) might not work neither.   //3. 不支持线程中间共享文件，因此printf可能无法使用;文件读写只能在该线程内进行fopen,fwrite,fcolse.   4.You cannot create a thread while the thread is running at a remote node.   //4.在remote节点执行的线程不能在创建新线程。   5.Networking is not supported.   //5.这个是通信层导致的。        **works: **(1) 维护页面的所有权来跟踪最新页面的位置, 基于the multi-reader single-writer memory model.    初始时，origin独占进程的所有页面，远程节点必须联系origin获取页面数据和页面所有权。    如果请求是读取访问，则源将共同所有权授予远程，以便源和远程都可以同时访问该页。当远程请求一个要写入的页面    时，源通过发送所有权撤销请求从其他节点（包括自身）撤销所有权，授予它独占所有权。\t为了使网络流量最小化，当远程节点已经拥有最新的页面数据时，源节点只需授予所有权，而无需转移页面数据。信息，    如所有者列表和页面状态维护在每进程基树中，该基树通过虚拟页面地址索引信息。(2) memory consistency protocol是通过page fault hander来触发的。    leader-follower model解决页面错误处理中固有的并发问题。    i. 页面错误处理中固有的并发问题的影响\t这种并发的错误处理使DEX中的所有权跟踪变得复杂。在内存一致性协议中，页面准备时，需要更新页面所有权。但是，    节点中的多个线程可能同时请求同一页。这可以发起多个协议请求，即使所有每线程的请求都是针对同一个页面的。如果    一个线程由于更改了PTE或线程之间的冲突而必须放弃读取的页面，则这会变得更加复杂；为了安全地放弃读取的页面或    解决冲突，内核应该维护per PTE元数据以标识哪个线程由于任何原因更改了PTE。这可能会减慢页面错误处理程序，这    是不能接受的。    ii. leader-follower model    为了有效地抑制页面错误处理中固有的并发性，我们在页面错误处理程序中采用了领导者-跟随者模型。DEX维护一个每个    进程的哈希表，以跟踪所有正在进行的故障处理。触发页面第一个故障的线程成为该页面的页面故障处理的leader。需要    具有相同访问类型（即读或写）的相同页面的后续线程成为领导者的追随者。leader执行准备页面的操作；它通过发送请    求和失效来从其他节点带出页面。leader处理故障后，同时更新对应的PTE。在领导者恢复执行之前，它会唤醒所有追随    者。追随者不会再次处理错误，相反，他们只是使用更新的PTE恢复执行。这样， DEX聚合了类似的页面错误类型，并通    过单个页面错误处理来处理它们。(3)On-Demand VMA Synchronization    Linux中的VM子系统在两个级别管理内存：虚拟内存区域（即VMA）和页表条目(PTE)。VMA维护地址空间范围的权限、备    份文件、文件中的偏移量等。另一方面，PTE保持当前的每页状态。由于VMA信息必须由进程中的线程共享，DEX需要一种    类似于上一节中解释的内存一致性协议的机制。但是，线程通常使用不相交的VMA（例如，线程本地存储），这使得在所    有线程中完全同步VMA是不必要的（甚至是禁止的）。出于这些原因，我们部署了按需VMA同步。在执行上下文迁移期间，不会将VMA信息传输到远程。当远程线程看到丢失的VMA（即，正在访问的地址不属于它拥有的任何VMA）时，它将联系源检查访问是否合法。如果访问是合法的地址范围，并且存在与该地址对应的VMA，则意味着远程节点具有过时的VMA信息。在这种情况下，源端回复有关VMA的最新日期信息，远程相应地更新其VMA。如果访问无效，源将向远程发送错误代码，该错误代码将终止远程线程，就像执行了非法内存访问一样。所有VMA操作都是通过使用第III-A节中解释的工作委托在原点执行的。仅当操作收缩VMA区域（例如，munmap）或降级（例如，m保护）其访问权限时，源端才广播更新的VMA信息；许可操作（例如，mmap）不会急于同步，而是通过按需VMA同步机制更新。(4)Inter-node Communication\t通信层在分布式系统中对性能至关重要。此外，通信层应足够灵活，以支持DEX实现中高度并发和复杂的通信使用。为    此，我们设计并实施了一个基于InfiniBand的节点间消息传递系统，以利用现代互连技术的高带宽和低延迟。\t在系统启动时，节点读取配置，以在InfiniBand可靠连接（RC）模式下为每个节点对建立通信通道。消息通过相应的连    接路由到目标节点，节点上的消息处理程序处理传入的消息。    与传统套接字不同，用于通过InfiniBand发送和接收的I/O缓冲区必须显式映射到支持DMA的地址空间范围，以便    InfiniBand主机控制器适配器（HCA）可以从缓冲区执行DMA。此外，要执行远程DMA (RDMA)，我们还必须将缓冲区与    RDMA内存区域关联，远程节点可以使用远程密钥从缓冲区执行RDMA。以前的研究表明，DMA映射和RDMA区域关联成本高昂    [20]–[22]；因此，我们的设计旨在最大限度地减少这些操作。    在DEX中，消息的大小是双峰的；控制消息很小，范围可达数十字节，而页面数据以4KB消息传输。由于RDMA区域关联和    RDMA完成控制路径【21】的高开销，通过RDMA传输小消息对DEX来说成本太高。相反，DEX使用InfiniBand VERB传输小消息。为了避免昂贵的DMA映射，我们在消息层中使用了发送缓冲池。每个连接都有自己的专用发送缓冲池，在初始设置    期间配置。在内部，池由映射到支持DMA的地址空间范围的物理连续页面块组成，池将这些块作为环形缓冲区管理。上下    文（例如，捕获到页面错误处理程序的线程）可以从池分配缓冲区，并在缓冲区中编写出站消息。由于缓冲区是DMA就绪    的，因此可以在没有DMA映射的情况下发送消息。发送完成时，池将回收缓冲区。类似地，DEX维护入站消息的接收缓冲池。每个连接在初始设置阶段通过发布使用DMA映射内存区域构建的接收工作请求来设置接收缓冲池。InfiniBand HCA通过DMA将传入数据写入缓冲区，并通过完成队列将事件通知主机。在处理传入消息事件后，DEX通过使用缓冲区重新初始化接收工作请求并再次发布请求来回收DMA就绪缓冲区。通过这种方式，DEX消除了小消息的DMA映射和内存副本。DEX利用RDMA传输大型消息，如页面数据。与特定于域的RDMA工作[20]–[24]不同，DEX必须支持任意用户应用程序。因此，不可能预先确定进程的虚拟内存占用空间和生存期，这些进程会随着时间的推移而动态变化，并且彼此不同。此外，在物理内存中保持应用程序的虚拟内存地址空间连续实际上是不可行的。因此，我们排除了这些域特定系统常用的RDMA内存区域关联的静态方法。另一方面，动态RDMA区域关联的成本如此之高，以至于它可以抵消RDMA的好处。基于这些观察，我们设计了一种使用RDMA和内存复制的混合方法。每个连接都有一个RDMA接收器，该接收器在连接初始化期间设置。RDMA接收器由物理连续页面的块组成，在设置期间，这些块与RDMA内存区域关联。要执行RDMA, DEX从RDMA接收器分配缓冲区，并要求其对等体对位置执行RDMA。当对等方通知RDMA完成时，RDMA接收器中的数据将复制到其最终目的地（即应用程序虚拟内存中的页面）并释放。即使这种方法涉及一个内存副本，但它比为内存一致性协议中的每个页面执行RDMA关联更快。IV. ADAPTING APPLICATIONS  我们将在第五节中展示的BA，许多应用程序都是可扩展的，因此它们可以轻松地扩展到DEX上的单机性能之外。但是，某些  应用程序不会不修改地扩展，因为DEX以页面粒度提供内存一致性。这可能导致（1）竞争页面，其中对同一页面上程序对象  的冲突访问（读/写和写/写）会导致跨节点干扰，（2）内存一致性协议开销，其中多节点读取，单节点写入模式导致一致  性协议向网络泛洪所有权无效消息。DEX提供了一组工具，帮助开发人员识别和消除应用程序中的这些瓶颈。由于DEX提供了  共享内存编程模型，开发人员在分析时可以花费最小的精力，通过使用DEX提供的工具和调整应用程序以实现群集上的可扩  展性，而不是MPI等其他编程模型，后者可能需要对整个应用程序进行全面检查。A.分析页面故障\t首先，对应用程序进行分析，以确定哪些组件导致了最多的跨节点流量。DEX提供了一个分析工具，该工具为需要DEX中内    存一致性协议的每个观察到的页面错误收集包含六元组的页面错误跟踪。每个元组包含页面故障发生时的系统时间、故障    发生的节点ID、故障任务的任务ID、故障类型（即读/写/无效）、故障指令的内存地址、导致故障的内存地址，以及用于    标记应用程序的单个部分的用户指定的标识符。DEX可以配置为收集每个故障的此信息，并通过ftrace将其移交给用户空    间。\t对于分析，应用程序是使用调试信息构建的，并使用DEX的分析工具运行的。执行后，分析工具将跟踪与二进制文件一起    后处理，以提供丰富的分析集，例如识别导致最多页面错误的程序对象或源代码位置、随时间推移的页面错误频率、每线    程内存访问模式、等。使用这些跟踪，我们可以识别跨节点流量的来源，并应用一组小而有效的优化，以获得更好的可扩    展性。\t应用程序数据通常可以分为两类：（1）所有线程使用的全局数据，通常由数组或自定义数据结构（例如，图形）组成，    （2）每节点数据，其中包括节点上所有线程的每线程数据和其他数据结构（例如，NUMA感知应用程序【16】中的过滤图或逻辑分区堆）。优化数据访问模式的方法因每个类别而异。对于每个节点的数据，分析工具有助于识别放置在同一页面    上的多个节点的数据；然后，开发人员可以轻松地将这些数据分离到不同的页面上，以避免争用。对于全局数据，该工具    帮助开发人员找到次优的数据访问模式，然后可以优化这些模式以进行横向扩展。此外，开发人员还可以通过数据访问提    示将这些模式表达到DEX系统，以减少协议开销。B.减少虚假页面共享\t在许多共享内存应用程序中，有几种常见的错误共享来源，这些来源很容易使用页面故障跟踪识别和删除。以下方法有助    于消除将多个节点的每个节点数据共定位到同一页面上所导致的错误共享。\t堆栈。每个应用程序线程都被分配自己的本地运行时堆栈以执行。但是，通常，在分叉子线程时，父线程将使用自己的堆    栈将数据传递给子线程，例如，传递给p线程创建或OpenMP共享变量的数据指针。当子线程读取/写入共享程序对象，而父线程在同一页面上的其他位置写入自己的堆栈时，这将导致错误共享。为了消除这种类型的错误共享，我们识别并将有    问题的堆栈数据重新定位到全局内存中，或将数据下推到子线程的线程本地存储中。特别是对于OpenMP，我们修改了编译    器，以在并行区域的持续时间内自动将共享变量卸载到全局内存。\t全局数据和堆。如果将两个访问类型冲突的程序对象分配给同一页面，则全局程序状态（包括静态和动态分配的数据）可    能会导致错误共享。这个问题很容易纠正：用户可以简单地使用静态数据的对齐声明属性添加填充和对齐对象到页面边    界，并使用posix memign分配动态数据。但是，盲目地将这些修复程序应用于所有程序对象可能会导致严重的内存膨    胀。将每个声明的程序对象移动到单独的页面将导致二进制文件的大小膨胀，而动态分配其自己页面中的每个对象将导致    分配大量小对象的程序的极端内部内存碎片和内存不足错误。更糟糕的是，将所有对象移动到单独的页面可能会通过降低    空间局部性和污染缓存而导致性能下降。我们没有将页面对齐应用于每个程序对象，而是根据页面错误跟踪识别并有选择    地对齐造成干扰最大的每个节点对象。C.优化全局内存分析工具还通过识别发生故障数量最多的源代码位置，帮助开发人员优化以前未见过的应用程序的全局内存使用情况。通常，两个瓶颈位置会出现在一起——一个位置会引起大量写入故障，而另一个位置会引起相关数量的读/写故障。另一个争用来源是全局共享标志；一些应用程序在某些条件保持的情况下继续迭代（例如，图计算继续，直到节点数据没有更改）。与其盲目检查和设置标志，不如在本地存储每个线程的标志更新，并在迭代结束时执行全局标志更新。该工具有助于识别应用程序中导致瓶颈的数据访问模式，并纠正它们。由于DEX的可编程性优势，开发人员可以轻松、渐进地优化这些模式以进行横向扩展。V. EVALUATIOND. Performance of DEX’s MechanismsThread migration overhead.\t为了测量线程迁移开销，我们使用了一个微基准，它每秒重复迁移一个线程。我们测量了在源节点和远程节点处理线程迁    移的时间。表II总结了使用10个线程迁移的平均值的结果。\t第一次正向迁移总共需要812.1μs，而第一次反向迁移总共只需要24.7μs。当线程再次迁移到同一节点时，第二次正向迁    移只花了230.0μs，仅占第一次迁移总时间的28.3%。第二次向后迁移的时间几乎与第一次向后迁移的时间相同。随后向    同一节点迁移的延迟与第二次迁移的延迟相似。\t第一次和第二次正向迁移之间的延迟差异来自构建每进程数据结构的时间。在第一次迁移期间，DEX处理大多数每个进程    的过程，如创建远程工作程序、设置地址空间和设置其他进程级数据结构。图3显示了分解延迟的评估结果，该结果确认    了620.0μs的第一次迁移被每个进程的过程占用，由符号键“Remote Worker”表示。    正向和反向迁移延迟之间的延迟差异来自于每种迁移类型所需的工作量。在正向迁移期间，DEX创建线程并使用原始执行    上下文设置线程。相反，向后迁移只需要更新原始线程的状态，这比正向迁移快得多。Page fault handling overhead.\t页面故障分析处理性能，我们创建了另一个微基准，它分叉两个线程，并将其中一个线程重新定位到远程。然后，两个线    程都会不断更新单个全局变量，强调内存一致性协议，以在节点之间洗牌页面，以获得独占所有权。在执行微基准的30秒    期间，我们从源收集了大约154,676个页面错误。    我们观察到故障处理时间的双峰分布；尽管我们的消息层一直需要13.6μs来检索4KB页面，但27.5%的故障在19.3μs内处    理。然而，当两个节点争用同一页面，其中一个节点必须回退重试时，故障处理平均扩展到158.8μs。这意味着减少错误    页面共享在DEX中至关重要，因为它不仅加快了故障处理，而且还减少了故障的发生。VI. RELATED WORK    分布式共享内存（DSM）系统为跨多台计算机的分布式执行上下文（即进程和线程）提供了一致的内存视图，过去已经进    行了彻底的讨论。这些系统中的绝大多数侧重于通过自定义内存管理API利用远程内存来显式获取、锁定和释放共享内存    区域[8]–[14]。通常，此类API限制了可以在分布式上下文之间共享的虚拟内存类型（例如，只能共享堆分配的数据），    并且只保证共享内存区域的宽松内存一致性。这就要求开发人员使用针对每个系统的内存模型定制的API和语义编写应用    程序，这使得应用程序的开发和调试变得复杂。与以前的DSM工作相比，DEX的独特之处在于，分布式线程可以透明地访问    一致的内存原样，而无需重写远程内存访问和分布式同步的应用程序。此外，分布式线程可以按原样使用同步原语，而不    管其实际位置如何。    大多数DSM系统专注于在进程之间共享数据；只有少数系统考虑DSM上下文中的线程[9], [28]。通常，后者仅支持静态线    程放置，在这种情况下，远程创建的线程一旦在节点上生成，就无法重新定位。此外，它们需要应用程序重构，以将数据    放置在可共享虚拟内存区域中，以便在迁移后访问[28]。相比之下，DEX允许线程动态放置自己，从而大大提高了灵活性    和可编程性。    最近提出的分类内存系统等利用现代高速低延迟互连，为应用程序提供超出单台计算机可用内存的大量内存。特别是，    Grappa [29]、LITE [22]、HotPot [24]、偏远地区【30】和乐高OS[3]通过探索具有RDMA支持互连和/或DSM概念的新    兴内存系统体系结构来激励我们在现代背景下。尽管它们显示出有希望的结果，但它们不允许开发人员利用单个计算机的    纵向扩展设计的简单性和效率；每个应用程序都必须考虑底层网络[20]、[21]、【24】的低级细节，和/或开发人员必须    从头重新设计整个应用程序[21]、[29]、[30]。例如，在Graappa[29]中，开发人员必须使用其数据寻址模式、委托操    作和构建在MPI编程模型上的通信接口完全重写应用程序。这损害了可编程性[31]–[33]，使现有应用程序难以适应框    架。此外，许多分类的内存系统没有提供利用内存以外的远程系统资源（即处理器和底层存储的计算能力）的机制；因    此，必须手动分发应用程序，否则系统资源仍然未充分利用【3】。    单系统映像（SSI）系统具有灵活的进程放置和迁移功能，通过平衡节点之间的负载，有效利用群集。然而，这些系统中    的大多数都在进程级别工作；一个进程不能同时利用多个节点，而只能在给定时刻在单个节点上运行。因此，即使群集中    存在空闲节点，应用程序性能也仅限于单机性能。Kerrighed [34], [35]唯一支持线程级迁移来处理这种情况；但是，    与传统的DSM系统一样，它需要显式声明的内存区域来在分布式线程之间共享数据。这再次损害了可编程性，并为重写应    用程序带来了开销。在虚拟化[36]–[39]和检查点/重新启动系统[40]–[42]的上下文中，还对重新定位运行上下文进行    了广泛的研究。但是，它们也不能同时利用多个节点，在任何给定时刻将执行边界限制在单个计算机上。vNUMA [43]提    出了虚拟机管理程序级DSM系统，但是，目前还不清楚它如何以分布式方式处理关键的操作系统级功能，如futex。    ScaleMP [44]允许通过利用虚拟化技术从多个节点中创建软件定义的服务器。尽管ScaleMP提供了与DEX非常相似的功    能，但其内部功能尚不清楚，因为它是专有软件。七、结论我们引入了DEX，一个Linux内核扩展，允许应用程序将其执行边界扩展到单个计算机之外。任何应用程序都可以通过简单的函数调用转换为跨多个节点执行。使用许多现实应用程序的评估结果证实，DEX提供了一种直观而有效的方法来利用机架规模系统中的分散资源。我们认为，DEX的执行重新定位能力可以在许多场景中利用，例如在数据附近重新定位计算，通过卸载加速计算，以及通过使用具有异构功率配置文件的节点来节省能源。```chttps://www.ssrg.ece.vt.edu/papers/systor20.pdfhttp://www.popcornlinux.org/integrating non-cache-coherent heterogeneous computing elementshttps://www.cnblogs.com/zhengshuangxi/p/11180610.html缓存强一致：3、MESI协议MESI协议是一种常用的缓存一致性协议，它通过定义一个状态机来保证缓存的一致性。在MESI协议中有四种状态，这些状态都是针对缓存行（缓存由多个缓存行组成，缓存行的大小单位与机器的位数相关）。（I）Invalid状态：缓存行无效状态。要么该缓存行数据已经过时，要么缓存行数据已经不在缓存中。对于无效状态，可直接认为缓存行未加载进缓存。（S）Shared状态：缓存行共享状态。缓存行数据与内存中对应数据保持一致，多个缓存中的相应缓存行都是共享状态。该状态下的缓存行只允许读取，不允许写。（E）Exclusive状态：缓存行独有状态。该缓存行中的数据与内存中对应数据保持一致，当某缓存行是独有状态，其他缓存对应的缓存行都必须为无效状态。（M）Modified状态：缓存行已修改状态。缓存行中的数据为脏数据，与内存中的对应数据不一致。如果一个缓存行为已修改状态，那么其他缓存中对应缓存行都必须为无效状态。另外，如果该状态下的缓存行状态被修改为无效，那么脏段必须先回写入内存中。MESI协议的定律：所有M状态下的缓存行（脏数据）回写后，任意缓存级别中的缓存行的数据都与内存保持一致。另外，如果某个缓存行处于E状态，那么在其他的缓存中就不会存在该缓存行。MESI协议保证了缓存的强一致性，在原理上提供了完整的顺序一致性。可以说在MESI协议实现的内存模型下，缓存是绝对一致的，但是这也会导致一些效率的问题，我们平时使用的机器往往都不会采用这种强内存模型，而是在这个基础上去使用较为弱一些的内存模型：如允许CPU读写指令的重排序等。这些弱内存模型可以带来一定的效率提升，但是也引入了一些语义上的问题。   https://www.cnblogs.com/miaolong/p/12545208.htmlhttps://zhuanlan.zhihu.com/p/95435168缓存一致性MSI状态机转化：现在主要用于类似arm + x86芯片的异构设备中进程迁移，二、Popcorn linuxhttps://github.com/ssrg-vt/popcorn-kernelhttps://github.com/systems-nuts/popcorn-tutorial/blob/master/popcorn-tutorial.pdf三、othershttp://www.vldb.org/pvldb/vol11/p1604-cai.pdfEfficient Distributed Memory Management with RDMA and Caching四、DSM解决的问题1、一致性对于数据复制的情况有两种基本的协议 ,即写无效和写更新协议.对于写无效与写更新的选择 ,利用竞争算法 ( competitiv e alg orithm)可以有自适应的优点.其结果在某些情况达到最优结果 ,最坏也不超过全用写更新方式开销的两倍.2、false share假共享 :就是指对于同一数据共享粒度中的不相关变量 ,当一个结点对其中一个变量进行写操作时 ,另外一个结点就不能同时对另外一个变量进行访问 .另外 ,数据的共享粒度也影响到目录的大小.共享粒度可以为 cache行、页或一个对象.五、已有机制及待补充功能考虑六、DSM的技术点分布式共享内存的技术和实现李 群 谢 立 孙钟秀(南京大学计算机科学与技术系及软件新技术国家重点实验室 南京 210093)1.复制问题  共享粒度、一致性协议、颠簸颠簸 ( thrashing )是指当两个结点同时对数据页进行写访问时引起的页面在两个结点之间频繁的传输 ,这种情况严重影响了系统的性能.2.存储一致性 ( coherence)模型​    有效地提供内存一致性是 DSM 系统的一个重要任务 .为了能对存储器的性能进行优化 ,即利用写缓存技术、存储访问重叠技术、流水线技术等严格的一致性 ,无法开发程序的语义 ,因而出现了减弱了的一致性模型[ 2].其目的是为了解决三个问题: ①减少昂贵的消息发送次数 .②掩盖对非本地内存访问的长等待时间.③解决因为一致性单元而潜在引起的假共享问题.已有的一致性模型有: 原子一致性、顺序一致性、处理机一致性、弱一致性、释放一致性、进入一致性 .3.系统界面​     DSM 虽然能够提供给用户一个方便的编程模型 ,但由于应用程序的行为过于复杂繁多 ,很难有一种统一的方法能够有效地处理这些问题 .因此DSM系统实现时往往要在实现统一地址空间的基础上 ,提供给程序员一些额外的措施 ,以供用户依照程序的具体知识选择使用.七、DSM 的实现常见三种方案（1）用硬件实现 ,实际上是传统的高速缓存 ( cache )技术在可扩展体系结构中的延伸 .（2）操作系统和程序库的实现方法 ,通过虚拟内存管理机制实现共享和一致性.（3）编译实现 ,自动将共享访问转变为同步和一致性原语."
  },
  
  {
    "title": "High Performance OS - caladan",
    "url": "/posts/High-Performance-OS-caladan/",
    "categories": "linux, caladan",
    "tags": "caladan",
    "date": "2021-11-14 00:00:00 +0000",
    





    
    "snippet": "Caladan: Mitigating Interference at Microsecond Timescales1 场景交互式、数据密集型Web服务 —— 可变负载。在真实场景，资源使用以及干扰频繁变化的情况下，隔离分区式的解决方案存在低CPU利用率（负载低）和长尾时延（负载高）的问题。即便有些方案增加了CPU资源流动的设计，但是从负载变化到资源流动收敛，需要毫秒级甚至是秒级的时间，无法...",
    "content": "Caladan: Mitigating Interference at Microsecond Timescales1 场景交互式、数据密集型Web服务 —— 可变负载。在真实场景，资源使用以及干扰频繁变化的情况下，隔离分区式的解决方案存在低CPU利用率（负载低）和长尾时延（负载高）的问题。即便有些方案增加了CPU资源流动的设计，但是从负载变化到资源流动收敛，需要毫秒级甚至是秒级的时间，无法应对短时的负载突变。2 技术概述基于调度时延、内存带宽、LLC未命中率等指标，实现上层任务的调度，以及CPU的流动，保持高CPU利用率和严格的性能隔离（吞吐量和尾时延）。从负载突变到CPU流动收敛可以达到微妙级别。1、微妙级的性能指标监控（调度时延、内存带宽、LLC未命中率），实时反馈当前系统负载，迅速应对负载突变的情况。调度时延的测量基于runtime来实现。所有的业务进程都运行在caladan定制的runtime上，业务进程需要划分线程类别（高、低优先级，用于配置调度策略），并完全由caladan调度器管理。调度时延由线程在调度队列中等待的时间来确定。内存带宽的测量依赖于intel的性能监控器(https://intel-pcm-api-documentation.github.io/classServerPCICFGUncore.html)，直接调用intel的API（getMCCounter），然后加以分析判断。2、微妙级的响应和CPU资源流动，迅速收敛应对负载突变。caladan的调度器每10us检查一次负载情况，响应速度很快。同时caladan舍弃了传统的资源隔离分区的做法，CPU资源流动不需要通过硬件或者linux CPU热插拔机制来完成，而是通过业务线程的调度（原线程迁移，目标线程运行，这个过程实际上就完成了一次CPU资源流动），大大降低了开销。调度由用户态调度器和内核模块ksched共同完成，舍弃sched_setaffinity这种长路径实现。用户态指定调度策略，通过ioctl下发调度命令，并通过mmap共享内存减少用户态内核态同步开销，ksched则在接收到用户态的调度命令后，使用IPI中断在目标核上快速完成调度切换。3 方案缺陷1、兼容性问题。业务进程需要运行在定制的runtime上，调度时延的测量以及线程调度都依赖于runtime对业务进程的拦截和封装。并且runtime不完全兼容linux，包含自定义的线程、互斥锁、条件变量和同步I/O机制等。业务进程需要将内部的线程信息传递给runtime，这可能需要对现有代码进行修改。2、暂时没有做numa节点之间干扰的优化。4 延伸思考caladan衡量负载情况的指标直接有效，值得参考。但是对性能指标的高效监控是定制化的（runtime+intel API），定制化的垂直优化很容易带来性能提升，但往往有兼容性问题，需要根据实际场景来取舍。在去除runtime这一层的情况下，寻求达到负载的快速感知和CPU资源快速流动的方法也是一个可以思考的方向。"
  },
  
  {
    "title": "Direct memory access(DMA)",
    "url": "/posts/dma-and-iommu/",
    "categories": "linux, DMA",
    "tags": "DMA",
    "date": "2021-10-14 00:00:00 +0000",
    





    
    "snippet": "一、DMADMA，全称Direct Memory Access，即直接存储器访问。DMA传输将数据从一个地址空间复制到另一个地址空间，提供在外设和存储器之间或者存储器和存储器之间的高速数据传输。当CPU初始化这个传输动作，传输动作本身是由DMA控制器来实现和完成的。DMA传输方式无需CPU直接控制传输，也没有中断处理方式那样保留现场和恢复现场过程，通过硬件为RAM和IO设备开辟一条直接传输数...",
    "content": "一、DMADMA，全称Direct Memory Access，即直接存储器访问。DMA传输将数据从一个地址空间复制到另一个地址空间，提供在外设和存储器之间或者存储器和存储器之间的高速数据传输。当CPU初始化这个传输动作，传输动作本身是由DMA控制器来实现和完成的。DMA传输方式无需CPU直接控制传输，也没有中断处理方式那样保留现场和恢复现场过程，通过硬件为RAM和IO设备开辟一条直接传输数据的通道，使得CPU的效率大大提高.【STM32】 DMA原理，步骤超细详解，一文看懂DMA看到STM32内核，存储器，外设及DMA的连接，这些硬件最终通过各种各样的线连接到总线矩阵中，硬件结构之间的数据转移都经过总线矩阵的协调，使各个外设和谐的使用总线来传输数据。AHB介绍：  AHB总线规范是AMBA总线规范的一部分，AMBA总线规范是ARM公司提出的总线规范，被大多数SoC设计采用，它规定了AHB (Advanced High-performance Bus)、ASB (Advanced System Bus)、APB (Advanced Peripheral Bus)。AHB用于高性能、高时钟频率的系统结构，典型的应用如ARM核与系统内部的高速RAM、NAND FLASH、DMA、Bridge的连接。APB用于连接外部设备，对性能要求不高，而考虑低功耗问题。ASB是AHB的一种替代方案。AHB总线的架构        AHB总线的强大之处在于它可以将微控制器（CPU）、高带宽的片上RAM、高带宽的外部存储器接口、DMA总线master、各种拥有AHB接口的控制器等等连接起来构成一个独立的完整的SOC系统，不仅如此，还可以通过AHB-APB桥来连接APB总线系统。AHB可以成为一个完整独立的SOC芯片的骨架。  ![image-20221130161933206](.\\images\\dma-and-iommu\\AHB总线.png)DMA原理介绍二、IOMMU1、DMA做地址翻译，用来解决DMA的安全性问题，DMA API同时肩负起了设置IOMMU的职责。2、做设备虚拟化直通。三、DMA-IOMMUIOMMU：DMA （iova）-&gt; memory port -&gt; iommu（pa） -&gt;  总线 -&gt; 内存控制器 存/取主存内容代码分析：设备attach iommu时install ops，arm64: iommu_dma_opsintel:  intel_dma_ops1、dma ops接口            dma_ops接口      功能      dma ops      iommu ops      iova分配                  alloc(*dev, size, *dma_handle, gfp)      申请物理页 + 申请iova + iommu mapm             map      Y              free(*dev, size, *vaddr, dma_handle, attr)      iommu unmap + 释放iova + 释放物理页             unmap      Y              alloc_pages(*dev, size, *dma_handle, dir, gfp)      申请dma连续物理页 + dma map_page      map_page             Y              free_pages(*dev, size, *vaddr, dma_handle, dir)      dma unmap_page + 释放连续物理页      unmap_page             Y              alloc_noncoherent(*dev, size, *dma_handle, dir, gfp)      与alloc_pages一致      noblock: map_page      block: map      Y              free_noncoherent(*dev, size, *vaddr, dma_handle, dir)      与free_pages一致      noblock: unmap_page      block: unmap      Y              mmap      mmu mmap                                   get_sgtable                                          map_page(*dev, *page, offset, size, dir, attrs)      申请iova + iommu map             map      Y              unmap_page(*dev, dma_handle, size, dir, attrs)      iommu unmap + 释放iova             unmap      Y              map_sg(*dev, *sg, nents, dir, attrs)      与map_page一致             map      Y              unmap_sg(*dev, *sg, nents, dir, attrs)      与unmap_page一致             unmap      Y              map_resource(*dev, phys, size, dir, attrs)      申请iova + iommu map                    Y              unmap_resource(*dev, dma_handle, size, dir, attrs)      iommu unmap + 释放iova                    Y              sync_single_for_cpu      iova_to_phys +  inv Dcache 保证cache一致性             iova_to_phys                     sync_single_for_device      iova_to_phys +  inv Dcache + clear Dcache 保证cache一致性             iova_to_phys                     sync_sg_for_cpu      与sync_single_for_cpu一致             iova_to_phys                     sync_sg_for_device      与sync_single_for_device一致             iova_to_phys                     cache_sync                                          dma_supported                                          get_required_mask                                          max_mapping_size                                          get_merge_boundary      获取iommu在使用的page size                           2、iommu ops            iommu  ops接口      功能      分类                  capable      check capability      iommu基础能力check              domain_alloc      allocate iommu domain      管理dev集合              domain_free      free iommu domain      管理dev集合              attach_dev      attach device to an  iommu domain      管理dev集合              detach_dev      detach device from an  iommu domain      管理dev集合               map      map a physically  contiguous memory region to an iommu domain      iommu page table操作              unmap      unmap a physically  contiguous memory region from an iommu domain      iommu page table操作              flush_iotlb_all      Synchronously flush all  hardware TLBs for this domain      iommu page table操作              iotlb_sync_map      Sync mappings created  recently using @map to the hardware      iommu page table操作              iotlb_sync      Flush all queued ranges  from the hardware TLBs and empty flush queue      iommu page table操作              iova_to_phys      translate iova to  physical address      iommu page table操作              probe_device      Add device to iommu  driver handling      管理dev集合              release_device      Remove device from  iommu driver handling      管理dev集合              probe_finalize      Do final setup work  after the device is added to an IOMMU group and attached to the groups domain      管理dev集合              device_group      find iommu group for a  particular device      管理dev集合              domain_get_attr      Query domain attributes      管理dev集合              domain_set_attr      Change domain  attributes      管理dev集合              support_dirty_log      Check whether domain  supports dirty log tracking      iommu page table操作              switch_dirty_log      Perform actions to  start|stop dirty log tracking      iommu page table操作              sync_dirty_log      Sync dirty log from  IOMMU into a dirty bitmap      iommu page table操作              clear_dirty_log      Clear dirty log of  IOMMU by a mask bitmap      iommu page table操作              get_resv_regions      Request list of  reserved regions for a device      iova预留              put_resv_regions      Free list of reserved  regions for a device      iova预留              apply_resv_region      Temporary helper  call-back for iova reserved ranges      iova预留              domain_window_enable      Configure and enable a  particular window for a domain      NA              domain_window_disable      Disable a particular  window for a domain      NA              of_xlate      add OF master IDs to  iommu grouping      NA              is_attach_deferred      Check if domain attach  should be deferred from iommu driver init to device driver init (default no)      管理dev集合              dev_has/enable/disable_feat      per device entries to  check/enable/disable iommu specific features.      管理dev集合              dev_feat_enabled      check enabled feature      iommu能力check              aux_attach/detach_dev      aux-domain specific  attach/detach entries.      aux              aux_get_pasid      get the pasid given an  aux-domain      aux              sva_bind      Bind process address  space to device      sva              sva_unbind      Unbind process address  space from device      sva              sva_get_pasid      Get PASID associated to  a SVA handle      sva              page_response      handle page request  response      sva              cache_invalidate      invalidate translation  caches      sva vfio              sva_bind_gpasid      bind guest pasid and mm      sva vfio              sva_unbind_gpasid      unbind guest pasid and  mm      sva vfio              attach_pasid_table      attach a pasid table      sva vfio              detach_pasid_table      detach the pasid table      sva vfio              bind_guest_msi      provides a stage1  giova/gpa MSI doorbell mapping      NA              unbind_guest_msi      withdraw a stage1  giova/gpa MSI doorbell mapping      NA              def_domain_type      device default domain type, return value      管理dev集合      dirty_log的使用HTTU Hardware Translation Table Update. The act of updating the Access flag or Dirtystate of a page in a given TTD which is automatically done in hardware, on anaccess or write to the corresponding page.参考：SMMU的spec 3.13 Translation table entries and Access/Dirty flags章节qemu/kvm dirty pages tracking in migrationQEMU&amp;KVM-2 Live Migration热迁移虚拟机还是要短暂停止的，只是时间很短，影响比较小，给人感觉服务没有中断。 dirty log就是记录哪些页被修改。DMA iommu的page write, live migrate dma dirty log trace if iommu support dirty log:live migrate start -&gt;  switch iommu dirty log on -&gt; sync dirty log to bitmap -&gt; clear dirty log -&gt;sync to qemu to copy memory"
  },
  
  {
    "title": "HugePages",
    "url": "/posts/linux-hugepages/",
    "categories": "linux, hugepages",
    "tags": "hugepages",
    "date": "2021-10-14 00:00:00 +0000",
    





    
    "snippet": "1 linux hugepage的目的减少tlb miss2 静态大页3 透明大页4 arm64特有：contiguous bit",
    "content": "1 linux hugepage的目的减少tlb miss2 静态大页3 透明大页4 arm64特有：contiguous bit"
  },
  
  {
    "title": "High Performance OS - shanango",
    "url": "/posts/High-Performance-OS-shanango/",
    "categories": "linux, shanango",
    "tags": "shanango",
    "date": "2021-10-14 00:00:00 +0000",
    





    
    "snippet": "一、论序Shenango  Achieving High CPU Efficiency for latency-sensitive dc workloads.pdf (526.36KB)https://github.com/shenango/shenangoIX A Protected Dataplane Operating System for High Throughput and Lo...",
    "content": "一、论序Shenango  Achieving High CPU Efficiency for latency-sensitive dc workloads.pdf (526.36KB)https://github.com/shenango/shenangoIX A Protected Dataplane Operating System for High Throughput and Low Latency.pdf (2.28MB)The IX Operating System Combining Low Latency, High Throughput, and efficiency in a protected dataplane.pdf (1.18MB)IX  A Protected Dataplane Operating System for High Throughput and Low Latency.pdf (371.23KB)https://github.com/ix-project/ixZygOS Achieving Low Tail Latency for microsecond-scale networked tasks.pdf (694.61KB)二、shenangohttps://zhuanlan.zhihu.com/p/360075148 知乎谬赞shenangohttps://tongtianta.site/paper/68031 论文中英翻译https://nan01ab.github.io/2019/03/Shinjuku-and-Shenango.html  Shinjuku and Shenango, New Network Stack and Optimizations//基本介绍\t\tShenango核心的重新分配的目的是为了给应用尽可能分配少的CPU核心，但是有不至于导致compute congestion的现象。    Shenango同时考虑线程和packet来探测compute congestion的信号，另外引入一个congestion detection algorithm来探明一个应用是否能从分配更多的核心中受益。这个算法要求细粒度的，高频率的观察每个应用的线程和packet排队情况。 所以这里Shenango引入了一个IOKernel，IOKernel指定一个核心运行的、忙轮询的进程，IOKernel运行在特权态。IOKernel通过忙轮询的方式在微秒级别的粒度观察观察每个应用的线程和packet排队情况。\t1 Shenango引入了一种packet steering机制。通过使用packet steering rules机制来快速实现核心的重新分配。\t2 应用运行在一个runtime中，通过共享内存和IOKernel交互。在应用启动的时候，runtime会创建多个内核线程(pthread)，每个内核线程有一个本地的runqueue。应用的逻辑使用一些保存在这些runqueue中的轻量级的用户基本的线程来运行。不同核心之间的负载均衡通过任务窃取的方式来处理。这里与go runtime有些类似，不过没有IOKernel，用户态线程这里称之为uthread，而内核态线程称之为kthread。    //IOKernel\t\tIOKernel组件运行在一个指定的核心上面，主要的作用有两个，一个是决定一个应用需要分配多少的CPU核心，要分配的话分配那一个CPU核心；另外一个就是Bypass Kernel的方式处理所有的网络IO。它通过忙轮询的方式直接轮询NIC的接受队列，然后将收到的数据包。由于IOKernel既要处理CPU核心的分配，又要处理网络数据包的转发，所以CPU核心的分配必须处理得很快，否则会降低数据处理的性能。 \t1 每个应用会有guaranteed cores以及burstable cores。前者可以理解为固定分配的，不用担心被抢占，而后者是根据需要分配的。一个kthread在自己的本地的runqueue中没有工作可以做的时候，代表这个进程在这个时间段内不需要这么多的CPU核心。应用会主动让出kthread，并通知IO Kernel。IOKernel可以在任何时候抢占一个burstable核心。\t2 在一个数据包达到一个应用的时候，如果没有被分配的核心，IO Kernel会立即分配一个。IOKernel使用congestion detection算法。这个计算基于两个元素，排队的线程和排队的ingress的数据包。任何一个队列中的item出现在连续的两个interval的时候，表明这个item至少排队了5us。对于发现可能处理拥塞状态的应用，IO Kernel会分配额外的核心。这些队列就使用ring buffer实现。在这之中通过头尾指针就可以其队列中表现出不同的interval。\t3 在具体分配给那一个核心的时候，IOKernel主要考虑三个因素。1. Hyper-threading efficiency，IO Kernel趋向于将分配在同一个物理核心的HyperThread上面，因为这样的缓存局部性更好。2. CaChe Locality，如果一个应用的数据已经在一个CPU核心的L1/L2中，则IOKernel会倾向于将其分配到对应的核心上面，3. Latency，在可能的情况下，肯定是优先选择分配空闲核心而不是忙的核心。        \tIOKernel忙轮询NIC的收入包队列，和应用的出队列，IOKernel可以直接将数据包传递给对应的应用。Shenango中，每个runtime都会配置自己的IP地址和Mac地址。在一个新的数据包达到的时候，通过参看数据包中的Mac地址即可得知对应的runtime。IOKernel通过RSS的方式在这个runtime中的CPU核心之间选择，将数据包放入其 ingress packet queue。engress队列也使用，轮询的方式可能导致很多的CPU占用，由于IOKernel可知kthread的活跃情况，它只需要轮询活跃的那一部分即可。        //runtime\truntime在IOKernel动态分配的CPU核心上面进行调度操作。在runtime初始化的时候，它会注册若干的kthreads到IO Kernel和对应的共享内存的区域作为packet queue。在IOKernel分配一个新的核心的时候，它会唤醒一个对应rumtime的kthread，并绑定到指定CPU核心上面。这个的runtime的结构是每个thread一个队列，并加上work stealing机制来实现负载均衡。这个和GO的runtime类似。————————————————————————————————————————————引用：https://nan01ab.github.io/2019/03/Shinjuku-and-Shenango.htmlShenango致力于实现三个目标的系统：1）微秒级的端到端延迟和数据中心应用程序的高吞吐量；2）多核机器上应用程序的CPU高效能；3）应用程序开发人员的高生产率，由于同步I/O和标准编程抽象，例如轻量级线程和阻塞TCP网络套接字。————————————————————————————————————————————引用：https://zhuanlan.zhihu.com/p/3600751481、Shenango实现cpu的动态分配，提高cpu的利用率。cpu均衡的时间在5us以内，而内核通用的均衡是在ms级。2、网络bypass kernel， IOKernel通过IP+Mac将数据包转发给对应的应用。总之、实现CPU高利用率和保持低尾延迟。三、 数据中心应用特性1、what is Datacenter workloads?2、具备的特点：四、代码分析1、iokernel//iokernel 独立核跑的后面进程    //main    \t-&gt; dataplane_loop    \t\t-&gt; cores_adjust_assignments //每5us执行一次2、runtime//runtime 链接时使用__real_main __wrap_main //what is? https://blog.csdn.net/gzxb1995/article/details/119880109 包装函数__wrap_main //shim/entry.c    -&gt;runtime_init //runtime/init.c3、iokernel和runtime联系 – AF_UNIX socket//\\0/control/iokernel.sockioqueues_register_iokernel //runtime/ioqueues.c  五、总结1 场景痛点    目前数据中心的微妙级延迟的解决方案是bypass-kernel,但是需要专用的cpu自旋轮询网卡，在中低负载下，会存在cpu浪费。Shenango实现了低延迟，但CPU使用效率更高。    2 技术思路    \t以非常精细的粒度（每5µs）在应用程序之间重新分配内核，从而使对延迟敏感的应用程序未使用的周期可以处理其他事。它可以通过一种高效的算法来检测应用程序何时从更多的内核中受益，以及一种运行在专用内核上的特权组件，称为IOKernel，协调内核的重新分配，从而实现如此快速的重新分配速率。    3 方案细节     Shenango引入一个congestion detection algorithm来探明一个应用是否能从分配更多的核心中受益。这个算法要求细粒度的，高频率的观察每个应用的线程和packet排队情况。 所以这里Shenango引入了一个IOKernel，IOKernel指定一个核心运行的、轮询的进程，IOKernel运行在特权态。IOKernel通过忙轮询的方式在微秒级别的粒度观察观察每个应用的线程和packet排队情况。\t1 cpu重新分配：引入了一种packet steering机制。通过使用packet steering rules机制来快速实现核心的重新分配。\t2 Lightweight Threading：运行在一个runtime中，通过共享内存和IOKernel交互。在应用启动的时候，runtime会创建多个内核线程(pthread)，每个内核线程有一个本地的runqueue。应用使用一些保存在这些runqueue中的轻量级的用户线程来运行。不同核心之间的负载均衡通过任务窃取的方式来处理。    IOKernel：   \tIOKernel组件运行在一个指定的核心上面，主要的作用有两个，一个是决定一个应用需要分配多少的CPU核心，要分配的话分配那一个CPU核心；另外一个就是Bypass Kernel的方式处理所有的网络IO。它通过忙轮询的方式直接轮询NIC的接受队列，然后将收到的数据包。由于IOKernel既要处理CPU核心的分配，又要处理网络数据包的转发，所以CPU核心的分配必须处理得很快，否则会降低数据处理的性能。     runtime:    在runtime初始化之后，一般的syscall也是可以使用的，但是最好不要使用会Blocking的syscall。runtime在IOKernel动态分配的CPU核心上面进行调度操作。在runtime初始化的时候，它会注册若干的kthreads到IO Kernel和对应的共享内存的区域作为packet queue。在IOKernel分配一个新的核心的时候，它会唤醒一个对应rumtime的kthread，并绑定到指定CPU核心上面。runtime使用run-to-completion的机制，可以让一个uthread一直运行到资源地让出。        4 有益效果+───────────+────────────────────+────────────────────────+─────────────────────+| system    | Kernel-bypass net  | Lightweight Threading  | Balancing Interval  |+───────────+────────────────────+────────────────────────+─────────────────────+| Linux     | N                  | N                      | 4ms                 || Arachne   | N                  | Y                      | 50ms                || ZygOS     | Y                  | N                      | N/A                 || Shenango  | Y                  | Y                      | 5us                 |+───────────+────────────────────+────────────────────────+─────────────────────+有比Arachne较低的Balancing Interval。 kernel-bypass net借鉴ZygOS低延。    5 方案缺陷 runtime来实现Lightweight Threading, hack pthread、mutex、sem, 比较定制。 系统本身要保证无其他应用和业务进程的干扰。cpu的动态分配其实就thread的分配和绑定。        6 借鉴意义               other、补充1、go runtimehttps://zhuanlan.zhihu.com/p/95056679  万字长文深入浅出 Golang Runtime2、dpdkhttps://zhuanlan.zhihu.com/p/272722355 DPDK 分析，原理以及学习路线3、Arachnehttps://nbjl.nankai.edu.cn/2020/0306/c12124a266839/page.htm NBJL 2020论文导读7：Arachne Core Aware Thread Management4、gc Garbage Collection"
  },
  
  {
    "title": "High Performance OS - Intel HPC kernel mOS",
    "url": "/posts/Intel-HPC-mOS/",
    "categories": "linux, mOS",
    "tags": "mOS",
    "date": "2021-09-22 00:00:00 +0000",
    





    
    "snippet": "一、 简介​\tIntel不仅是最大的CPU公司，还是全球最大的软件公司之一，10万员工中有1.5万都是软件工程师。在OS系统上，Intel也开发了多种系统了，现在最新产品是mOS，一款专用于HPC超算的高性能Linux变种。Intel的mOS系统很少人关注，官方透露的细节也不多，目前还在开发中，主要用于高性能计算，在超算负载中可以提供更好的并行性及可靠性。​\tmOS系统依然会基于Linux扩...",
    "content": "一、 简介​\tIntel不仅是最大的CPU公司，还是全球最大的软件公司之一，10万员工中有1.5万都是软件工程师。在OS系统上，Intel也开发了多种系统了，现在最新产品是mOS，一款专用于HPC超算的高性能Linux变种。Intel的mOS系统很少人关注，官方透露的细节也不多，目前还在开发中，主要用于高性能计算，在超算负载中可以提供更好的并行性及可靠性。​\tmOS系统依然会基于Linux扩展而来，目前最新版0.8版使用的是Linux 5.4 LTS内核，但它又有自己的LWK轻量级内核，Linux内核管理少量部分CPU核心，以确保兼容性，LWK内核管理系统其他部分，类似Mutil-OS多OS。​\tIntel的mOS已经在ASCI Red，IBM Blue Gene等超算上应用，不过它最终的目标是用于2021年的百亿亿次超算Aurora上，后者采用了未来一代的Intel至强可扩展处理器、Intel Xe计算架构、Intel未来一代的傲腾DC可持续内存、Intel One API软件等。该超算同时采用Cray的新一代超算平台“Shasta”，由超过200个机柜组成，支持Cray Slingshot高性能可扩展互连架构，并在软件堆栈方面针对Intel架构进行专门优化。二、mOS内存管理1：什么是MosMos是一款intel 开发的，针对HPC场景优化的os，目前已经开源，其开源网址为https://github.com/intel/mOS。 2：Mos和linux kernel的区别。Mos 是在linux kernel的根目录下面加了一个mos的文件夹，里面放的是Mos的主要文件，总结一下，Mos就是内嵌到linux kernel中的一个轻量级os. 3: Mos 的工作原理 通过命令行参数 lwkcpus 和lwkmem 来隔离内存和cpu，或则通过lwkctl 来在linux kernel启动后来隔离cpu和内存。其中lwkcpus的使用举例如下 lwkcpus=&lt;syscall cpu1&gt;.&lt;lwkcpu set1&gt;:&lt;syscall cpu2&gt;.&lt;lwkcpu set2&gt;... For example: lwkcpus=28.1-13,29-41:42.15-27,43-55 https://github.com/intel/mOS/wiki/mOS-for-HPC-v0.8-Administrator's-GuideThe following parameters and values are recommended for mOS for HPC.  Not all combinations and variations of boot parameters have been validated and tested.  Boot failure is possible if, for example, lwkcpus and lwkmem are not properly set for your system. The lwkcpus and lwkmem parameters can be omitted and the lightweight kernel partition created after booting using the lwkctl command. Please refer to Documentation/kernel-parameters.txt in the mOS for HPC kernel source for further details.4:应用怎么运行到Mos上正常不加任何前缀的话，应用运行在linux kernel上，加yod的话，应用运行在Mos中https://github.com/intel/mOS/wiki/mOS-for-HPC-v0.8-User's-Guide The yod utility of mOS is the fundamental mechanism for spawning LWK processes.  The syntax is: yod yod-arguments program program-arguments 5：linux kernel 和Mos的关系————————————————版权声明：本文为CSDN博主「tiantao2012」的原创文章，遵循CC 4.0 BY-SA版权协议，转载请附上原文出处链接及本声明。原文链接：https://blog.csdn.net/tiantao2012/article/details/113852469lwkcpu=8.9-15 lwkmem=0:128G,1:128Glwk_config_lwkmem //入参为NULL,destroy mem;反之create.    -&gt;if param_value == NULL ? lwkmem_partition_destroy : lwkmem_partition_create1、lwkmem_partition_create创建lwkmem partition#define __ATTR_RW(_name) __ATTR(_name, 0644, _name##_show, _name##_store)static struct kobj_attribute lwk_config_attr = __ATTR_RW(lwk_config);-&gt;lwk_config_store lwk_config_show///strcmp(s_keyword, \"lwkmem\")lwk_config_store    -&gt;lwk_config_lwkmem      //系统启动rest_init\t-&gt;kernel_init //在free_initmem之后\t\t-&gt;lwkctl_def_partition    \t\t-&gt;lwk_config_lwkmemlwkmem_partition_create    -&gt;lwkmem_parse_args //spec参数，解析mos_lwkmem_nodes, mos_lwkmem_size信息.    -&gt;mos_mem_init1)mos_mem_init初始化内存mos_mem_init    -&gt;for_each_node_mask  allocate_memory_from_linux(nid, req_size)    //申请的nid上内存记录在static struct lwkmem_designated lwkmem[MAX_NUMNODES];中    /* * lwkmem[MAX_NUMNODES], *   Used to track all the physical memory ranges designated to LWK. *   An element at index N gives the lwkmem_designated structure that *   embeds the list head for all designated memory granules and *   keeps the counters that indicate number of free and available *   memory in terms of pages on that NUMA node. *               *   lwkmem[NID]           lwkmem_granule         lwkmem_granule *   +--------------+      +-----------------+    +-----------------+ *   | list         |-----&gt;| list_designated |---&gt;| list_designated | *   | n_resv_pages |      | list_reserved   |    | list_reserved   | *   | n_free_pages |      | base            |    | base            | *   +--------------+      | length          |    | length          | *                         | owner           |    | owner           | *                         +-----------------+    +-----------------+ */ //mOS/lwkmem/pma_buddy.cstatic struct lwk_pm_factory_operations pma_buddy_factory_ops = {        .alloc_pma = alloc_pma_buddy,        .free_pma = free_pma_buddy};static struct lwk_pm_operations pma_buddy_ops = {        .alloc_pages = buddy_alloc_pages,        .free_pages = buddy_free_pages,        .split_page = buddy_split_page,        .report = buddy_report,        .meminfo = buddy_meminfo,        .setup = buddy_setup};//注册pma操作，申请、释放、拆分、报告、统计、setuppma_buddy_init    -&gt;register_lwk_pma  //pm_registered_opslwkmem_early_init\t-&gt;mos_register_process_callbacks //mos_process_callbacks//lwkmem_callbacks回调来执行lwkmem_process_start申请lwkmemstatic struct mos_process_callbacks_t lwkmem_callbacks = {        .mos_process_init = lwkmem_process_init,        .mos_process_start = lwkmem_process_start,        .mos_process_exit = lwkmem_process_exit,};  lwkmem_process_start    -&gt;start_lwk_mm        -&gt;| curr_lwk_mm        -&gt;| lwk_mm_set_mempolicy_info        -&gt;| [Assigning Values] //lwk_mm-&gt;pma = pma_buddy_factory_ops-&gt;alloc_pma; lwk_mm-&gt;pm_ops = pma_buddy_ops        -&gt;| pma_buddy_ops-&gt;setupMOS_SYSFS_CPU_WO(lwkcpus_request);static struct mos_sysfs_mask_write_op name##_mask_op = {        \\    .parser = cpumask_parse,                                \\    .operation = _##name##_set,                             \\ ///here};  _lwkcpus_request_set\t-&gt;mos_get_process //给进程设置mos_process  current-&gt;mos_processstatic struct kobj_attribute lwkmem_request_attr = __ATTR_WO(lwkmem_request);lwkmem_request_store    -&gt;lwkmem_request        -&gt;allocate_lwk_mm //lwk_mm-&gt;vm_ops = &amp;lwk_vm_ops;            -&gt;set_lwk_mm //设置给进程    //mOS/lwkmem/mm.cstatic struct lwk_vm_operations lwk_vm_ops = {        .get_unmapped_area      = lwk_mm_get_unmapped_area,        .unmap_page_range       = lwk_mm_unmap_pages,        .move_page_tables       = lwk_mm_move_page_tables,        .change_protection      = lwk_mm_change_protection,        .follow_page            = lwk_mm_follow_page,        .page_fault             = lwk_mm_page_fault,        .alloc_pages_vma        = lwk_mm_alloc_pages_vma,        .vma_adjust             = lwk_mm_vma_adjust,        .populated              = lwk_mm_vma_populated,        .fork                   = lwk_mm_fork,        .clear_heap             = lwk_mm_clear_heap,        .elf_map                = lwk_mm_elf_map,};//include/linux/moslwkmem.h#define lwkmem_get_unmapped_area_ops() \\                curr_lwk_mm()-&gt;vm_ops-&gt;get_unmapped_area#define lwkmem_page_fault(vma, addr, flags)\\                vma_lwk_mm(vma)-&gt;vm_ops-&gt;page_fault(vma, addr, flags)#define lwkmem_unmap_range(vma, start, end)\\                vma_lwk_mm(vma)-&gt;vm_ops-&gt;unmap_page_range(vma, start, end)#define lwkmem_change_protection_range(vma, start, end, prot) \\                vma_lwk_mm(vma)-&gt;vm_ops-&gt;change_protection(vma, start, end, \\                                                           prot)#define lwkmem_vma_adjust(vma, start, end) \\                vma_lwk_mm(vma)-&gt;vm_ops-&gt;vma_adjust(vma, start, end)#define lwkmem_follow_page(vma, addr, flags, pagemask) \\                vma_lwk_mm(vma)-&gt;vm_ops-&gt;follow_page(vma, addr, flags, pagemask)#define lwkmem_move_page_tables(old_vma, old_addr, new_vma, new_addr, len) \\                vma_lwk_mm(old_vma)-&gt;vm_ops-&gt;move_page_tables(old_vma, \\                                                old_addr, new_vma, new_addr,\\                                                len)#define lwkmem_populated(vma) \\                vma_lwk_mm(vma)-&gt;vm_ops-&gt;populated(vma)#define lwkmem_fork(oldvma, newvma) \\                vma_lwk_mm(oldvma)-&gt;vm_ops-&gt;fork(oldvma, newvma)#define lwkmem_clear_heap(vma, oldbrk, newbrk) \\                vma_lwk_mm(vma)-&gt;vm_ops-&gt;clear_heap(vma, oldbrk, newbrk)#define lwkmem_elf_map(s, len, fp, off, addr, sz, tsz) \\                curr_lwk_mm()-&gt;vm_ops-&gt;elf_map(s, len, fp, off, addr, sz, tsz)2、lwkmem_partition_destroy销毁lwkmem partition三、how use? yod问题2： syscall cpu1/utility_cpus 怎么使用，处理syscall 什么意思？syscall 指令：https://man7.org/linux/man-pages/man2/syscall.2.htmlsyscall调用流程：http://gityuan.com/2016/05/21/syscall///mOS/mos.cyod -&gt; 调用sysfs接口_lwkcpus_request_set\tcpumask_or(current-&gt;mos_process-&gt;utilcpus, current-&gt;mos_process-&gt;utilcpus, utility_cpus_map); //utilcpuscopy_process:2087 这个写的也太详细了： http://gityuan.com/2017/08/05/linux-process-fork/sched_fork -&gt; .task_fork//.task_fork              = task_fork_mos,// Called on fork with the child task as argument from the parent's context//- child not yet on the tasklist//- preemption disabledtask_fork_mos    -&gt;|push_utility_threads        -&gt;||select_linux_utility_cpus //选择utility_cpus的CPU        -&gt;||push_to_linux_scheduler //push到linux调度域？    -&gt;|set_utility_cpus_allowed问题3： lwkcpu的调度是个简化版，具体原理？http://www.wowotech.net/process_management/447.html //调度类实现https://linuxtoy.org/archives/bfs-intro-future-of-linux-desktop-kernel.html 脑残调度器CPU拓扑结构存在下面三个level（SMT level最低）：SMT Level 超线程处理器的一个核心MC Level 多核CPU的一个核心DIE Level 一个物理CPU的晶片（注意不是package，package是封装好了的，肉眼看到的CPU处理器）cpu最小级别的就是超线程处理器的一个smt核，次小的一级就是一个多核cpu的核，然后就是一个物理cpu封装，再往后就是cpu阵列，根据这些cpu级别的不同，Linux将所有同一级别的cpu归为一个“调度组”，然后将同一级别的所有的调度组组成一个“调度域”cpu最小级别的就是超线程处理器的一个smt核，次小的一级就是一个多核cpu的核，然后就是一个物理cpu封装，再往后就是cpu阵列，根据这些cpu级别的不同，Linux将所有同一级别的cpu归为一个“调度组”，然后将同一级别的所有的调度组组成一个“调度域”对于ARM 架构，目前由于不支持超线程技术，只有DIE和MC两个Topology Level————————————————原文链接：https://blog.csdn.net/wukongmingjing/article/details/81664820 调度域和调度组  16  *  kernel/sched/mos.c  17  *  18  * When executing on a CPU that has been designated to be an LWK CPU, all tasks  19  * are managed by the mOS scheduler. However, the tasks within the mOS  20  * scheduler must occasionally interact with the Linux scheduler. For  21  * example, a Linux/mOS task may be blocked on a mutex held by a mOS/Linux task  22  * and will need to be awakened when the resource is released. Also when an  23  * mOS process is executing on an Linux core due to evanescence, this task must  24  * obey the rules of the linux scheduler. This file contains the mOS scheduler  25  * and the mos scheduler class that allow the the two schedulers to  26  * interoperate.      在指定为LWK CPU的CPU上执行时，所有任务都由mOS调度程序管理。但是，mOS调度程序中的任务偶      尔必须与Linux调度程序交互。例如，Linux/mOS任务可能会在mOS/Linux任务持有的互斥体上被阻      止，并且需要在释放资源时唤醒。此外，当mOS进程因消失而在Linux核心上执行时，此任务必须遵      守linux调度程序的规则。此文件包含允许两个调度程序互操作的mOS调度程序和mos调度程序类。const struct sched_class mos_sched_class         __attribute__((section(\"__mos_sched_class\"))) = {        .enqueue_task           = enqueue_task_mos,        .dequeue_task           = dequeue_task_mos,        .yield_task             = yield_task_mos,        .check_preempt_curr     = check_preempt_curr_mos,        .pick_next_task         = pick_next_task_mos,        .put_prev_task          = put_prev_task_mos,#ifdef CONFIG_SMP        .balance                = balance_mos,        .select_task_rq         = select_task_rq_mos,        .set_cpus_allowed       = set_cpus_allowed_mos,        .rq_online              = rq_online_mos,        .rq_offline             = rq_offline_mos,        .task_woken             = task_woken_mos,        .switched_from          = switched_from_mos,#endif        .set_next_task          = set_next_task_mos,        .task_tick              = task_tick_mos,        .get_rr_interval        = get_rr_interval_mos,        .prio_changed           = prio_changed_mos,        .switched_to            = switched_to_mos,        .update_curr            = update_curr_mos,        .task_fork              = task_fork_mos,};    抓个lwkcpu的调度轨迹？static struct mos_process_callbacks_t lwksched_callbacks = {        .mos_process_init = lwksched_process_init,        .mos_process_start = lwksched_process_start,        .mos_thread_exit = lwksched_thread_exit,        .mos_process_exit = lwksched_process_exit,};lwksched_mod_init    -&gt;|mos_register_process_callbacks lwksched_callbacks        static struct mos_process_callbacks_t lwkmem_callbacks = {        .mos_process_init = lwkmem_process_init,        .mos_process_start = lwkmem_process_start,        .mos_process_exit = lwkmem_process_exit,}; subsys_initcall lwkmem_early_init    -&gt;mos_register_process_callbacks lwkmem_callbacks定论1：lwkcpu只能一个program使用//mOS/tools/yod/mos_plugin.cstruct yod_plugin mos_plugin = {        .get_designated_lwkcpus = mos_get_designated_lwkcpus,        .get_reserved_lwk_cpus = mos_get_reserved_lwk_cpus,        .request_lwk_cpus = mos_request_lwk_cpus,        .set_util_threads = mos_set_util_threads,        .map_cpu = mos_map_cpu,        .get_designated_lwkmem = mos_get_designated_lwkmem,        .get_reserved_lwkmem = mos_get_reserved_lwkmem,        .request_lwk_memory = mos_request_lwk_memory,        .get_numa_nodes_online = mos_get_numa_nodes_online,        .lock = mos_combo_lock,        .unlock = mos_combo_unlock,        .get_distance_map = mos_get_distance_map,        .lwkcpus_sequence_request = mos_lwkcpus_sequence_request,        .set_options = mos_set_options,        .set_lwkmem_mempolicy_info = mos_set_lwkmem_mempolicy_info,        .get_mos_view = mos_get_mos_view,        .set_mos_view = mos_set_mos_view,        .get_lwk_processes = mos_get_lwk_processes,};//kernel/fork.c//都是通过调用execvp直接继承设置的属性， 先通过提供的sys接口设置current task_struct里面的mos_process使用lwkcpu和lwkmem。lwk_mm_fork.dup_mmap    -&gt;lwkmem_fork    \t-&gt;lwk_mm_fork  //CLONE_THREAD 继承父进程的mos_process.static __latent_entropy struct task_struct *copy_process(...{    ...2199:  #ifdef CONFIG_MOS_FOR_HPC        if (clone_flags &amp; CLONE_THREAD) {                /* A copy of an LWK thread is also an LWK thread. */                p-&gt;mos_flags = current-&gt;mos_flags;                p-&gt;mos_process = current-&gt;mos_process;                if (current-&gt;mos_process)                        atomic_inc(&amp;current-&gt;mos_process-&gt;alive);        } else {                /* A copy of an LWK process is not an LWK process. */                p-&gt;mos_flags = current-&gt;mos_flags &amp; ~MOS_IS_LWK_PROCESS;                p-&gt;mos_process = NULL;                /* All Linux processes inherit the mOS view from its parent.                 * The child process can override its view later by writing to                 * its /proc/self/mos_view or by some other process writing to                 * /proc/&lt;pid&gt;/mos_view                 *                 * This rule is not applicable to LWK processes. The child                 * process starts off with the default view and does not in-                 * -herit view from its parent LWK process.                 *                 * No need to lock child process since it is not yet active.                 */                if (is_mostask())                        SET_MOS_VIEW(p, MOS_VIEW_DEFAULT);        }#endif       ...}   //mOS/tools/yod/yod.c四、lwkmem内存管理数据结构五、MPI 跨域通信https://www.codenong.com/10542284/Open MPI功能的方式是将其分为多个层，并且每个层的功能由动态加载的多个模块提供。有一种计分机制可以在特定条件下选择最佳模块。所有MPI实现都提供一种进行所谓SPMD启动的机制。本质上，MPI应用程序是SPMD(单程序多数据)的一种特殊类型-运行单个可执行文件的多个副本，并将消息传递用作通信和协调的机制。 SPMD启动器获取执行节点列表，远程启动流程并在它们之间建立关联和通信方案(在Open MPI中，这称为MPI Universe)。它是创建全局MPI通信器MPI_COMM_WORLD并分配初始等级分配的一种，它可以提供诸如将进程绑定到CPU内核的选项(在NUMA系统上非常重要)。一旦启动了进程，则可以使用某种识别机制(例如，等级与IP地址/ TCP端口之间的映射)，可以采用其他寻址方案。例如，开放式MPI使用ssh，rsh启动远程进程，也可以使用其他资源管理系统提供的机制(例如PBS / Torque，SLURM，Grid Engine，LSF ...)。一旦进程启动并且它们的IP地址和端口号在Universe中记录和广播，进程就可以在其他(更快)网络上找到彼此，例如InfiniBand，并在它们之间建立通信路由。路由消息通常不是由MPI自己完成的，而是留给底层的通信网络。 MPI仅负责构造消息，然后将它们传递到网络以传递到目的地。对于驻留在同一节点上的进程之间的通信，通常使用共享内存。问题一： HPC应用的特点？ 通信的主要用途是什么？ 关乎内存管理算法？问题二：等待队列？lwk域是否能使用？openMPI mpirun四个线程：Thread 1是主线程，在启动业务进程运行后，调用poll等待业务进程运行结束。业务进程结束后，Thread 1完成清理工作退出。Thread 2是progress thread，负责进程之间的异步通信，提供非阻塞的通信功能。线程启动后，会调用epoll_wait等待事件的到来。Thread 3是本地连接监听线程，负责建立本地连接。线程启动后，调用select等待事件。Thread 4是tcp监听线程，负责建立tcp连接。线程启动后，调用select等待事件。mpirun运行的后台线程是mpi进程间通信必不可少的，它们都有一个共同的特点，就是大部分时间都处于阻塞状态，没有在运行。这和lwk相性不佳，lwk上运行的线程是资源独占（CPU + 内存）的，直到退出才会释放资源，如果mpirun的后台线程在lwk上运行，会造成计算资源的浪费。另外对于进程间的通信，同步通信在lwk域内就可以完成，但是异步通信需要跨域进行（需要和progress thread交互），从这点来看，“跨域”确实可能会对通信造成一定的影响。    HPCG：高性能共轭梯度计算，超算性能的标准测试套。主要涉及 计算、访存、进程通信，一般要达到高性能，都需要针对CPU架构进行专门的优化，包括数据结构，代码流程，甚至是指令级别的优化。intel针对自己的CPU架构做了MPI + hpcg的优化，如果要在intel的CPU上达到高性能，需要使用intel oneapi + intel hpcg。    目前来看，lwk和MPI进程通信的相性不是很好：在lwk上运行的线程，可能会被MPI进程通信阻塞，而当前线程占用的CPU资源是无法让给其他线程运行的，这就会造成CPU资源的浪费。这个问题有两个思路，一是使用MPI_Isend类似的接口，这是MPI提供的非阻塞调用，但是需要修改程序，兼容性很差；二是正面从架构上解决这个问题，目前mOS这种隔离运行的方式太过死板了（但应该是为了性能考虑），CPU资源其实是进程独占，而不是简单的lwk域独占，一旦进程被I/O阻塞，进程占有的整个CPU资源就都被浪费掉了。crc计算卸载到计算域？那这个cpu预留就削减整体的性能了？    如何快速的动态隔离出域？    2个CPU处理一个ready队列， 2个核进行抢锁，    https://cloud.tencent.com/developer/article/1517909 MuqSS调度器 有意思！！2个cpu绑在一起，来并行两个调度类。cpu active状态设置为其他状态，隔离起来？    1) 局部的最优解    2) 减小load balance的锁粒度"
  },
  
  {
    "title": "Interesting Kernel Scheduler - BFS",
    "url": "/posts/Interesting-scheduler-BFS/",
    "categories": "linux, BFS",
    "tags": "BFS",
    "date": "2021-09-21 00:00:00 +0000",
    





    
    "snippet": "一、BFShttps://cloud.tencent.com/developer/article/1517909  知乎介绍， 很有意思http://kernel.meizu.com/bfs-porting.html 魅族移植，看看就行二、改进MuQSS附：http://ck.kolivas.org/patches/ 补丁三、脑残调度器，其中skiplist想法很有意思",
    "content": "一、BFShttps://cloud.tencent.com/developer/article/1517909  知乎介绍， 很有意思http://kernel.meizu.com/bfs-porting.html 魅族移植，看看就行二、改进MuQSS附：http://ck.kolivas.org/patches/ 补丁三、脑残调度器，其中skiplist想法很有意思"
  },
  
  {
    "title": "Numactl",
    "url": "/posts/numactl/",
    "categories": "Package, Numactl",
    "tags": "Numactl",
    "date": "2021-09-10 00:00:00 +0000",
    





    
    "snippet": "numactl github:https://github.com/numactl/numactl一 NUMA技术https://blog.csdn.net/don_chiang709/article/details/100735052NUMA技术将CPU划分成不同的组（Node)，每个Node由多个CPU组成，并且有独立的本地内存、I/O等资源。Node之间通过互联模块连接和沟通，因此除了...",
    "content": "numactl github:https://github.com/numactl/numactl一 NUMA技术https://blog.csdn.net/don_chiang709/article/details/100735052NUMA技术将CPU划分成不同的组（Node)，每个Node由多个CPU组成，并且有独立的本地内存、I/O等资源。Node之间通过互联模块连接和沟通，因此除了本地内存外，每个CPU仍可以访问远端Node的内存，只不过效率会比访问本地内存差一些，我们用Node之间的距离（Distance，抽象的概念）来定义各个Node之间互访资源的开销。**Node-&gt;Socket-&gt;Core-&gt;Processor**随着多核技术的发展，将多个CPU封装在一起，这个封装被称为插槽Socket；Core是socket上独立的硬件单元；通过intel的超线程HT技术进一步提升CPU的处理能力，OS看到的逻辑上的核数Processor。**socket = node**socket是物理概念，指的是主板上CPU插槽；node是逻辑概念，对应于socket。**core = 物理CPU**core是物理概念，一个独立的硬件执行单元，对应于物理CPU；https://www.cnblogs.com/machangwei-8/p/10402644.html由于SMP在扩展能力上的限制，人们开始探究如何进行有效地扩展从而构建大型系统的技术，NUMA就是这种努力下的结果之一。利用NUMA技术，可以把几十个CPU(甚至上百个CPU)组合在一个服务器内。NUMA服务器的基本特征是具有多个CPU模块，每个CPU模块由多个CPU(如4个)组成，并且具有独立的本地内存、I/O槽口等。由于其节点之间可以通过互联模块(如称为Crossbar Switch)进行连接和信息交互，因此每个CPU可以访问整个系统的内存(这是NUMA系统与MPP系统的重要差别)。显然，访问本地内存的速度将远远高于访问远地内存(系统内其它节点的内存)的速度，这也是非一致存储访问NUMA的由来。由于这个特点，为了更好地发挥系统性能，开发应用程序时需要尽量减少不同CPU模块之间的信息交互。利用NUMA技术，可以较好地解决原来SMP系统的扩展问题，在一个物理服务器内可以支持上百个CPU。比较典型的NUMA服务器的例子包括HP的Superdome、SUN15K、IBMp690等。每个CPU模块之间都是通过互联模块进行连接和信息交互，CPU都是互通互联的，同时，每个CPU模块平均划分为若干个Chip（不多于4个），每个Chip都有自己的内存控制器及内存插槽。在NUMA中还有三个节点的概念：1）、本地节点:对于某个节点中的所有CPU，此节点称为本地节点。2）、邻居节点:与本地节点相邻的节点称为邻居节点。3）、远端节点:非本地节点或邻居节点的节点，称为远端节点。4）、邻居节点和远端节点,都称作非本地节点(Off Node)。CPU访问不同类型节点内存的速度是不相同的，访问本地节点的速度最快，访问远端节点的速度最慢，即访问速度与节点的距离有关，距离越远访问速度越慢，此距离称作Node Distance。应用程序要尽量的减少不通CPU模块之间的交互，如果应用程序能有方法固定在一个CPU模块里，那么应用的性能将会有很大的提升。https://www.xiexianbin.cn/linux/commands/numactl/index.htmlnumactl使用方法二、 numactl使用的syscallnumactl用于设置进程的调度或内存绑定策略，所有子项继承设置的策略。此外，它还可以设置共享内存段或文件的内存策略。该工具可用于查看当前服务器的NUMA节点配置、状态，可通过该工具将进程绑定到指定CPU core，由指定CPU core来运行对应进程。https://linux.die.net/man/（1）set_mempolicy设置进程的默认numa策略。//set default NUMA memory policy for a process and its children#include &lt;numaif.h&gt;int set_mempolicy(int mode, unsigned long *nodemask, unsigned long maxnode);Link with -lnuma.（2）get_mempolicy获取进程的numa策略。//retrieves the NUMA policy of the calling thread or of a memory address, depending on the setting of flags.#include &lt;numaif.h&gt;int get_mempolicy(int *mode, unsigned long *nodemask, unsigned long maxnode, unsigned long addr, unsigned long flags);Link with -lnuma.（3）mbind设置内存的内存策略。//set memory policy for a memory range#include &lt;numaif.h&gt;int mbind(void *addr, unsigned long len, int mode, unsigned long *nodemask, unsigned long maxnode, unsigned flags);Link with -lnuma.（4）migrate_pages迁移所有的page到另一个node上。//move all pages in a process to another set of nodes#include &lt;numaif.h&gt;long migrate_pages(int pid, unsigned long maxnode, const unsigned long *old_nodes, const unsigned long *new_nodes);Link with -lnuma.（5）move_pages迁移单个page到另一个node上。//move individual pages of a process to another node#include &lt;numaif.h&gt;long move_pages(int pid, unsigned long count, void **pages, const int *nodes, int *status, int flags);Link with -lnuma.（6）sched_setaffinity/sched_getaffinity设置/获取进程CPU亲和性Mask;若pid = 0? calling process的CPU亲和性Mask？//set and get a process's CPU affinity mask;If pid is zero, then the mask of the calling process is returnedint sched_setaffinity(pid_t pid, size_t cpusetsize, cpu_set_t *mask);int sched_getaffinity(pid_t pid, size_t cpusetsize, cpu_set_t *mask);numactl [--interleave nodes] [--preferred node] [--membind nodes] [--cpunodebind nodes] [--physcpubind cpus] [--localalloc] [--] {arguments ...}numactl --shownumactl --hardwarenumactl [--huge] [--offset offset] [--shmmode shmmode] [--length length] [--strict][--shmid id] --shm shmkeyfile | --file tmpfsfile[--touch] [--dump] [--dump-nodes] memory policy三、numactl命令行usage: numactl [--all | -a] [--interleave= | -i &lt;nodes&gt;] [--preferred= | -p &lt;node&gt;]               [--physcpubind= | -C &lt;cpus&gt;] [--cpunodebind= | -N &lt;nodes&gt;]               [--membind= | -m &lt;nodes&gt;] [--localalloc | -l] command args ...       numactl [--show | -s]       numactl [--hardware | -H]       numactl [--length | -l &lt;length&gt;] [--offset | -o &lt;offset&gt;] [--shmmode | -M &lt;shmmode&gt;]               [--strict | -t]               [--shmid | -I &lt;id&gt;] --shm | -S &lt;shmkeyfile&gt;               [--shmid | -I &lt;id&gt;] --file | -f &lt;tmpfsfile&gt;               [--huge | -u] [--touch | -T]                memory policy | --dump | -d | --dump-nodes | -Dmemory policy is --interleave | -i, --preferred | -p, --membind | -m, --localalloc | -l&lt;nodes&gt; is a comma delimited list of node numbers or A-B ranges or all.Instead of a number a node can also be:  netdev:DEV the node connected to network device DEV  file:PATH  the node the block device of path is connected to  ip:HOST    the node of the network device host routes through  block:PATH the node of block device path  pci:[seg:]bus:dev[:func] The node of a PCI device&lt;cpus&gt; is a comma delimited list of cpu numbers or A-B ranges or allall ranges can be inverted with !all numbers and ranges can be made cpuset-relative with +the old --cpubind argument is deprecated.use --cpunodebind or --physcpubind instead&lt;length&gt; can have g (GB), m (MB) or k (KB) suffixes      1 交织分配模式使用 --interleave 参数，如占用内存的mongodb程序，共享所有 node 内存：numactl --interleave=all mongod -f /etc/mongod.conf也可参考 &lt;Mongo Sharding 集群配置&gt;中配置 rs 启动脚本2 内存绑定numactl --cpunodebind=0 --membind=0 python paramnumactl --physcpubind=0 --membind=0 python param3 CPU绑定numactl -C 0-1 ./test将应用程序test绑定到0~1核上运行      1.缺省(default)：总是在本地节点分配（分配在当前进程运行的节点上）；2.绑定(bind)：强制分配到指定节点上；3.交叉(interleave)：在所有节点或者指定的节点上交织分配；4.优先(preferred)：在指定节点上分配，失败则在其他节点上分配。[csluo@localhost node3]$ numactl -Havailable: 4 nodes (0-3)node 0 cpus: 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31node 0 size: 64847 MBnode 0 free: 6721 MBnode 1 cpus: 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63node 1 size: 65465 MBnode 1 free: 5235 MBnode 2 cpus: 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95node 2 size: 65465 MBnode 2 free: 5753 MBnode 3 cpus: 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127node 3 size: 64440 MBnode 3 free: 19081 MBnode distances:node   0   1   2   3   0:  10  16  32  33   1:  16  10  25  32   2:  32  25  10  16   3:  33  32  16  10     -&gt;| nopolicy    -&gt;| hardware      -&gt;| numa_node_size64 ///sys/devices/system/node/node%d/meminfo 获取node的total/free\t/*----------------------------------------------------------------------*/      -&gt;| print_node_cpus      \t-&gt;| numa_node_to_cpus ///sys/devices/system/node/node%d/cpumap 获取node的cpumask\t/*----------------------------------------------------------------------*/      -&gt;| print_distances      \t-&gt;| numa_distance      \t\t-&gt;| read_distance_table ////sys/devices/system/node/node%d/distance 获取node与node的距离[csluo@localhost node3]$ numactl -spolicy: defaultpreferred node: currentphyscpubind: 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 cpubind: 0 1 2 3 nodebind: 0 1 2 3 membind: 0 1 2 3     -&gt;| show    \t-&gt;|numa_get_run_node_mask  //sched_getaffinity + /sys/devices/system/node/node%d/cpumap = affinity_node    \t-&gt;|numa_preferred //get_mempolicy(policy, &amp;bmp) -&gt; policy\t\t-&gt;|numa_get_interleave_mask    \t-&gt;|numa_get_membind //get_mempolicy(policy, &amp;bmp) -&gt; bmp\t\t-&gt;|numa_get_interleave_nodevoid __attribute__((constructor))numa_init\t-&gt;|set_sizes \t\t/* &lt;/proc/self/status Mems_allowed:\\tnum &gt; nodemask_t的size，\t\t * 即系统支持最大node数2^CONFIG_NODES_SHIFT          */        -&gt;|set_nodemask_size();\t/* size of kernel nodemask_t */\t\t/* 遍历&lt;/sys/devices/system/node&gt; \t\t * [环境最大node号:maxconfigurednode],\t\t * [环境所有的nodemask numa_nodes_ptr],\t\t * [有可用内存的nodemask numa_memnode_ptr] \t\t */        -&gt;|set_configured_nodes();\t/* configured nodes listed in /sys */\t\t/* sched_getaffinity [获取cpumask_t的size cpumask_sz], \t\t * 即系统支持最大CPU数CONFIG_NR_CPUS          */        -&gt;|set_numa_max_cpu();\t/* size of kernel cpumask_t */\t\t/* sysconf(_SC_NPROCESSORS_CONF) [获取最大配置CPU maxconfiguredcpu ] */        -&gt;|set_configured_cpus();\t/* cpus listed in /sys/devices/system/cpu */        /* &lt;/proc/self/status&gt;          * [Cpus_allowed:  numa_all_cpus_ptr], 进程可用的CPU Mask         * [Mems_allowed: numa_all_nodes_ptr], 进程可用的Node Mask         * [maxconfigurednode-&gt;numa_possible_nodes_ptr], 根据最大node号(1 &lt;&lt; maxconfigurednode)得到的possible NodeMask         * [maxconfiguredcpu-&gt;numa_possible_cpus_ptr], 根据最大的CPU号(1 &lt;&lt; maxconfiguredcpu)得的possible CpuMask          */        -&gt;|set_task_constraints(); /* cpus and nodes for current task *///sysV share memory Segmenthttps://flylib.com/books/en/1.393.1.140/1/Shared memory provides an efficient way to share large amounts of data between processes. Shared memory is one of the most important resources the IPC facility provides because it is heavily used in many database applications. A SysV shared memory segment is created by the shmget() system call. After the shared memory segment is created, a process can attach itself to the shared memory segment by issuing a shmat()system call. Then the process can perform operations (read or write) on it. The process can detach itself from the memory segment by a shmdt() system call. Because shared memory provides a common resource for multiple processes, it is often used with semaphores to prevent collisions.[root@localhost numactl]$ numactl -m 0 -C 0 top&amp;[1] 596490 //查看进程的内存申请[root@localhost numactl]$ cat /proc/597865/numa_maps | grep \"N[0-9]\" [csluo@localhost numactl]$ cat /proc/`pidof top`/numa_maps | grep \"N[0-9]\"aaada7450000 bind:0 file=/usr/bin/top mapped=2 mapmax=2 N1=2 kernelpagesize_kB=64aaada7470000 bind:0 file=/usr/bin/top anon=1 dirty=1 N0=1 kernelpagesize_kB=64aaada7480000 bind:0 file=/usr/bin/top anon=1 dirty=1 N0=1 kernelpagesize_kB=64aaada7490000 bind:0 anon=1 dirty=1 N0=1 kernelpagesize_kB=64aaadc6d30000 bind:0 heap anon=3 dirty=3 N0=3 kernelpagesize_kB=64fffc6dcb0000 bind:0 file=/usr/lib64/libnuma.so.1.0.0 mapped=1 mapmax=11 N1=1 kernelpagesize_kB=64fffc6dcc0000 bind:0 file=/usr/lib64/libnuma.so.1.0.0 anon=1 dirty=1 N0=1 kernelpagesize_kB=64fffc6dcd0000 bind:0 file=/usr/lib64/libnuma.so.1.0.0 anon=1 dirty=1 N0=1 kernelpagesize_kB=64fffc6dd00000 bind:0 file=/usr/lib/locale/en_US.utf8/LC_CTYPE mapped=2 mapmax=77 N0=2 kernelpagesize_kB=64fffc6dd60000 bind:0 file=/usr/lib/locale/en_US.utf8/LC_NUMERIC mapped=1 mapmax=76 N0=1 kernelpagesize_kB=64fffc6dd70000 bind:0 file=/usr/lib/locale/en_US.utf8/LC_TIME mapped=1 mapmax=76 N0=1 kernelpagesize_kB=64fffc6dd80000 bind:0 file=/usr/lib/locale/en_US.utf8/LC_COLLATE mapped=3 mapmax=76 N0=3 kernelpagesize_kB=64fffc6e000000 bind:0 file=/usr/lib/locale/en_US.utf8/LC_MONETARY mapped=1 mapmax=76 N0=1 kernelpagesize_kB=64fffc6e010000 bind:0 file=/usr/lib/locale/en_US.utf8/LC_MESSAGES/SYS_LC_MESSAGES mapped=1 mapmax=76 N0=1 kernelpagesize_kB=64fffc6e020000 bind:0 file=/usr/lib/locale/en_US.utf8/LC_PAPER mapped=1 mapmax=76 N0=1 kernelpagesize_kB=64fffc6e030000 bind:0 file=/usr/lib/locale/en_US.utf8/LC_NAME mapped=1 mapmax=76 N0=1 kernelpagesize_kB=64fffc6e040000 bind:0 file=/usr/lib/locale/en_US.utf8/LC_ADDRESS mapped=1 mapmax=76 N0=1 kernelpagesize_kB=64fffc6e050000 bind:0 file=/usr/lib/locale/en_US.utf8/LC_TELEPHONE mapped=1 mapmax=76 N0=1 kernelpagesize_kB=64fffc6e060000 bind:0 file=/usr/lib64/libgpg-error.so.0.26.1 mapped=2 mapmax=67 N0=2 kernelpagesize_kB=64fffc6e080000 bind:0 file=/usr/lib64/libgpg-error.so.0.26.1 anon=1 dirty=1 N0=1 kernelpagesize_kB=64fffc6e090000 bind:0 file=/usr/lib64/libgpg-error.so.0.26.1 anon=1 dirty=1 N0=1 kernelpagesize_kB=64fffc6e0a0000 bind:0 file=/usr/lib64/libgcc_s-7.3.0-20190804.so.1 mapped=1 mapmax=86 N0=1 kernelpagesize_kB=64fffc6e0c0000 bind:0 file=/usr/lib64/libgcc_s-7.3.0-20190804.so.1 anon=1 dirty=1 N0=1 kernelpagesize_kB=64fffc6e0d0000 bind:0 file=/usr/lib64/libgcc_s-7.3.0-20190804.so.1 anon=1 dirty=1 N0=1 kernelpagesize_kB=64fffc6e0e0000 bind:0 file=/usr/lib64/libgcrypt.so.20.2.3 mapped=3 mapmax=67 N0=3 kernelpagesize_kB=64fffc6e1a0000 bind:0 file=/usr/lib64/libgcrypt.so.20.2.3 anon=1 dirty=1 N0=1 kernelpagesize_kB=64fffc6e1b0000 bind:0 file=/usr/lib64/libgcrypt.so.20.2.3 anon=1 dirty=1 N0=1 kernelpagesize_kB=64fffc6e1c0000 bind:0 file=/usr/lib64/liblz4.so.1.9.2 mapped=1 mapmax=66 N0=1 kernelpagesize_kB=64fffc6e200000 bind:0 file=/usr/lib64/liblz4.so.1.9.2 anon=1 dirty=1 N0=1 kernelpagesize_kB=64fffc6e210000 bind:0 file=/usr/lib64/liblz4.so.1.9.2 anon=1 dirty=1 N0=1 kernelpagesize_kB=64fffc6e220000 bind:0 file=/usr/lib64/liblzma.so.5.2.4 mapped=1 mapmax=67 N0=1 kernelpagesize_kB=64fffc6e250000 bind:0 file=/usr/lib64/liblzma.so.5.2.4 anon=1 dirty=1 N0=1 kernelpagesize_kB=64fffc6e260000 bind:0 file=/usr/lib64/liblzma.so.5.2.4 anon=1 dirty=1 N0=1 kernelpagesize_kB=64fffc6e270000 bind:0 file=/usr/lib64/librt-2.28.so mapped=1 mapmax=71 N0=1 kernelpagesize_kB=64fffc6e280000 bind:0 file=/usr/lib64/librt-2.28.so anon=1 dirty=1 N0=1 kernelpagesize_kB=64fffc6e290000 bind:0 file=/usr/lib64/librt-2.28.so anon=1 dirty=1 N0=1 kernelpagesize_kB=64fffc6e2a0000 bind:0 file=/usr/lib64/libpthread-2.28.so mapped=2 mapmax=128 N0=2 kernelpagesize_kB=64fffc6e2c0000 bind:0 file=/usr/lib64/libpthread-2.28.so anon=1 dirty=1 N0=1 kernelpagesize_kB=64fffc6e2d0000 bind:0 file=/usr/lib64/libpthread-2.28.so anon=1 dirty=1 N0=1 kernelpagesize_kB=64fffc6e2e0000 bind:0 file=/usr/lib64/libc-2.28.so mapped=17 mapmax=198 N0=17 kernelpagesize_kB=64fffc6e450000 bind:0 file=/usr/lib64/libc-2.28.so anon=1 dirty=1 N0=1 kernelpagesize_kB=64fffc6e460000 bind:0 file=/usr/lib64/libc-2.28.so anon=1 dirty=1 N0=1 kernelpagesize_kB=64fffc6e470000 bind:0 file=/usr/lib64/libdl-2.28.so mapped=1 mapmax=131 N0=1 kernelpagesize_kB=64fffc6e480000 bind:0 file=/usr/lib64/libdl-2.28.so anon=1 dirty=1 N0=1 kernelpagesize_kB=64fffc6e490000 bind:0 file=/usr/lib64/libdl-2.28.so anon=1 dirty=1 N0=1 kernelpagesize_kB=64fffc6e4a0000 bind:0 file=/usr/lib64/libtinfo.so.6.1 mapped=3 mapmax=51 N0=3 kernelpagesize_kB=64fffc6e4d0000 bind:0 file=/usr/lib64/libtinfo.so.6.1 anon=1 dirty=1 N0=1 kernelpagesize_kB=64fffc6e4e0000 bind:0 file=/usr/lib64/libtinfo.so.6.1 anon=1 dirty=1 N0=1 kernelpagesize_kB=64fffc6e4f0000 bind:0 file=/usr/lib64/libncurses.so.6.1 mapped=1 mapmax=3 N1=1 kernelpagesize_kB=64fffc6e520000 bind:0 file=/usr/lib64/libncurses.so.6.1 anon=1 dirty=1 N0=1 kernelpagesize_kB=64fffc6e530000 bind:0 file=/usr/lib64/libncurses.so.6.1 anon=1 dirty=1 N0=1 kernelpagesize_kB=64fffc6e540000 bind:0 file=/usr/lib64/libsystemd.so.0.27.0 mapped=2 mapmax=57 N0=2 kernelpagesize_kB=64fffc6e5f0000 bind:0 file=/usr/lib64/libsystemd.so.0.27.0 anon=1 dirty=1 N0=1 kernelpagesize_kB=64fffc6e600000 bind:0 file=/usr/lib64/libsystemd.so.0.27.0 anon=1 dirty=1 N0=1 kernelpagesize_kB=64fffc6e610000 bind:0 file=/usr/lib64/libprocps.so.8.0.2 mapped=1 mapmax=2 N1=1 kernelpagesize_kB=64fffc6e630000 bind:0 file=/usr/lib64/libprocps.so.8.0.2 anon=1 dirty=1 N0=1 kernelpagesize_kB=64fffc6e640000 bind:0 file=/usr/lib64/libprocps.so.8.0.2 anon=1 dirty=1 N0=1 kernelpagesize_kB=64fffc6e650000 bind:0 anon=1 dirty=1 N0=1 kernelpagesize_kB=64fffc6e660000 bind:0 file=/usr/lib/locale/en_US.utf8/LC_MEASUREMENT mapped=1 mapmax=76 N0=1 kernelpagesize_kB=64fffc6e670000 bind:0 file=/usr/lib64/gconv/gconv-modules.cache mapped=1 mapmax=78 N0=1 kernelpagesize_kB=64fffc6e6a0000 bind:0 file=/usr/lib64/ld-2.28.so mapped=2 mapmax=197 N0=2 kernelpagesize_kB=64fffc6e6c0000 bind:0 file=/usr/lib/locale/en_US.utf8/LC_IDENTIFICATION mapped=1 mapmax=76 N0=1 kernelpagesize_kB=64fffc6e6d0000 bind:0 file=/usr/lib64/ld-2.28.so anon=1 dirty=1 N0=1 kernelpagesize_kB=64fffc6e6e0000 bind:0 file=/usr/lib64/ld-2.28.so anon=1 dirty=1 N0=1 kernelpagesize_kB=64ffffd2cb0000 bind:0 stack anon=2 dirty=2 N0=2 kernelpagesize_kB=64//查看program运行的cpu[csluo@localhost numactl]$ cat /proc/`pidof top`/status |grep Cpus_allowed_listCpus_allowed_list:\t0[csluo@localhost numactl]$ ps -o pid,psr,comm -p `pidof top`    PID PSR COMMAND 599842   0 top[csluo@localhost numactl]$ ps -o pid,psr,comm -p `pidof top`    PID PSR COMMAND 599842   0 top[csluo@localhost numactl]$ ps -o pid,psr,comm -p `pidof top`    PID PSR COMMAND 599842   0 top#0  0x0000ffffafe5db04 in strstr () from /usr/lib64/libc.so.6(gdb) bt#0  0x0000ffffafe5db04 in strstr () from /usr/lib64/libc.so.6#1  0x0000000000401ed8 in add_pids_from_pattern_search (pattern=pattern@entry=0x0) at numastat.c:1319#2  0x00000000004012e8 in main (argc=1, argv=0xffffdd7413c8) at numastat.c:1399"
  },
  
  {
    "title": "Kernel Page_Idle",
    "url": "/posts/linux-page_idle-bitmap/",
    "categories": "linux, page_idle",
    "tags": "page_idle",
    "date": "2021-09-01 00:00:00 +0000",
    





    
    "snippet": "动机空闲页跟踪功能允许跟踪哪些内存页工作负载访问的空闲状态。此信息对估计工作负载的工作集大小，而工作集的大小又可以用于配置工作负载参数、设置内存控制组限制、或者决定在计算群集中将工作负载放置到何处。通过CONFIG_IDLE_PAGE_TRACKING=y来启用。用户接口空闲页面跟踪API位于/sys/kernel/mm/page_idle。目前，它由唯一的读写文件/sys/kernel/m...",
    "content": "动机空闲页跟踪功能允许跟踪哪些内存页工作负载访问的空闲状态。此信息对估计工作负载的工作集大小，而工作集的大小又可以用于配置工作负载参数、设置内存控制组限制、或者决定在计算群集中将工作负载放置到何处。通过CONFIG_IDLE_PAGE_TRACKING=y来启用。用户接口空闲页面跟踪API位于/sys/kernel/mm/page_idle。目前，它由唯一的读写文件/sys/kernel/mm/page_idle/bitmap组成。该文件实现了位图，其中每个位对应一个内存页。位图由8字节整数数组表示，PFN #i处的页面映射到数组元素#i/64的bit #i%64，字节顺序为本机。当某个bit位被置位时，对应的页面处于空闲状态。如果页面被标记为空闲后未被访问，则认为该页面处于空闲状态（有关“已访问”的更多详细信息，请参阅IMPLEMENTATION DETAILS部分）。要标记页面空闲，必须通过写入文件。写入文件的值与当前位图值或。仅跟踪对用户内存页的访问。这些页映射到进程地址空间、页缓存和缓冲页、交换缓存页。对于其他页面类型（例如。SLAB pages）将页面标记为空闲的尝试被静默忽略，因此此类页面永远不会被报告为空闲。对于大页，空闲标志只在头页上设置，因此必须读取/proc/kpageflags才能正确计数空闲的大页。如果未在8字节边界上启动读/写，或者读/写的大小不是8字节的倍数，则对/sys/kernel/mm/page_idle/bitmap进行读/写操作将返回-EINVAL。写入此文件超过max PFN将返回-ENXIO。也就是说，为了估计工作量未使用的页面数量，应该：1.通过设置/sys/kernel/mm/page_idle/bitmap中对应位，将工作负载的所有页面标记为空闲。如果工作负载由进程表示，则可以通过读取/proc/pid/pagemap来查找页面，或者如果工作负载被放置在内存控制组中，则通过使用/proc/kpagecgroup过滤外来页来查找页面。2.等待工作负载访问其工作集。3、读取/sys/kernel/mm/page_idle/bitmap，统计设置位数。如果想要忽略某些类型的页面，例如，由于不可回收的锁定页面，他或她可以使用/proc/kpageflags过滤掉它们。有关/proc/pid/pagemap、/proc/kpageflags和/proc/kpagecgroup的详细信息，请参见Documentation/vm/pagemap.txt。实施详情内核在内部跟踪对用户内存页的访问，以便在内存不足的情况下首先回收未引用的页。如果最近通过进程地址空间访问过一个页面，则认为该页面被引用，在这种情况下，它被映射到的一个或多个PTE将设置访问位。或标记由内核显式访问（参见mark_page_accessed(）)。后者发生于以下情况：-用户空间进程使用系统调用读取或写入页面（例如。读(2）或写（2）)-用于存储文件系统缓冲区的页被读取或写入，因为进程需要文件系统元数据存储在其中（例如。目录树如所示）-一个页面由设备驱动程序使用get_user_pages()访问当脏页由于内存回收或超过脏内存限制而写入交换或磁盘时，它不会被标记为引用。空闲内存跟踪功能添加了一个新的页标志，即空闲标志。此标志通过写入/sys/kernel/mm/page_idle/bitmap （请参见USER API部分）手动设置，并且每当引用上面定义的页时，该标志将自动清除。当页面被标记为空闲时，必须清除它映射到的所有PTE中的“已访问”位，否则我们将无法检测来自进程地址空间的对页面的访问。为了避免与回收器（如上所述，回收器使用Accessed位来提升主动引用的页面）的干扰，引入了另一个页面标志，即Young标志。当由于设置或更新页面的空闲标志而清除PTE Accessed位时，将在页面上设置Young标志。回收程序将Young标志视为额外的PTE Accessed位，因此将认为这样的页面被引用。由于空闲内存跟踪功能基于内存回收程序逻辑，因此它只对LRU列表中的页起作用，其他页将被静默忽略。这意味着，如果用户内存页被隔离，它将忽略它，但是由于通常不会有很多，所以它不会明显影响整个结果。为了不中断空闲页位图的扫描，也可以跳过锁定页。https://github.com/sjp38/idle_page_tracking/blob/master/pageidle.chttps://github.com/luochenglcs/wss/blob/master/wss-v2.c"
  },
  
  {
    "title": "Customized Scheduler - google Ghost",
    "url": "/posts/Customized-Scheduler-In-Userspace/",
    "categories": "linux, Scheduler",
    "tags": "Scheduler",
    "date": "2021-08-22 00:00:00 +0000",
    





    
    "snippet": "一、鸿蒙调度/LiteOS调度//鸿蒙OS调度https://codechina.csdn.net/kuangyufei/kernel_liteos_a_note/-/wikis/04_%E4%BB%BB%E5%8A%A1%E8%B0%83%E5%BA%A6%E7%AF%87https://juejin.cn/post/7015965298234753032线程状态说明：初始化（Init）：...",
    "content": "一、鸿蒙调度/LiteOS调度//鸿蒙OS调度https://codechina.csdn.net/kuangyufei/kernel_liteos_a_note/-/wikis/04_%E4%BB%BB%E5%8A%A1%E8%B0%83%E5%BA%A6%E7%AF%87https://juejin.cn/post/7015965298234753032线程状态说明：初始化（Init）：该线程正在被创建。就绪（Ready）：该线程在就绪列表中，等待CPU调度。运行（Running）：该线程正在运行。阻塞（Blocked）：该线程被阻塞挂起。Blocked状态包括：pend(因为锁、事件、信号量等阻塞)、suspend（主动pend）、delay(延时阻塞)、pendtime(因为锁、事件、信号量时间等超时等待)。退出（Exit）：该线程运行结束，等待父线程回收其控制块资源。说LosTaskCB之前先说下官方文档任务状态对应的 define，可以看出task和线程是一个东西。#define OS_TASK_STATUS_INIT         0x0001U#define OS_TASK_STATUS_READY        0x0002U#define OS_TASK_STATUS_RUNNING      0x0004U#define OS_TASK_STATUS_SUSPEND      0x0008U#define OS_TASK_STATUS_PEND         0x0010U#define OS_TASK_STATUS_DELAY        0x0020U#define OS_TASK_STATUS_TIMEOUT      0x0040U#define OS_TASK_STATUS_PEND_TIME    0x0080U#define OS_TASK_STATUS_EXIT         0x0100U-----https://juejin.cn/post/7015965298234753032Huawei LiteOS 系统中的任务管理模块为用户提供下面几种功能。            功能分类      接口名      描述                  任务的创建和删除      LOS_TaskCreateOnly      创建任务，并使该任务进入suspend状态，并不调度。                     LOS_TaskCreate      创建任务，并使该任务进入ready状态，并调度。                     LOS_TaskDelete      删除指定的任务。              任务状态控制      LOS_TaskResume      恢复挂起的任务。                     LOS_TaskSuspend      挂起指定的任务。                     LOS_TaskDelay      任务延时等待。                     LOS_TaskYield      显式放权，调整指定优先级的任务调度顺序。              任务调度的控制      LOS_TaskLock      锁任务调度。                     LOS_TaskUnlock      解锁任务调度。              任务优先级的控制      LOS_CurTaskPriSet      设置当前任务的优先级。                     LOS_TaskPriSet      设置指定任务的优先级。                     LOS_TaskPriGet      获取指定任务的优先级。              任务信息获取      LOS_CurTaskIDGet      获取当前任务的ID。                     LOS_TaskInfoGet      设置指定任务的优先级。                     LOS_TaskPriGet      获取指定任务的信息。                     LOS_TaskStatusGet      获取指定任务的状态。                     LOS_TaskNameGet      获取指定任务的名称。                     LOS_TaskInfoMonitor      监控所有任务，获取所有任务的信息。                     LOS_NextTaskIDGet      获取即将被调度的任务的ID。      二、ghost调度器在userspace设计调度代理agent， 内核将线程信息（new、wakeup、block、relax、dead等）通过共享内存方式发送给调度代理agent，调度代理agent实施调度决策，并通过Syscall下发给内核;ghost调度实现： ghost-kenrel / ghost-userspace1&gt; ghost-kernel–如何调度切换1、ghost class timerfddo_timerfd_settime {    ...    #ifdef CONFIG_SCHED_CLASS_GHOST       if (tfdl)               memcpy(&amp;ctx-&gt;timerfd_ghost, tfdl, sizeof(struct timerfd_ghost));       else               ctx-&gt;timerfd_ghost.flags = 0;   /* disabled */\t#endif    ...}2、kernel/sched/ghost.c​\t1&gt; 新增调度类 调度实体….//新增ghost task和agent的调度类#define SCHED_DATA                             \\        STRUCT_ALIGN();                         \\        __begin_sched_classes = .;              \\        *(__idle_sched_class)                   \\+       *(__ghost_sched_class)                  \\ //ghost task schedhere        *(__fair_sched_class)                   \\        *(_rt_sched_class)                     \\        *(__dl_sched_class)                     \\+       *(__ghost_agent_sched_class)            \\  ///ghost agent sched here        *(__stop_sched_class)                   \\        __end_sched_classes = .;//ghost调度实体阿+struct sched_ghost_entity {+       struct list_head run_list;+       ktime_t last_runnable_at;++       /* The following fields are protected by 'task_rq(p)-&gt;lock' */+       struct ghost_queue *dst_q;+       struct ghost_status_word *status_word;+       struct ghost_enclave *enclave;++       /*+        * See also ghost_prepare_task_switch() and ghost_deferred_msgs()+        * for flags that are used to defer messages.+        */+       uint blocked_task : 1;+       uint yield_task : 1;+       uint new_task   : 1;+       uint agent      : 1;++       struct list_head task_list;+};​\t2&gt; scheduler_ipi//核间中断处理函数do_handle_IPI    -&gt;scheduler_ipi //IPI_RESCHEDULE    void scheduler_ipi(void){\t/*\t * Fold TIF_NEED_RESCHED into the preempt_count; anybody setting\t * TIF_NEED_RESCHED remotely (for the first time) will also send\t * this IPI.\t */\tpreempt_fold_need_resched();\tif (llist_empty(&amp;this_rq()-&gt;wake_list) &amp;&amp; !got_nohz_idle_kick())\t\treturn;\t/*\t * Not all reschedule IPI handlers call irq_enter/irq_exit, since\t * traditionally all their work was done from the interrupt return\t * path. Now that we actually do some work, we need to make sure\t * we do call them.\t *\t * Some archs already do call them, luckily irq_enter/exit nest\t * properly.\t *\t * Arguably we should visit all archs and update all handlers,\t * however a fair share of IPIs are still resched only so this would\t * somewhat pessimize the simple resched case.\t */\tirq_enter();\tsched_ttwu_pending();\t/*\t * Check if someone kicked us for doing the nohz idle load balance.\t */\tif (unlikely(got_nohz_idle_kick())) {\t\tthis_rq()-&gt;idle_balance = 1;\t\traise_softirq_irqoff(SCHED_SOFTIRQ);\t}\tirq_exit();}//https://www.codenong.com/cs106431107/ 引用于scheduler_ipi()函数调用sched_ttwu_pending()函数唤醒pending的任务然后调用raise_softirq_irqoff（）函数发起一个软中断，软中断将在后续的文章中介绍。IPI_CALL_FUNC：函数smp_call_function()生成的中断，通过调用函数generic_smp_call_function_interrupt()最终调用函数flush_smp_call_function_queue（），该函数调用所有在队列中pending的回调函数。flush_smp_call_function_queue（）函数的源码可以在kernel/smp.c文件中可以找到：     http://oliveryang.net/2016/03/linux-scheduler-2///流程1ghost_latched_task_preempted    -&gt;_ghost_task_preempted  if ghost_police        -&gt;set_tsk_need_resched &amp;&amp; set_preempt_need_resched        //流程2 context_switch    -&gt;prepare_task_switch         -&gt;ghost_prepare_task_switch || pick_next_ghost_agent //pick_next_ghost_agent忽略            -&gt;ghost_task_preempted                -&gt;_ghost_task_preempted 3、new syscall – ghost ghost_run450    64      ghost_run               sys_ghost_run451    64      ghost                   sys_ghost4、bpf//include/linux/bpf_types.hBPF_PROG_TYPE(BPF_PROG_TYPE_GHOST_SCHED, ghost_sched, struct bpf_ghost_sched,              struct bpf_ghost_sched_kern)//kernel/sched/bpf.cBPF_CALL_2(bpf_ghost_wake_agent, struct bpf_ghost_sched_kern *, ctx, u32, cpu){        return ghost_wake_agent_on_check(cpu);}//BPF_CALL_4(bpf_ghost_run_gtid, struct bpf_ghost_sched_kern *, ctx, s64, gtid,           u32, task_barrier, int, run_flags){        return ghost_run_gtid_on(gtid, task_barrier, run_flags,                                 smp_processor_id());}//static const struct bpf_link_ops bpf_ghost_sched_link_ops = {        .release = bpf_ghost_sched_link_release,        .dealloc = bpf_ghost_sched_link_dealloc,};5、kernel/sched/ghostfs.c1 提供enclave的创建enclave机制简介传统用法ghost Enclave//kernel/sched/ghostfs.cghostfs_init    -&gt;| ghost_setup_root    \t-&gt;| kernfs_create_root //https://www.binss.me/blog/sysfs-udev-and-Linux-Unified-Device-Model/ //kernfs-&gt;sysfs//ghost enclave mount -t ghost /dev/ghost /sys/fs/ghost1、先执行agent-shinjuku2、执行用例2 提供cpu_data/sys/fs/ghost/enclave_1/cpu_data设置cpu-&gt;rq-&gt;ghost_rq-&gt;latched_task，提交该cpu锁定的task。方便ghost-userspace在该cpu上执行指定task.**方法**: 与用户态共享同一块物理内存3 提供status_word/sys/fs/ghost/enclave_1/sw_regions/sw_0进程的task-&gt;ghost-&gt;status_word从这片内存申请，记录进程的执行时间相关信息；方便ghost-userspace获取进程执行时间。**方法**：与用户态共享一块物理内存 每次tick更新进程的task，在dequeue_task_ghost、put_prev_task_ghost、_ghost_task_preempted、_ghost_task_new、ghost_task_yield、ghost_switchto时，更新到task-&gt;ghost-&gt;status_word中方便用户态获取。6、 ghost调度分析_ghost_task_preempted     &lt;- ghost_latched_task_preempted //在ghost.latched_task但是还未pick走在cpu运行,例如    \t&lt;- ghost_prepare_task_switch //1、线程切换时，next非ghost线程    \t&lt;- invalidate_cached_tasks //2. 线程迁移到其他cpu,无效latched_task; 3.线程重新设置调度类 4. DEQUEUE_SAVE        &lt;- task_tick_ghost //5. 被agent线程抢占     \t&lt;- pick_next_ghost_agent //5. 被agent线程抢占    \t&lt;- release_from_ghost    \t&lt;- ghost_set_pnt_state //6.被新任务覆盖    ------    &lt;- ghost_task_preempted    \t&lt;- ghost_prepare_task_switch //正在运行的prev被抢占    \t&lt;- pick_next_ghost_agent //prev被agent任务抢占ghost_task_blocked    &lt;- ghost_produce_prev_msgs //prev-&gt;ghost.blocked_task=true,进程切换时如果发现prev线程是Dequeue sleep，则为block状态    \ttask_woken_ghost    &lt;- ghost_class.task_woken //调度类的task_woken    \t&lt;- ttwu_do_wakeup //wake up等待任务    ----------    \t&lt;- wake_up_new_task //wake up刚创建的任务目前per-cpu ebpf的调度的问题：1、锁2、进程调度延迟https://zhuanlan.zhihu.com/p/462728452  //测量调度延迟     kworker/1:1-250     [001] d...   129.594930: bpf_trace_printk: sched_switch prev kworker/1:1     kworker/1:1-250     [001] d...   129.594932: bpf_trace_printk:  -&gt; next swapper/1        ghostctl-1963    [016] dN..   130.895647: bpf_trace_printk: TASK NEW         ghostctl-1963    [016] dN..   130.895658: bpf_trace_printk: fffe start         ghostctl-1963    [016] dN..   130.895659: bpf_trace_printk: fffc select cpu 1        ghostctl-1963    [016] dN..   130.895663: bpf_trace_printk: add 1 rq have 1 task 1963 gtid          &lt;idle&gt;-0       [001] d...   132.010916: bpf_trace_printk: sched_switch prev swapper/1          &lt;idle&gt;-0       [001] d...   132.010925: bpf_trace_printk:  -&gt; next migration/1     migration/1-18      [001] d...   132.010957: bpf_trace_printk: del 1 rq have 0 task 1963 Pid     migration/1-18      [001] d...   132.010969: bpf_trace_printk: run cpu 1 pid 1963 ret 0     migration/1-18      [001] d...   132.010973: bpf_trace_printk: sched_switch prev migration/1     migration/1-18      [001] d...   132.010974: bpf_trace_printk:  -&gt; next ghostctl              ls-1963    [001] dN..   132.013195: bpf_trace_printk: TASK BLOCKED               ls-1963    [001] dN..   132.013200: bpf_trace_printk: pid 1963 runtime 36ba0a cpu 1              ls-1963    [001] dN..   132.013201: bpf_trace_printk: block pid 1963 BLOCK but in CPU 1              ls-1963    [001] dN..   132.013202: bpf_trace_printk: fffc start               ls-1963    [001] dN..   132.013202: bpf_trace_printk: fffe set cpu 1              ls-1963    [001] d...   132.013207: bpf_trace_printk: sched_switch prev ls              ls-1963    [001] d...   132.013207: bpf_trace_printk:  -&gt; next agent_cephdo_idle函数分析：https://www.cnblogs.com/Linux-tech/p/13326567.htmlhttps://www.cnblogs.com/LoyenWang/p/11379937.htmlresched_cpu_unlocked:https://zhuanlan.zhihu.com/p/500191837 IPI中断类型https://zhuanlan.zhihu.com/p/373959024 进程切换，地址空间切换内核主动触发调度点：https://blog.csdn.net/pwl999/article/details/78817899 Linux schedule 1、调度的时刻https://blog.51cto.com/qmiller/4842433 Linux内核进程调度发生的时间点问题定位原因：1、idle线程无法退出的原因：​\t1&gt; ipi_scheduler确实会从idle状态退出，走进schedule_idle​\t2&gt; schedule_idle-&gt;__schedule-&gt;pick_next_task 走进fair_class的优化分支，因为此时ghost_task还没有入队；跟踪日志如下： migration/1-18      [001] d...    84.012159: bpf_trace_printk:  -&gt; next swapper/1          &lt;idle&gt;-0       [001] dN..    84.012161: bpf_trace_printk: schedule_idle          &lt;idle&gt;-0       [001] d...    84.012167: bpf_trace_printk: cpu_idle: state 1 cpu 1        ghostctl-3518    [018] dN..    85.605119: bpf_trace_printk: TASK NEW //ghost task 从cfs 切成ghost调度类        ghostctl-3518    [018] dN..    85.605125: bpf_trace_printk: fffe start        ghostctl-3518    [018] dN..    85.605126: bpf_trace_printk: fffc select cpu 1        ghostctl-3518    [018] dN..    85.605128: bpf_trace_printk: add 1 rq have 1 task 3518 gtid          &lt;idle&gt;-0       [001] d.h.    85.605163: bpf_trace_printk: ipi_entry: Rescheduling interrupts //ipi_resche          &lt;idle&gt;-0       [001] dNh.    85.605167: bpf_trace_printk: ipi_exit: Rescheduling interrupts          &lt;idle&gt;-0       [001] dN..    85.605169: bpf_trace_printk: cpu_idle: state ffffffff cpu 1 //idle进程退出          &lt;idle&gt;-0       [001] dN..    85.605173: bpf_trace_printk: schedule_idle //重新调度idle，发现无任务          &lt;idle&gt;-0       [001] d...    85.605179: bpf_trace_printk: cpu_idle: state 1 cpu 1 //重新pick idle          &lt;idle&gt;-0       [001] dN..    88.012086: bpf_trace_printk: cpu_idle: state ffffffff cpu 1          &lt;idle&gt;-0       [001] dN..    88.012121: bpf_trace_printk: schedule_idle          &lt;idle&gt;-0       [001] d...    88.012127: bpf_trace_printk: sched_switch prev swapper/1          &lt;idle&gt;-0       [001] d...    88.012128: bpf_trace_printk:  -&gt; next migration/1     migration/1-18      [001] d...    88.012138: bpf_trace_printk: del 1 rq have 0 task 3518 Pid     migration/1-18      [001] d...    88.012147: bpf_trace_printk: run cpu 1 pid 3518 ret 0     migration/1-18      [001] d...    88.012149: bpf_trace_printk: sched_switch prev migration/1     migration/1-18      [001] d...    88.012152: bpf_trace_printk:  -&gt; next ghostctl        ghostctl-3518    [001] d.h.    88.012156: bpf_trace_printk: ipi_entry: IRQ work interrupts        ghostctl-3518    [001] d.h.    88.012157: bpf_trace_printk: ipi_exit: IRQ work interrupts        ghostctl-3518    [001] d...    88.012185: bpf_trace_printk: ipi_raise: Function call interrupt\tif (likely(prev-&gt;sched_class &lt;= &amp;fair_sched_class &amp;&amp;\t\t   rq-&gt;nr_running == rq-&gt;cfs.h_nr_running)) {//prev-&gt;sched_class == idle_sched_class &lt;= fair_sched_class 满足条件//rq-&gt;nr_running == rq-&gt;cfs.h_nr_running == 0 满足条件  \t\tp = pick_next_task_fair(rq, prev, rf);  //这里返回NULL\t\tif (unlikely(p == RETRY_TASK))\t\t\tgoto restart;\t\t/* Assumes fair_sched_class-&gt;next == idle_sched_class */\t\tif (!p) {\t\t\tput_prev_task(rq, prev);\t\t\tp = pick_next_task_idle(rq); //这里重新又pick idle，重新进去idle\t\t}搞清楚latched_task与ghost_rq-&gt;task_list的关系？2、内核没有打开强制功能，内核中断不会触发主动调度\t.align\t6SYM_CODE_START_LOCAL_NOALIGN(el1_irq)\tkernel_entry 1\tgic_prio_irq_setup pmr=x20, tmp=x1\tenable_da_f\tmov\tx0, sp\tbl\tenter_el1_irq_or_nmi\tirq_handler#ifdef CONFIG_PREEMPTION  //内核抢占功能使能\tldr\tx24, [tsk, #TSK_TI_PREEMPT]\t// get preempt countalternative_if ARM64_HAS_IRQ_PRIO_MASKING\t/*\t * DA_F were cleared at start of handling. If anything is set in DAIF,\t * we come back from an NMI, so skip preemption\t */\tmrs\tx0, daif\torr\tx24, x24, x0alternative_else_nop_endif\tcbnz\tx24, 1f\t\t\t\t// preempt count != 0 || NMI return path\tbl\tarm64_preempt_schedule_irq\t// irq en/disable is done inside1:#endif\tmov\tx0, sp\tbl\texit_el1_irq_or_nmi\tkernel_exit 1SYM_CODE_END(el1_irq)ghos怎么做到主动抢占的呢？https://www.coolcou.com/linux-kernel/linux-kernel-references/linux-kernel-scheduling-process.html Linux内核调度流程-抢占的发生\t\tghost_task_new(rq, prev); //给用户态发送task_new消息\t\tghost_wake_agent_of(prev); //prev目前信息：ghost消息流程的后面如果需要主动抢占的，会调用wakeup agent，如果是非central的cpu，执行yeild_task-&gt;ghost_run-&gt;schedule()触发调度。抢占点设计：复用内核抢占，打开内核抢占功能？？？2&gt; ghost-userspace分两部分： 用户态代码 + ebpf代码1&gt; ebpf机制简介​\tBPF 是 Linux 内核中一个非常灵活与高效的类虚拟机（virtual machine-like）组件， 能够在许多内核 hook 点安全地执行字节码（bytecode ）。很多 内核子系统都已经使用了 BPF，例如常见的网络（networking）、跟踪（ tracing）与安全（security ，例如沙盒）。reference:https://arthurchiao.art/blog/cilium-bpf-xdp-reference-guide-zh/https://pwl999.github.io/2018/09/28/bpf_kernel/ //从内核代码层面分析 bpf load verify run...reference:https://zhuanlan.zhihu.com/p/373090595bpf map//mapstruct {        __uint(type, BPF_MAP_TYPE_HASH);        __uint(max_entries, MAX_PIDS);        __type(key, u32);        __type(value, struct task_stat);} task_stats SEC(\".maps\");struct {        __uint(type, BPF_MAP_TYPE_PERCPU_ARRAY);        __uint(max_entries, NR_HISTS);        __type(key, u32);        __type(value, struct hist);} hists SEC(\".maps\");bpf SEC – bpf hook//SECSEC(\"tp_btf/sched_wakeup\") int BPF_PROG(sched_wakeup, struct task_struct *p){        if (task_has_ghost_policy(p))                task_runnable(p);        return 0;}引用：https://www.shuzhiduo.com/A/kvJ3q9g7dg/#include \"vmlinux.h\"   /* all kernel types */#include &lt;bpf/bpf_helpers.h&gt;  /* most used helpers: SEC, __always_inline, etc */#include &lt;bpf/bpf_core_read.h&gt;  /* for BPF CO-RE helpers */内核空间的BPF代码如下(假设生成的.o文件名为runqslower.bpf.o)：// SPDX-License-Identifier: GPL-2.0// Copyright (c) 2019 Facebook/* BPF程序包含的头文件，可以看到内容想相当简洁 */#include \"vmlinux.h\"#include &lt;bpf/bpf_helpers.h&gt;#include \"runqslower.h\"#define TASK_RUNNING 0#define BPF_F_CURRENT_CPU 0xffffffffULL/* 在BPF代码侧，可以使用一个 const volatile 声明只读的全局变量，只读的全局变量，变量最后会存在于runqslower.bpf.o的.rodata只读段，用户侧可以在BPF程序加载前读取或修改该只读段的参数【1】 */const volatile __u64 min_us = 0;const volatile pid_t targ_pid = 0;/* 定义名为 start 的map，类型为 BPF_MAP_TYPE_HASH。容量为10240，key类型为u32，value类型为u64。可以在【1】中查看BPF程序解析出来的.maps段【2】 */struct {\t__uint(type, BPF_MAP_TYPE_HASH);\t__uint(max_entries, 10240);\t__type(key, u32);\t__type(value, u64);} start SEC(\".maps\");/* 由于 PERF_EVENT_ARRAY, STACK_TRACE 和其他特殊的maps(DEVMAP, CPUMAP, etc) 尚不支持key/value类型的BTF类型，因此需要直接指定 key_size/value_size */struct {\t__uint(type, BPF_MAP_TYPE_PERF_EVENT_ARRAY);\t__uint(key_size, sizeof(u32));\t__uint(value_size, sizeof(u32));} events SEC(\".maps\");/* record enqueue timestamp *//* 自定义的辅助函数必须标记为 static __always_inline。该函数用于保存唤醒的任务事件，key为pid，value为唤醒的时间点 */__always_inlinestatic int trace_enqueue(u32 tgid, u32 pid){\tu64 ts;\tif (!pid || (targ_pid &amp;&amp; targ_pid != pid))\t\treturn 0;\tts = bpf_ktime_get_ns();\tbpf_map_update_elem(&amp;start, &amp;pid, &amp;ts, 0);\treturn 0;}/* 所有BPF程序提供的功能都需要通过 SEC() (来自 bpf_helpers.h )宏来自定义section名称【3】。可以在【1】中查看BPF程序解析出来的自定义函数 *//* 唤醒一个任务，并保存当前时间 */SEC(\"tp_btf/sched_wakeup\")int handle__sched_wakeup(u64 *ctx){\t/* TP_PROTO(struct task_struct *p) */\tstruct task_struct *p = (void *)ctx[0];\treturn trace_enqueue(p-&gt;tgid, p-&gt;pid);}/* 唤醒一个新创建的任务，并保存当前时间。BPF的上下文为一个task_struct*结构体 */SEC(\"tp_btf/sched_wakeup_new\")int handle__sched_wakeup_new(u64 *ctx){\t/* TP_PROTO(struct task_struct *p) */\tstruct task_struct *p = (void *)ctx[0];\treturn trace_enqueue(p-&gt;tgid, p-&gt;pid);}/* 计算一个任务入run队列到出队列的时间 */SEC(\"tp_btf/sched_switch\")int handle__sched_switch(u64 *ctx){\t/* TP_PROTO(bool preempt, struct task_struct *prev,\t *\t    struct task_struct *next)\t */\tstruct task_struct *prev = (struct task_struct *)ctx[1];\tstruct task_struct *next = (struct task_struct *)ctx[2];\tstruct event event = {};\tu64 *tsp, delta_us;\tlong state;\tu32 pid;\t/* ivcsw: treat like an enqueue event and store timestamp */    /* 如果被切换的任务的状态仍然是TASK_RUNNING，说明其又重新进入run队列，更新入队列的时间 */\tif (prev-&gt;state == TASK_RUNNING)\t\ttrace_enqueue(prev-&gt;tgid, prev-&gt;pid);    /* 获取下一个任务的PID */\tpid = next-&gt;pid;\t/* fetch timestamp and calculate delta */    /* 如果该任务并没有被唤醒，则无法正常进行任务切换，返回0即可 */\ttsp = bpf_map_lookup_elem(&amp;start, &amp;pid);\tif (!tsp)\t\treturn 0;   /* missed enqueue */    /* 当前切换时间减去该任务的入队列时间，计算进入run队列到真正调度的毫秒级时间 */\tdelta_us = (bpf_ktime_get_ns() - *tsp) / 1000;\tif (min_us &amp;&amp; delta_us &lt;= min_us)\t\treturn 0;    /* 更新events section，以便用户侧读取 */\tevent.pid = pid;\tevent.delta_us = delta_us;\tbpf_get_current_comm(&amp;event.task, sizeof(event.task));\t/* output */\tbpf_perf_event_output(ctx, &amp;events, BPF_F_CURRENT_CPU,\t\t\t      &amp;event, sizeof(event));    /* 该任务已经出队列，删除map */\tbpf_map_delete_elem(&amp;start, &amp;pid);\treturn 0;}char LICENSE[] SEC(\"license\") = \"GPL\";bfp辅助函数​\t辅助函数是一组内核定义的函数集，使 eBPF 程序能从内核读取数据， 或者向内核写入数据（retrieve/push data from/to the kernel）调用约定​\t辅助函数的调用约定（calling convention）也是固定的：- R0：存放程序返回值- R1 ~ R5：存放函数参数（function arguments）- R6 ~ R9：**被调用方**（callee）负责保存的寄存器- R10：栈空间 load/store 操作用的只读 frame pointerBPF_PROG_TYPEBPF_CALL//介绍BPF_CALL https://arthurchiao.art/blog/on-getting-tc-classifier-fully-programmable-zh/内核将辅助函数抽象成 BPF_CALL_0() 到 BPF_CALL_5() 几个宏，形式和相应类型的系 统调用类似。当前可用的 BPF 辅助函数已经有几十个，并且数量还在不断增加，例如，写作本文时，tc BPF 程序可以使用38 种不同的 BPF 辅助函数。对于一个给定的 BPF 程序类型，内核的 struct bpf_verifier_ops 包含了 get_func_proto 回调函数，这个函数提供了从某个 特定的enum bpf_func_id 到一个可用的辅助函数的映射.     reference:https://arthurchiao.art/blog/cilium-bpf-xdp-reference-guide-zh/#12-%E8%BE%85%E5%8A%A9%E5%87%BD%E6%95%B0//get_func_proto介绍https://blogs.oracle.com/linux/post/bpf-in-depth-bpf-helper-functions//译文附录：一些相关的 BPF 内核实现https://arthurchiao.art/blog/lifetime-of-bpf-objects-zh///mapbpf_create_map() -&gt; bpf_create_map_xattr() -&gt; sys_bpf() -&gt; SYSCALL_DEFINE3(bpf, ...)：系统调用 SYSCALL_DEFINE3(bpf, ...) -&gt; case BPF_MAP_CREATE -&gt; map_create()：创建 map//load bpf programbpf(BPF_PROG_LOAD) -&gt; sys_bpf() -&gt; SYSCALL_DEFINE3(bpf, ...) SYSCALL_DEFINE3(bpf, ...) -&gt; case BPF_PROG_LOAD -&gt; bpf_prog_load()：加载逻辑bpf_prog_load() -&gt; bpf_check()：执行内核校验 bpf_check() -&gt; replace_map_fd_with_map_ptr() -&gt; bpf_map_inc()：更新 map refcnt2 用户态代码//创建ghost class的进程GhostThread::GhostThread(KernelScheduler ksched, std::function&lt;void()&gt; work)    : ksched_(ksched) {  GhostThread::SetGlobalEnclaveCtlFdOnce();    thread_ = std::thread([this, w = std::move(work)] {  //进程创建    tid_ = GetTID();    gtid_ = Gtid::Current();      // TODO: Consider moving after SchedEnterGhost.    started_.Notify();       if (ksched_ == KernelScheduler::kGhost) {       const int ret = SchedTaskEnterGhost(/*pid=*/0);  //如果是kGhost的话，设置为ghost_class调度类。      CHECK_EQ(ret, 0);    }    std::move(w)();  });  started_.WaitForNotification();  }//agent_shinjukumain    -&gt;ghost::AgentProcess&lt;ghost::FullShinjukuAgent&lt;ghost::LocalEnclave&gt;, ghost::ShinjukuConfig&gt;(config)__NR_memfd_create    3&gt; experiments//antagonist./agent-sol 或者agent-shinjuku./antagonist --scheduler=ghost --cpus=1,2,3,4,5,6,7,8//rocksdb./rocksdb --scheduler=ghost --rocksdb_db_path=/home/rocksdb/  ///cfs./rocksdb --scheduler=cfs --rocksdb_db_path=/home/rocksdb/ --throughput=200000 --num_workers=20 --worker_cpus=1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,21  --batch=1  All:Stage                        Total Requests     Throughput (req/s)     Min (us)     50% (us)     99% (us)     99.5% (us)   99.9% (us)   Max (us)    ----------------------------------------------------------------------------------------------------------------------------------------------------Ingress Queue Time           23528589           199938                 0            7559         2293590      2537468      2729921      2786260     Repeatable Handle Time       23528589           199938                 0            854          177527       206358       247805       254317      Worker Queue Time            23528589           199938                 0            0            0            1            4            25983       Worker Handle Time           23528589           199938                 10           10           13           14           15           13019       Total                        23528589           199938                 11           9601         2305599      2549779      2739167      2800522     //ghost./rocksdb --scheduler=ghost --rocksdb_db_path=/home/rocksdb/ --throughput=200000 --num_workers=20  --batch=1    Stage                        Total Requests     Throughput (req/s)     Min (us)     50% (us)     99% (us)     99.5% (us)   99.9% (us)   Max (us)    ----------------------------------------------------------------------------------------------------------------------------------------------------Ingress Queue Time（入队排队耗时）           8820243            200041                 0            0            32501        47881        71177        80389       Repeatable Handle Time       8820243            200041                 0            0            0            0            0            86          Worker Queue Time （查询耗时）           8820243            200041                 0            0            0            0            4            694068      Worker Handle Time           8820243            200041                 10           10           13           13           15           803878      Total                        8820243            200041                 10           11           34104        50669        76510        803880 在200000req/s情况下， 1 batch任务， 20个work来处理req时，ghost调度的99%的时延比cfs号很多Thread 1 \"rocksdb\" received signal SIGABRT, Aborted.0x00007ffff7b5bdd3 in pthread_kill () from /usr/lib64/libc.so.6(gdb) bt#0  0x00007ffff7b5bdd3 in pthread_kill () from /usr/lib64/libc.so.6#1  0x00007ffff7b0ffc6 in raise () from /usr/lib64/libc.so.6#2  0x00007ffff7afb457 in abort () from /usr/lib64/libc.so.6#3  0x00007ffff7e93c44 in ?? () from /usr/lib64/libstdc++.so.6#4  0x00007ffff7f12212 in std::__cxx11::basic_string&lt;char, std::char_traits&lt;char&gt;, std::allocator&lt;char&gt; &gt;::back() () from /usr/lib64/libstdc++.so.6#5  0x000000000053dc4f in rocksdb::SanitizeOptions(std::__cxx11::basic_string&lt;char, std::char_traits&lt;char&gt;, std::allocator&lt;char&gt; &gt; const&amp;, rocksdb::DBOptions const&amp;) ()#6  0x000000000083ce2b in rocksdb::DBImpl::DBImpl(rocksdb::DBOptions const&amp;, std::__cxx11::basic_string&lt;char, std::char_traits&lt;char&gt;, std::allocator&lt;char&gt; &gt; const&amp;, bool, bool) ()#7  0x0000000000546c68 in rocksdb::DBImpl::Open(rocksdb::DBOptions const&amp;, std::__cxx11::basic_string&lt;char, std::char_traits&lt;char&gt;, std::allocator&lt;char&gt; &gt; const&amp;, std::vector&lt;rocksdb::ColumnFamilyDescriptor, std::allocator&lt;rocksdb::ColumnFamilyDescriptor&gt; &gt; const&amp;, std::vector&lt;rocksdb::ColumnFamilyHandle*, std::allocator&lt;rocksdb::ColumnFamilyHandle*&gt; &gt;*, rocksdb::DB**, bool, bool) ()#8  0x00000000005463a2 in rocksdb::DB::Open(rocksdb::DBOptions const&amp;, std::__cxx11::basic_string&lt;char, std::char_traits&lt;char&gt;, std::allocator&lt;char&gt; &gt; const&amp;, std::vector&lt;rocksdb::ColumnFamilyDescriptor, std::allocator&lt;rocksdb::ColumnFamilyDescriptor&gt; &gt; const&amp;, std::vector&lt;rocksdb::ColumnFamilyHandle*, std::allocator&lt;rocksdb::ColumnFamilyHandle*&gt; &gt;*, rocksdb::DB**) ()#9  0x0000000000546158 in rocksdb::DB::Open(rocksdb::Options const&amp;, std::__cxx11::basic_string&lt;char, std::char_traits&lt;char&gt;, std::allocator&lt;char&gt; &gt; const&amp;, rocksdb::DB**)    ()#10 0x0000000000421e41 in ghost_test::Database::OpenDatabase(std::filesystem::__cxx11::path const&amp;) ()#11 0x0000000000421f26 in ghost_test::Database::Database(std::filesystem::__cxx11::path const&amp;) ()#12 0x000000000043fa9b in ghost_test::Orchestrator::Orchestrator(ghost_test::Orchestrator::Options, unsigned long) ()#13 0x0000000000426789 in ghost_test::GhostOrchestrator::GhostOrchestrator(ghost_test::Orchestrator::Options) ()#14 0x000000000043a586 in std::_MakeUniq&lt;ghost_test::GhostOrchestrator&gt;::__single_object std::make_unique&lt;ghost_test::GhostOrchestrator, ghost_test::Orchestrator::Options&amp;&gt;(ghost_test::Orchestrator::Options&amp;) ()main    -&gt;std::make_unique&lt;ghost_test::GhostOrchestrator&gt;(options)  //main.cc        -&gt;GhostOrchestrator::GhostOrchestrator(Orchestrator::Options opts) //rocksdb/ghost_orchestrator.cc            -&gt; Orchestrator::Orchestrator(Options options, size_t total_threads) //experiments/rocksdb/orchestrator.cc            //database、thread_pool构造函数 创建了database和thread_pool.            {                -&gt;InitThreadPool()                //kernel_schedulers(cfs, ghost, ghost,..) thread_work(GhostOrchestrator::LoadGenerator, GhostOrchestrator::Worker, GhostOrchestrator::Worker, ..)                  //thread_pool().Init(kernel_schedulers, thread_work);                 -&gt;InitGhost()                  //设置进程ghost参数            }       // thread_pool.Init实现： 根据KernelScheduler[]类型设置线程sched_attr，并执行thread_work[] 27 void ExperimentThreadPool::Init( 28     const std::vector&lt;ghost::GhostThread::KernelScheduler&gt;&amp; ksched, 29     const std::vector&lt;std::function&lt;void(uint32_t)&gt;&gt;&amp; thread_work) { 30   CHECK_EQ(ksched.size(), num_threads_); 31   CHECK_EQ(ksched.size(), thread_work.size()); 32  33   threads_.reserve(num_threads_); 34   for (uint32_t i = 0; i &lt; num_threads_; i++) { 35     threads_.push_back(std::make_unique&lt;ghost::GhostThread&gt;(  //根据ksched的type设置进程的sched_attr. 36         ksched[i], 37         std::bind(&amp;ExperimentThreadPool::ThreadMain, this, i, thread_work[i]))); //ThreadMain函数执行thread_work[i] 38   }\t... 45 void ExperimentThreadPool::ThreadMain( 46     uint32_t i, std::function&lt;void(uint32_t)&gt; thread_work) { 47   while (!ShouldExit(i)) { 48     thread_work(i); 49   } 50   num_exited_.fetch_add(1, std::memory_order_release); 51 }3&gt; ghost用户态工具的编译1 bazel//增加-g参数bazel build -c opt --copt=\"-g\" --cxxopt=\"-g\" --host_copt=\"-g\" --host_cxxopt=\"-g\" ...//~/.bazelrcbuild --cxxopt='-std=c++17' --cxxopt='-g'简介Bazel的目标之一是创建一个构建系统，在这个系统中，构建目标的输入和输出是完全指定的，因此构建系统可以精确地知道它们的输入和输出，这样可以更准确地分析和确定构建系统依赖图中过时的构建工件。使依赖图分析更加准确，通过避免重新执行不必要的构建目标，从而可能改善构建时间。通过避免构建目标可能依赖于过时的输入工件的错误，提高了构建的可靠性。https://docs.bazel.build/versions/main/command-line-reference.html help文件依赖cmake make gcc gcc-c++ elfutils-devel numactl-devel numactl-libs  libbpf libbpf-devel bcc bpftools libcap-devel llvm llvm-devel python3-pip编译##-g参数bazel build -c opt --copt=\"-g\" --cxxopt=\"-g\" --host_copt=\"-g\" --host_cxxopt=\"-g\" ...//http文件服务器搭建：https://blog.51cto.com/soysauce93/1725318https://www.cnblogs.com/zhuyeshen/p/11693362.html//遇事不行就关闭防火墙：systemctl stop firewalld.serviceForbidden：You don't have permission to access this resource.//遇到说权限不足的，注意看一下目录权限//修改文件web服务器sed -i \"s/https:\\/\\/github.com\\/bazelbuild\\/rules_foreign_cc\\/archive\\//http:\\/\\/x.x.x.x\\/bazel\\//g\" WORKSPACE直接编译方法：1、解决unable to find valid certification path to requested target     1&gt;先按照这个&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;\t\t//指定位置和密码         alias bazel='bazel --host_jvm_args=-Djavax.net.ssl.trustStore=/usr/lib/jvm/java-11-openjdk-11.0.9.11-4.oe1.x86_64/lib/security/cacerts --host_jvm_args=-Djavax.net.ssl.trustStorePassword=changeit'         bazel --host_jvm_args=-Djavax.net.ssl.trustStore=/usr/lib/jvm/java-11-openjdk-11.0.9.11-4.oe1.x86_64/lib/security/cacerts --host_jvm_args=-Djavax.net.ssl.trustStorePassword=changeit build agent_shinjuku     2&gt; 安装对应网站证书 &gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;\t//导入证书：点击左上角的锁icon -&gt; 证书 -&gt; 详细信息 -&gt; 复制到文件 -&gt; 选择Base64编码的X.509格式，保存证书到本地目录\tkeytool -import -file /root/caCert.cer -keystore /usr/lib/jvm/java-11-openjdk-11.0.9.11-4.oe1.x86_64/lib/security/cacerts  -trustcacerts -alias github_crt -storepass changeit          2、为了快捷下载linux包，采用本地web文件服务器        systemctl start httpd        systemctl stop firewalld.service//编译遇到pip CERTIFICATE_VERIFY_FAILED失败：SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: self signed certificate in certificate chain (_ssl.c:1123)解决：ssh-keygen//etc/pip.conf[root@localhost ghost-userspace]# cat ~/.pip/pip.conf [global]trusted-host = pypi.python.org               pypi.org               files.pythonhosted.orgverify = false//etc/pip.conf[root@localhost ghost-userspace]# cat /etc/pip.conf [global]trusted-host = pypi.python.org               pypi.org               files.pythonhosted.org[http]sslVerify = false[https]sslVerify = false//编译失败 'always_inline' 'uint8x16_t vaesmcq_u8(uint8x16_t)'In file included from external/com_google_absl/absl/random/internal/randen_hwaes.cc:229:/usr/lib/gcc/aarch64-linux-gnu/10.3.1/include/arm_neon.h: In function 'Vector128 {anonymous}::AesRound(const Vector128&amp;, const Vector128&amp;)':/usr/lib/gcc/aarch64-linux-gnu/10.3.1/include/arm_neon.h:12332:1: error: inlining failed in call to 'always_inline' 'uint8x16_t vaesmcq_u8(uint8x16_t)': target specific option mismatch12332 | vaesmcq_u8 (uint8x16_t data)//解决： + cpu_aarch64https://github.com/abseil/abseil-cpp/commit/2e94e5b6e152df9fa9c2fe8c1b96e1393973d32c    \":cpu_x64_windows\": ABSL_RANDOM_HWAES_MSVC_X64_FLAGS,    \":cpu_k8\": ABSL_RANDOM_HWAES_X64_FLAGS,    \":cpu_ppc\": [\"-mcrypto\"],   //+ \":cpu_aarch64\": ABSL_RANDOM_HWAES_ARM64_FLAGS,    # Supported by default or unsupported.    \"//conditions:default\": [],\t@@ -70,6 +71,7 @@ def absl_random_randen_copts_init():        \"darwin\",        \"x64_windows_msvc\",        \"x64_windows\",     // +  \"aarch64\",    ]    for cpu in cpu_configs:        native.config_setting(//arm64没有pause指令/tmp/ccVaJFns.s:15314: Error: unknown mnemonic `pause' -- `pause'//解决： pause -&gt; yield1&gt; 遇到编译错误ERROR: /root/.cache/bazel/_bazel_root/7e9b6806b9417f00ba913f77eac102ca/external/rules_foreign_cc/toolchains/BUILD.bazel:77:22: @platforms//os:windows is not a valid configuration key for @rules_foreign_cc//toolchains:built_make    //直接注释解决： 看这个暴力，非常有用    //rules_foreign_cc/toolchains/BUILD.bazel:77native_tool_toolchain(    name = \"built_make\",    path = select({        \"//conditions:default\": \"$(execpath :make_tool)/bin/make\",    }),    target = \":make_tool\",)     //rules_foreign_cc/foreign_cc/private/framework/platform.bzl:33 33 def framework_platform_info(name = \"platform_info\"): 34     \"\"\"Define a target containing platform information used in the foreign_cc framework\"\"\" 35     _framework_platform_info( 36         name = name, 37         os = select({ 38             \"//conditions:default\": \"unknown\", 39         }), 40         visibility = [\"//visibility:public\"], 41     )    //参考解决，实际没用    https://docs.bazel.build/versions/main/platforms-intro.htmlBUILD文件里指定编译目标，platforms, cpus:https://docs.bazel.build/versions/main/configurable-attributes.htmlExample: Constraint Valuesplatform(    name = \"linux_x86\",    constraint_values = [        \"@platforms//os:linux\",        \"@platforms//cpu:x86_64\",    ],)https://blog.csdn.net/don_chiang709/article/details/105727621\twget -c https://github.com/bazelbuild/bazel/releases/download/3.0.0/bazel-3.0.0-installer-linux-x86_64.sh    chmod +x bazel-3.0.0-installer-linux-x86_64.sh     ./bazel-3.0.0-installer-linux-x86_64.sh --user        https://john-millikin.com/bazel-school/toolchains@bazel_tools//platforms:cpu    @bazel_tools//platforms:arm    @bazel_tools//platforms:ppc    @bazel_tools//platforms:s390x    @bazel_tools//platforms:x86_32    @bazel_tools//platforms:x86_64@bazel_tools//platforms:os    @bazel_tools//platforms:freebsd    @bazel_tools//platforms:linux    @bazel_tools//platforms:osx    @bazel_tools//platforms:windows//clean:bazel clean --expunge//编译顺序：    base -&gt; base-test -&gt; ghost -&gt; shared-&gt; bazel build ... //编译所有的//bpf_skeleton -&gt; 定义bpf/bpf.bzl中    http://manpages.ubuntu.com/manpages/focal/man8/bpftool-gen.8.html-&gt; bpftools//[Bazel]自定义工具链\thttps://cloud.tencent.com/developer/article/1677379//bazel toolchain bazel 工具链https://kekxv.github.io/2021/08/06/bazel%20toolchain%2001///查看本地编译配置https://www.coder.work/article/2786053`bazel info output_base`/external/local_config_cc ---------------[root@localhost ghost-userspace]# ll `bazel  info output_base`/external/local_config_cctotal 32Klrwxrwxrwx. 1 root root  126 Nov 19 10:06 armeabi_cc_toolchain_config.bzl -&gt; /root/.cache/bazel/_bazel_root/7433de7b30d6d58a288c26dfb16d43d1/external/bazel_tools/tools/cpp/armeabi_cc_toolchain_config.bzl-rwxr-xr-x. 1 root root 4.4K Nov 19 10:06 BUILD-rwxr-xr-x. 1 root root  552 Nov 19 10:06 builtin_include_directory_pathslrwxrwxrwx. 1 root root  123 Nov 19 10:06 cc_toolchain_config.bzl -&gt; /root/.cache/bazel/_bazel_root/7433de7b30d6d58a288c26dfb16d43d1/external/bazel_tools/tools/cpp/unix_cc_toolchain_config.bzl-rwxr-xr-x. 1 root root  739 Nov 19 10:06 cc_wrapper.shdrwxr-xr-x. 3 root root 4.0K Nov 19 10:06 tools-rw-r--r--. 1 root root  111 Nov 19 10:06 WORKSPACE//rules_foreign_cc支持的cmake、make、ninja版本//rules_foreign_cc/foreign_cc/repositories.bzlregister_default_tools = True,cmake_version = \"3.21.2\",make_version = \"4.3\",ninja_version = \"1.10.2\",cmake 3.19.2make 4.3ninja_build 1.8.2编译所有的ghost-userspace的二进制：[root@localhost ghost-userspace]# bazel build ...INFO: Analyzed 62 targets (17 packages loaded, 1505 targets configured).INFO: Found 62 targets...INFO: Elapsed time: 48.090s, Critical Path: 15.80sINFO: 531 processes: 531 linux-sandbox.INFO: Build completed successfully, 798 total actions4&gt; 思考1、现在是CPU的进程调度放到用户态，这个有什么优势？ 还能继续做些什么？2、能结合反馈式智能调度吗？3、进程&lt;—-&gt;资源调度？4、CFS调度器的参数是全局的？ 如果有资源隔离的话，可以将CFS也可以按照隔离域独立设置参数吗？5、内核调度器中bpf的拓展, 那内存部分ebpf可以有所作为吗？https://www.ebpf.top/post/cfs_scheduler_bpf/  cfs的bpf优化.https://jirnal.com/train-of-ebpf-in-cpu-scheduler/TRAIN OF EBPF IN CPU SCHEDULEReBPF has been frail broadly in efficiency profiling and monitoring. In this affirm, I am going to exclaim a location of eBPF positive aspects that aid show screen and beef up cpu scheduling performances. These positive aspects consist of:Profiling scheduling latencies. I am going to focus on an software program of eBPF to amass scheduling latency stats.Profiling useful resource effectivity. For background, I am going to first introduce the scheduler characteristic core scheduling which is developed for mitigating L1TF cpu vulnerability. Then I am going to introduce the eBPF characteristic ksym which enables this software program and affirm how eBPF can support yarn the forced lazy time, a invent of cpu usage inefficiency caused by core scheduling.The third software program of eBPF is to encourage userspace scheduling. ghOSt is a framework open sourced by Google to enable overall-goal delegation of scheduling protection to userspace processes in a Linux ambiance. ghOSt uses BPF acceleration for defense actions that deserve to occur closer to scheduling edges. We use this to maximize CPU utilization (pick_next_task), decrease jitter (task_tick elision) and preserve watch over tail latency (select_task_rq on wakeup). We’re also experimenting with BPF to place in pressure a scaled-down variant of the scheduling protection while upgrading the principle userspace ghOSt agent.三、扩展1&gt;、调度激活机制https://www.codenong.com/cs105549070/ 调度激活机制upcall具体做了什么？内核发现用户进程的一个线程被block了（比如调用了一个被block的system call，或者发生了缺页异常。内核通过进程的运行时线程被block（还会告知被block的线程的详细信息），这个就是upcall进程的运行时系统接收到内核发来的消息，得知自己的线程被block运行时系统先将当前线程标识为block（会保存在线程表-thread table）运行时系统从当前线程表（thread table）选择一个ready的线程进行运行至此已经完成了当一个进程内的一个用户线程被block(比如发生缺页异常）时，不会导致整个进程被block，这个进程的内的其他用户线程还可以继续运行（类似于内核线程）。当内核发现之前被block的线程可以run了，同样会通过upcall通知运行时系统，运行时系统要么马上运行该线程，要么把该线程标志位ready放入线程表。2&gt;、基于网络栈的用户态定制调度Syrup: User-Defined Scheduling Across the Stackhttp://stanford.edu/~kkaffes/papers/syrup.pdfhttps://zhuanlan.zhihu.com/p/4645603153&gt; fast preemt快速抢占https://ubuntu.com/blog/industrial-embedded-systems-ii  Low latency Linux kernel for industrial embedded systems – Part II4&gt; 轻量级线程LWTPS：1&gt; linux内核进程状态机转化https://blog.51cto.com/ciellee/3411615 操作系统进程状态和状态转换详解\tshenango:Process Context Identifiers (PCIDs) allow page tables to be swapped without flushing the TLB2&gt; 可监控的资源            监控类型                  end-to-end  latency              schedule  latency              Memory  Bandwidth              LLC miss rate              Network  Bandwidth              Disk Bandwidth      应用特征不同，资源监控（cpu、内存、磁盘、网络）使用率和策略应该是定制化的。或者是性能特征来作为资源调度的依据3&gt; 现有混布与ghost方案对比1、QOS混部方案当前的缺点及问题 QOS混布方案是在内核CFS增加定制，由于CFS本身的复杂度很高，导致新增调度策略实现难度大，扩展性弱。     2、Ghost方案的主要特点，及对比混部的优势  1&gt; 可定制的调度实现框架，可以结合场景特点来设计满足不同延迟、吞吐量要求的调度器。  2&gt; 在用户态设计调度策略，独立于内核的CFS调度器，降低调度器实现难度，扩展性强。  3&gt; ghost可以灵活部署，可以支持动态升级回滚，不需要重新编译内核、重启。 ghost就是提供了调度器的设计、实现、部署的一种新范式，与传统的调度器设计有很大区别。    3、Ghost框架灵活性等特点，是否有解决其他问题的潜力   有解决其他问题的潜力；    1&gt; ghost设计之初是在google的数据中心使用，实现在高吞吐量的前提实现低尾时延；    2&gt; 由于具有灵活的可定制调度策略的特性，混布场景自然也可以使用    3&gt; 异构设备场景下的任务调度分发或许也是个很好的场景。"
  },
  
  {
    "title": "The Robot Operating System 2 (ROS2)",
    "url": "/posts/ROS2-For-Industrial-Control/",
    "categories": "Package, ROS2",
    "tags": "ROS2",
    "date": "2021-07-21 00:00:00 +0000",
    





    
    "snippet": "一、ROS2介绍https://www.jianshu.com/p/3829624ac310 //ROS2简介 有图有介绍，很详细1) 基本概念ROS1 Vs ROS2.pngNodes-节点概念节点即Node，是ROS里面的一个执行体，可以和其他节点直接在ROS中互相通信。Node是Package里面的可执行文件的一个功能体现（也就是说Package的可执行文件能够实现的功能不仅仅是一个N...",
    "content": "一、ROS2介绍https://www.jianshu.com/p/3829624ac310 //ROS2简介 有图有介绍，很详细1) 基本概念ROS1 Vs ROS2.pngNodes-节点概念节点即Node，是ROS里面的一个执行体，可以和其他节点直接在ROS中互相通信。Node是Package里面的可执行文件的一个功能体现（也就是说Package的可执行文件能够实现的功能不仅仅是一个Node，还有其他的功能，但是Node是其最基本的一个功能）。节点通过发布messages到topic来实现互相通信。也可以调用ROS的service实现request和response的消息交换。Messages-消息概念message 是一种由类型字段（类型域）组成的简单数据结构。支持原始的标准类型（整数、浮点、布尔、数组等），同时支持类似C语言的结构和数组嵌套。我们使用.msg格式的的文本文件指定消息的数据结构。Topic-话题概念Topic 被称为节点信息交互的总线，话题拥有匿名发布和订阅语义，这样能够解耦信息的生产者和使用者。通常来说，节点是不清楚他们在和谁通信，他们更关注所订阅话题的数据。一个话题可以有多个订阅者和发布者。Discovery-发现节点之间的互相发现是ROS2底层的中间件自动运行的一个进程，通过这个进程不同的节点相互发现，建立连接。这是区别ROS1中的master，真正实现了分布式通信。当一个节点启动后， 它会向其他拥有相同ROS域名(ROS domain， 可以通过设置ROS_DOMAIN_ID环境变量来设置)的节点进行广播，说明它已经上线。其他节点在收到广播后返回自己的相关信息，这样节点间的连接就可以建立了，之后就可以通信了。节点会定时广播它的信息，这样即使它已经错过了最初的发现过程，它也可以和新上线的节点进行连接。节点在下线前它也会广播其他节点自己要下线了。节点只会和具有相兼容的[服务质量]设置的节点进行通信。2) Qos3)Real-Time Publish/Subscribe Protocol实时发布订阅协议（Real Time Publish Subscribe Protocol，RTPS）是一种协议，用于在单播和多播中通过UDP等不可靠传输进行best effort和reliable的发布-订阅通信.RTPS协议的主要特点是：性能和服务质量（QoS）属性，为使用标准IP网络的实时应用程序提供best-effort和reliable的发布-订阅通信。容错，可以创建没有单点故障的网络。可扩展性，可以通过协议的扩展和新服务的增强实现向后兼容性和互操作性。即插即用连接，新的应用程序和服务允许通过应用程序随时加入和离开网络来实现自动的、无需配置的发现。可配置性，可以平衡每个数据交付事务的可靠性和及时性需求。模块化，允许简单的设备实现协议的子集，并且仍然参与发布-订阅网络。可伸缩性，使系统能够扩展到非常大的发布-订阅网络。类型安全，防止应用程序编程错误影响发布-订阅网络中的远程节点的操作。OMG规范： 定义了基于RTPS的DDS设计https://www.omg.org/spec/DDSI-RTPS/2.2/PDFhttps://blog.csdn.net/DDS_CSIT/article/details/104940013 spec的中文文档https://paul.pub/dds-and-fastrtps/在DDS规范中，有两个描述标准的基本文档：DDS Specification：描述了以数据为中心的发布-订阅模型。该规范定义了API和通信语义（行为和服务质量），使消息从消息生产者有效地传递到匹配的消费者。DDS规范的目的可以概括为：“能够在正确的时间将正确的信息高效，可靠地传递到正确的位置”。DDSI-RTPS：描述了RTPS（Real Time Publish Subscribe Protocol）协议。该协议通过UDP等不可靠的传输，实现最大努力（Best-Effort）和可靠的发布-订阅通信。RTPS是DDS实现的标准协议，它的目的和范围是确保基于不同DDS供应商的应用程序可以实现互操作。    传输控制Fast-RTPS实现了可插拔的传输架构，这意味着每一个参与者可以随时加入和退出。在传输上，Fast-RTPS支持以下五种传输方式：UDPv4 UDPv6 TCPv4 TCPv6 SHM（Shared Memory）默认的，当Participant创建时，会自动的配置两个传输通道：SHM：用来与同一个机器上的参与者通信。UDPv4：同来与跨机器的参与者通信。当然，开发者可以改变这个默认行为，通过C++接口或者XML配置文件都可以。SHM要求所有参与者位于同一个系统上，它是借助了操作系统提供的共享内存机制实现。共享内存的好处是：支持大数据传输，减少了数据拷贝，并且也减少系统负载。因此通常情况下，使用SHM会获得更好的性能。使用SHM时，可以配置共享内存的大小。(1)The DDSI-RTPS (DDS-Interoperability Real Time Publish Subscribe) protocol     (2)eProsima’s FastRTPS implementation is available on GitHub and is LGPL licensed:https://github.com/eProsima/Fast-RTPSeProsima Fast RTPS is a relatively new, lightweight, and open source implementation of RTPS. It allows direct access to the RTPS protocol settings and features, which is not always  possible with other DDS implementations. eProsima’s implementation also includes a minimum  DDS API, IDL support, and automatic code generation and they are open to working with the  ROS community to meet their needs.https://fast-dds.docs.eprosima.com/en/latest/ 介绍fast-dds with fast-RTPShttps://www.brixbot.com/ros2/fast_rtps-02-introduce_fast_buffer/ https://zhuanlan.zhihu.com/p/59465983ROS 2使用Fast RTPS去实现消息的订阅和发布。而Fast RTPS要通过网络发送消息，就一定要把消息序列化成byte array发送出去，然后消息订阅方收到消息后要把byte array还原成对应的消息对象。消息的序列化和消息对象的还原就是Fast Buffers干的活。按官网介绍，特点就是快。eProsima有对比Apache Thrift和Google Protocol Buffers，其结果当然是自家的Fast Buffers完胜。http://design.ros2.org/articles/ros_on_dds.htmlPublish-Subscribe TransportThe DDSI-RTPS (DDS-Interoperability Real Time Publish Subscribe) protocol would replace ROS’s TCPROS and UDPROS wire protocols for publish/subscribe. The DDS API provides a few more actors to the typical publish-subscribe pattern of ROS 1. In ROS the concept of a node is most clearly paralleled to a graph participant in DDS. A graph participant can have zero to many topics, which are very similar to the concept of topics in ROS, but are represented as separate code objects in DDS, and is neither a subscriber nor a publisher. Then, from a DDS topic, DDS subscribers and publishers can be created, but again these are used to represent the subscriber and publisher concepts in DDS, and not to directly read data from or write data to the topic. DDS has, in addition to the topics, subscribers, and publishers, the concept of DataReaders and DataWriters which are created with a subscriber or publisher and then specialized to a particular message type before being used to read and write data for a topic. These additional layers of abstraction allow DDS to have a high level of configuration, because you can set QoS settings at each level of the publish-subscribe stack, providing the highest granularity of configuration possible. Most of these levels of abstractions are not necessary to meet the current needs of ROS. Therefore, packaging common workflows under the simpler ROS-like interface (Node, Publisher, and Subscriber) will be one way ROS 2 can hide the complexity of DDS, while exposing some of its features.https://docs.ros.org/en/foxy/Concepts.html#internal-ros-interfaces //ROS2 官网概念介绍https://docs.ros.org/en/foxy/Tutorials/Writing-A-Simple-Cpp-Publisher-And-Subscriber.html // ROS2官网简单pub-sub用例二、DDS介绍https://docs.ros.org/en/foxy/Tutorials/Discovery-Server/Discovery-Server.html?highlight=dischttp://design.ros2.org/articles/ros_on_dds.html数据分发服务DDS(DataDistributionService)是对象管理组织(OMG)在HLA及CORBA等标准的基础上制定的新一代分布式实时通信中间件技术规范，DDS采用发布/订阅体系架构，强调以数据为中心，提供丰富的QoS服务质量策略，能保障数据进行实时、高效、灵活地分发，可满足各种分布式实时通信应用需求。DDS信息分发中间件是一种轻便的、能够提供实时信息传送的中间件技术。\t原文链接：https://blog.csdn.net/DDS_CSIT/article/details/104607476三、使用1&gt; 编译1、编译过程：cd HERAcolcon build --install-base /opt/hera --merge-install2、依赖包综合：yum install libacl-devel python3-importlib-resources libatomic tinyxml2 tinyxml2-devel python3-lark-parser log4cxx log4cxx-devel python3-numpy \tyum install boost//https://pkgs.dyn.su/el8/extras/x86_64/asio-devel-1.14.0-12.el8.x86_64.rpmyum localinstall asio-devel-1.14.0-12.el8.x86_64.rpmrepo:环境信息：[root@localhost HERA]# uname -aLinux localhost.localdomain 4.18.0-240.el8.x86_64 #1 SMP Fri Sep 25 19:48:47 UTC 2020 x86_64 x86_64 x86_64 GNU/Linux[download-ib01.fedoraproject.org_pub_epel_8_Everything_x86_64_]name=created by dnf config-manager from https://download-ib01.fedoraproject.org/pub/epel/8/Everything/x86_64/baseurl=https://download-ib01.fedoraproject.org/pub/epel/8/Everything/x86_64/enabled=1yum install python36-colcon-coreyum install python3-colcon-common-extensionsyum install cmake问题1：HERA/src/iceoryx_v0.17.0/iceoryx_utils/platform/linux/include/iceoryx_utils/platform/acl.hpp:17:10: fatal error: sys/acl.h: No such file or directoryyum install libacl-devel问题2：Traceback (most recent call last):  File \"/opt/hera/lib/python3.6/site-packages/ament_package/templates.py\", line 19, in &lt;module&gt;    import importlib.resources as importlib_resourcesModuleNotFoundError: No module named 'importlib.resources'yum install python3-importlib-resources问题3:Starting &gt;&gt;&gt; test_osrf_testing_tools_cpp--- stderr: iceoryx_posh                                                                            /usr/bin/ld: cannot find /usr/lib64/libatomic.so.1.2.0collect2: error: ld returned 1 exit statusyum install libatomic问题4：Starting &gt;&gt;&gt; ament_cmake_pyflakes--- stderr: tinyxml2_vendor                                                                                       CMake Error at /usr/share/cmake/Modules/FindPackageHandleStandardArgs.cmake:165 (message):  Could NOT find TinyXML2 (missing: TINYXML2_LIBRARY TINYXML2_INCLUDE_DIR)Call Stack (most recent call first):  /usr/share/cmake/Modules/FindPackageHandleStandardArgs.cmake:458 (_FPHSA_FAILURE_MESSAGE)  cmake/Modules/FindTinyXML2.cmake:58 (find_package_handle_standard_args)  CMakeLists.txt:7 (find_package)yum install tinyxml2 tinyxml2-devel问题5：--- stderr: rosidl_adapter                                                           CMake Warning at /opt/hera/share/ament_cmake_pytest/cmake/ament_add_pytest_test.cmake:77 (message):  The Python module 'pytest' was not found, pytests cannot be run.  On Linux,  install the 'python3-pytest' package.  On other platforms, install 'pytest'  using pip.Call Stack (most recent call first):  CMakeLists.txt:14 (ament_add_pytest_test)问题6：--- stderr: rosidl_generator_c                                                                              Traceback (most recent call last):  File \"/home/luocheng/HERA/src/ros2/rosidl/rosidl_generator_c/bin/rosidl_generator_c\", line 8, in &lt;module&gt;    from rosidl_generator_c import generate_cModuleNotFoundError: No module named 'rosidl_generator_c'During handling of the above exception, another exception occurred:Traceback (most recent call last):  File \"/home/luocheng/HERA/src/ros2/rosidl/rosidl_generator_c/bin/rosidl_generator_c\", line 20, in &lt;module&gt;    rosidl_generator_c = loader.load_module()  File \"&lt;frozen importlib._bootstrap_external&gt;\", line 399, in _check_name_wrapper  File \"&lt;frozen importlib._bootstrap_external&gt;\", line 823, in load_module  File \"&lt;frozen importlib._bootstrap_external&gt;\", line 682, in load_module  File \"&lt;frozen importlib._bootstrap&gt;\", line 265, in _load_module_shim  File \"&lt;frozen importlib._bootstrap&gt;\", line 684, in _load  File \"&lt;frozen importlib._bootstrap&gt;\", line 665, in _load_unlocked  File \"&lt;frozen importlib._bootstrap_external&gt;\", line 678, in exec_module  File \"&lt;frozen importlib._bootstrap&gt;\", line 219, in _call_with_frames_removed  File \"/home/luocheng/HERA/src/ros2/rosidl/rosidl_generator_c/rosidl_generator_c/__init__.py\", line 15, in &lt;module&gt;    from rosidl_cmake import convert_camel_case_to_lower_case_underscore  File \"/opt/hera/lib/python3.6/site-packages/rosidl_cmake/__init__.py\", line 24, in &lt;module&gt;    from rosidl_parser.parser import parse_idl_file  File \"/opt/hera/lib/python3.6/site-packages/rosidl_parser/parser.py\", line 20, in &lt;module&gt;    from lark import LarkModuleNotFoundError: No module named 'lark'gmake[2]: *** [CMakeFiles/rosidl_generator_c_interfaces__rosidl_generator_c.dir/build.make:104: rosidl_generator_c/rosidl_generator_c/msg/arrays.h] Error 1gmake[1]: *** [CMakeFiles/Makefile2:298: CMakeFiles/rosidl_generator_c_interfaces__rosidl_generator_c.dir/all] Error 2gmake[1]: *** Waiting for unfinished jobs....gmake: *** [Makefile:160: all] Error 2yum install python3-lark-parser问题7：Starting &gt;&gt;&gt; test_launch_testing--- stderr: fastrtps                                                                               CMake Error at cmake/modules/FindAsio.cmake:22 (message):  Not found a local version of Asio installed.Call Stack (most recent call first):  cmake/common/eprosima_libraries.cmake:212 (find_package)  CMakeLists.txt:228 (eprosima_find_thirdparty)yum install boost//https://pkgs.dyn.su/el8/extras/x86_64/asio-devel-1.14.0-12.el8.x86_64.rpmyum localinstall asio-devel-1.14.0-12.el8.x86_64.rpm问题8：--- stderr: rcl_logging_log4cxx                                                                                CMake Error at /usr/share/cmake/Modules/FindPackageHandleStandardArgs.cmake:165 (message):  Log4cxx_INCLUDE_DIR (missing: Log4cxx_LIBRARY)Call Stack (most recent call first):  /usr/share/cmake/Modules/FindPackageHandleStandardArgs.cmake:458 (_FPHSA_FAILURE_MESSAGE)  cmake/FindLog4cxx.cmake:35 (FIND_PACKAGE_HANDLE_STANDARD_ARGS)  CMakeLists.txt:16 (find_package)---Failed   &lt;&lt;&lt; rcl_logging_log4cxx [1.04s, exited with code 1]yum install log4c log4c-devel  log4cplus log4cplus-devel log4cxx log4cxx-devel问题9：Starting &gt;&gt;&gt; rosidl_typesupport_cpp--- stderr: rosidl_generator_py                                                                                Traceback (most recent call last):  File \"&lt;string&gt;\", line 1, in &lt;module&gt;ModuleNotFoundError: No module named 'numpy'CMake Error at cmake/rosidl_generator_py_generate_interfaces.cmake:213 (message):  execute_process(/usr/bin/python3 -c 'import  numpy;print(numpy.get_include())') returned error code 1Call Stack (most recent call first):  /opt/hera/share/ament_cmake_core/cmake/core/ament_execute_extensions.cmake:48 (include)  /opt/hera/share/rosidl_cmake/cmake/rosidl_generate_interfaces.cmake:286 (ament_execute_extensions)  CMakeLists.txt:48 (rosidl_generate_interfaces)---Failed   &lt;&lt;&lt; rosidl_generator_py [1.25s, exited with code 1]Aborted  &lt;&lt;&lt; rosidl_typesupport_cpp [4.56s]  yum install python3-numpy2&gt; 用例测试1.hera编完要这样设置下环境变量，再去编测试套。source /opt/hera/setup.bash2.clone测试套和编译git clone ssh:/xxs/RobotSDK_Tests.gitcd RobotSDK_Tests/ROS2/dev_ws#Step1：编译自定义的数据结构colcon build --packages-select my_struct#Step2：执行环境变量脚本source install/setup.bash#Step3：编译listen_talk包colcon build --packages-select listen_talk3.运行cd build/listen_talk/#pty1./talker [ -z ]  ## -z 为zero-copy版本     #pty2 ./listener4.result#pty1[root@localhost listen_talk]# ./talker -zStarting to do test using zero-copy!!!!!!!!!!!!![INFO] [1623937655.203340827] [minimal_publisher]: Publishing: (128 64 0) 1623937655203335[INFO] [1623937656.203293168] [minimal_publisher]: Publishing: (128 64 1) 1623937656203291#pty2[root@localhost listen_talk]# ./listener [INFO] [1623937688.203468974] [minimal_subscriber]: I heard: (128, 64, 33), size = 2097152, latency: 157 us[INFO] [1623937689.203369801] [minimal_subscriber]: I heard: (128, 64, 34), size = 2097152, latency: 78 us[INFO] [1623937690.203362141] [minimal_subscriber]: I heard: (128, 64, 35), size = 2097152, latency: 73 us[INFO] [1623937691.203375374] [minimal_subscriber]: I heard: (128, 64, 36), size = 2097152, latency: 80 us四 ROS2场景-工业机械臂https://cn.element14.com/robotic-arm​\t机械臂是工业机器人的一个关键组成部分。通过机械臂上安装的工具，可以执行各种不同的工作，如焊接、油漆和货盘装运。目前在广泛的工业应用中采用了若干类型的机械臂，即卡式机械臂、圆柱机械臂、极性机械臂和关节式机械臂。其中关节式机械臂使用最广，并且其DOF（自由度）较高，体积小，操作范围广，可以避开小范围内的障碍物。​\t关节式机械臂通常由刚性杆和可旋转关节构成。伺服控制系统用于控制伺服电机，后者驱动关节旋转。该系统中包含三个模块：伺服电机控制模块、传感器模块和中央控制模块。伺服电机控制模块中集成了MCU、电机驱动器、编码器与电流传感器。MCU根据中央模块的指令MCU将控制信号发给电机驱动器，后者放大这些信号以驱动电机旋转。编码器和电流传感器负责监测电机，并将反馈信息发送回MCU，以确保伺服电机正常工作。传感器模块涉及多种类型的传感器，如接近传感器、图像传感器、压力传感器和LVDT传感器，这些传感器用于收集有关机械臂的运动信息，并在由信号调节电路处理之后发送给中央控制模块。中央控制模块拥有DSP和PLC模块。DSP根据传感器模块提供的数据计算关节的运动轨迹和参数。然后通过CAN总线将结果发送给伺服电机控制模块，以便机械臂实施所需操作。PLC模块提供人机界面，供用户设置程序来控制机械臂。此外，PLC模块还有用于连接紧急按钮和不同类型继电器的接口，紧急按钮和继电器用于控制机械臂上连接的工具。https://wenku.baidu.com/view/9e3e54d86f1aff00bed51e2a.html"
  },
  
  {
    "title": "Realtime Operating System",
    "url": "/posts/Real-time-operating-system/",
    "categories": "linux, RTOS",
    "tags": "RTOS",
    "date": "2021-06-28 00:00:00 +0000",
    





    
    "snippet": "一、RT linux patchLinux kernel在spinlock、irq上下文方面无法抢占，因此高优先级任务被唤醒到得以执行的时间并不能完全确定。同时，Linux kernel本身也不处理优先级反转。RT-Preempt Patch是在Linux社区kernel的基础上，加上相关的补丁，以使得Linux满足硬实时的需求。RT-Preempt Patch对Linux kernel的主...",
    "content": "一、RT linux patchLinux kernel在spinlock、irq上下文方面无法抢占，因此高优先级任务被唤醒到得以执行的时间并不能完全确定。同时，Linux kernel本身也不处理优先级反转。RT-Preempt Patch是在Linux社区kernel的基础上，加上相关的补丁，以使得Linux满足硬实时的需求。RT-Preempt Patch对Linux kernel的主要改造包括： //1. spinlock/sem优化，支持抢占Making in-kernel locking-primitives (using spinlocks) preemptible though reimplementation with rtmutexes:Critical sections protected by i.e. spinlock_t and rwlock_t are now preemptible. The creation of non-preemptible sections (in kernel) is still possible with raw_spinlock_t (same APIs like spinlock_t)Implementing priority inheritance for in-kernel spinlocks and semaphores. For more information on priority inversion and priority inheritance please consult Introduction to Priority Inversion (http://www.embedded.com/electronics-blogs/beginner-s-corner/4023947/ Introduction-to-Priority-Inversion)//中断线程化，中断支持抢占Converting interrupt handlers into preemptible kernel threads: The RT-Preempt patch treats soft interrupt handlers in kernel thread context, which is represented by a task_struct like a common userspace process. However it is also possible to registeran IRQ in kernel context.Converting the old Linux timer API into separate infrastructures for high resolution kernel timers plus one for timeouts, leading to userspace POSIX timers with high resolution.原文链接：https://blog.csdn.net/juS3Ve/article/details/79788554通过Preempt_RT来实现Linux实时性的关键点是减少内核中非抢占性（non-preemptible）的代码量，且要尽量减少对实际的代码的修改量。为了减少内核中非抢占性（non-preemptible）的代码量，需要实现对临界区（critical secitons），中断处理例程（interrupt handlers），中断屏蔽代码段（interrupt-disable code sequences）的可抢占性。为了减少对实际的代码的修改量，Preempt_RT patches充分重用了LInux kernel对SMP的支持能力，从而避免了对Linux kernel的大量重写。原文链接：https://github.com/chyyuu/rt-patch-analysis/blob/master/developers/chy/techreport.md2  实时抢占补丁研究2.1 实时补丁现状    实时抢占补丁(RealtimePreemptionPatch,PreemptRT)是由IngoMolnar和ThomasGleixner更新维护,和其他在微内核中通过增加实时抢占方法所不同,它原有的低延迟补丁和抢占补丁的基础上,加入中断线程化、高精度时钟、优先级继承等新特性,将Linux内核修改成完全可抢占式内核,使其具有硬实时能力。目前,PreemptRT还没有完全加入到标准Linux内核中,但部分抢占支持、高精度时钟、中断线程化等已经加入到最近的内核版本中,如Linux2．6．23内核中加入CompletelyFairScheduler(CFS)、2．6．24版本中加入高精度时钟以及2．6．30版本加入中断线程化特性等。对完全可抢占的支持目前还没有加入内核中,但增加PreemptRT后可实现。因此,随着实时特性不断融入Linux内核中,其实时性会越来越强。2.2实时抢占补丁分析    本文针对Linux2．6．33内核实时抢占补丁中一些关键的实时特性进行分析。其中包括新型锁机制、中断线程化、优先级继承、高精度时钟。(1) 新型锁机制提升内核性能    PreemptRT将大内核锁(BKL)和自旋锁(spinlock)全部转化为优先级继承的互斥锁(mutex),持有锁的线程可以被抢占,减少了内核调度延迟,避免了不必要的时间开销;同时该补丁实现了可抢占的RCU(Read-CopyUpdate)锁和串行化读写锁,提高了内核性能。(2) 中断线程化    中断线程化是实时改造Linux的一个重要步骤。在Linux标准内核中,中断是最高优先级的执行单元,只要有中断事件,系统将立即响应,会使中断非常频繁,实时任务很难有机会运行。为解决这个问题,引入了中断线程化,中断将作为内核线程运行而且被赋予不同的实时优先级,若实时任务比到来的中断线程拥有更高的优先级,实时任务不会被中断线程中断。中断线程化保证了实时性,减小实时抢占延迟。(3) 优先级继承    自旋锁被互斥锁取代后会产生优先级逆转(rriorityinversion)现象,即优先级高的进程由于优先级低的进程保持了竞争资源被迫等待,而让中间优先级的进程运行。优先级逆转将导致高优先级进程的抢占延迟增大,不能保证实时性。为避免不可预期的优先级反转问题,PreemptRT实现了优先级继承协议,即自旋锁的保持者将继承高优先级的竞争者进程的优先级,从而能先于中间优先级进程运行,尽可能快地释放锁,这样高优先级进程就能很快得到竞争的自旋锁,使抢占延迟更短[7].(4) 高精度时钟Linux标准内核通过基于Jiffies周期性时钟滴答计时,而且高精度的时间获取需要依赖特定的平台,为调度短周期任务,需要设置时钟频率为更小值,意味着时钟中断更加频繁,会造成大量时钟中断处理和资源浪费。为了解决这个问题,实时抢占内核的时钟系统重新设计,实现了高精度定时器[8]。时钟精度不再依赖jiffies,使POSIX定时器和nanosleep精度由具体硬件提供的精度决定,从而系统调用gettimeofday能够获得精确的时间值。原文链接：http://www.ecice06.com/CN/article/downloadArticleFile.do?attachType=PDF&amp;id=25958二、freeRTOS /RTOS三、EVL / XenomaiRTlinux （海康）"
  },
  
  {
    "title": "Opensource License",
    "url": "/posts/Opensource-license/",
    "categories": "Package, License",
    "tags": "License",
    "date": "2021-05-01 00:00:00 +0000",
    





    
    "snippet": "一、CDLL license```c/*  CDDL HEADER START *  The contents of this file are subject to the terms of the  Common Development and Distribution License (the “License”).  You may not use this file except ...",
    "content": "一、CDLL license```c/*  CDDL HEADER START *  The contents of this file are subject to the terms of the  Common Development and Distribution License (the “License”).  You may not use this file except in compliance with the License. *  You can obtain a copy of the license at usr/src/OPENSOLARIS.LICENSE  or http://www.opensolaris.org/os/licensing.  See the License for the specific language governing permissions  and limitations under the License. *  When distributing Covered Code, include this CDDL HEADER in each  file and include the License file at usr/src/OPENSOLARIS.LICENSE.  If applicable, add the following below this CDDL HEADER, with the  fields enclosed by brackets “[]” replaced with your own identifying  information: Portions Copyright [yyyy] [name of copyright owner] *  CDDL HEADER END */静态/动态链接，自研代码部分均不感染~  但是对CDDL开源软件本身的修改，必须以CDDL开源.1、 CDDL 与 GPL不兼容https://fedoraproject.org/wiki/Licensing/CDDLThe Common Development and Distribution License (CDDL) version 1.0 is a Free license, but it was intentionally drafted by Sun in such a way as to make it GPL (v2 and v3) incompatible. A copy of this license was taken from https://netbeans.org/cddl-gplv2.html on Wednesday, August 21, 2013. It was previously available at http://www.opensolaris.org/os/licensing/cddllicense.txt, but that link has been removed by Oracle.（1）GPL软件本身须开源。 具有传染性，与其有链接关系的代码都必须以GPL许可对外开源，即与该软件在同一进程中运行的代码都必须开源.GPL协议的主要内容是只要在一个软件中使用(”使用”指类库引用，修改后的代码或者衍生代码)GPL 协议的产品，则该软件产品必须也采用GPL协议，既必须也是开源和免费。这就是所谓的”传染性”。GPL协议的产品作为一个单独的产品使用没有任何问题，还可以享受免费的优势。由于GPL严格要求使用了GPL类库的软件产品必须使用GPL协议，对于使用GPL协议的开源代码，商业软件或者对代码有保密要求的部门就不适合集成/采用作为类库和二次开发的基础。(2)  CDDL静态/动态链接，自研代码部分均不感染~  但是对CDDL开源软件本身的修改，必须以CDDL开源如果GPL license的软件要引用CDDL license的软件，如果无法做到进程隔离，那么CDDL license被要求以GPL的license开源，与CDDL的本身的license要求冲突，导致不兼容。2、 CDDL与LGPL的兼容，只能动态库引用，使用时不做任何修改3、CDDL与商业友好license 例如BSD兼容，使用时不做任何修改4、CDDL与自研代码可能存在兼容风险， 如果自研代码没有使用GPL（进程隔离），可以直接使用。二 LICENSE对比            见许可证类型      典型软件      触发代码开源义务前提条件      开源要求和范围      规避开源方式                  BSD类如Apache/BSD/MIT等      Tomcat,OpenSSL      无      无      不涉及              MPL类如：MPL/EPL等      FireFox,Eclipse      产品集成使用该软件，并对外分发或销售产品对该软件进行了修改      若无修改，则无需开源若对其进行了修改，需将修改的部分开源      使用时不做任何修改              LGPL      Hibernate，glibc      产品集成使用该软件，并对外分发或销售      软件本身须开源。 具有传染性，与其静态链接部分的代码也必须以LGPL许可开源；动态链接则不被传染。若对其进行修改，若修改后增加的功能实现依赖于产品软件的数据或功能，则产品代码也会被传染。      动态链接使用，仅开源其软件本身即可，产品代码可免受传染。              GPL      Busybox，linux kernel      产品集成使用该软件，并对外分发或销售      软件本身须开源。 具有传染性，与其有链接关系的代码都必须以GPL许可对外开源，即与该软件在同一进程中运行的代码都必须开源      进程隔离，独立于产品进程运行，仅开源其软件本身即可，产品代码可免受传染              AGPL      Berkeley_DB      产品集成使用该软件      在GPL上增加了一条限制：即便不对外分发，只要在网络服务器上使用AGPL软件提供网络服务，就需要履行相关开源义务。例如： Berkeley_DB，即使没有“分发”动作，通过WEB形式为用户提供服务，也要履行对外开源义务。      同GPL      "
  },
  
  {
    "title": "Memory Leakage Check Mechanism",
    "url": "/posts/Memory-Leakage-Check-Mechanism/",
    "categories": "Package, userspace memleak",
    "tags": "userspace memleak",
    "date": "2021-04-02 00:00:00 +0000",
    





    
    "snippet": "基于下面网站内容分析https://blog.csdn.net/lqxandroid2012/article/details/79799844一、libumem内存检查https://www.codenong.com/8287649/环境变量UMEM_DEBUG此变量包含逗号分隔的选项列表。忽略无法识别的选项。可能的选项包括：审计【=帧】此选项启用记录审计信息，包括线程ID、高分辨率时间戳和...",
    "content": "基于下面网站内容分析https://blog.csdn.net/lqxandroid2012/article/details/79799844一、libumem内存检查https://www.codenong.com/8287649/环境变量UMEM_DEBUG此变量包含逗号分隔的选项列表。忽略无法识别的选项。可能的选项包括：审计【=帧】此选项启用记录审计信息，包括线程ID、高分辨率时间戳和每次分配上最后一个操作（分配或空闲）的堆栈跟踪。如果启用了事务日志记录（请参阅UMEM_LOGGING），则也会记录此审计信息。frames参数设置审计结构中记录的堆栈帧数。帧的上限由实现定义。如果请求较大的值，则使用上界。如果不指定frames或者frames不是整数，则使用默认值15。此选项还启用“guards”选项。内容【=计数】如果启用了审计和内容记录（请参见UMEM_LOGGING），则每个缓冲区的第一个计数字节在释放时将被记录。如果缓冲区小于计数字节，则将其全部记录。如果不指定count或者count不是整数，则默认为256。违约此选项等同于audit、contents、guards。守卫此选项允许用特殊模式填充已分配和释放的缓冲区，以帮助检测未初始化数据和以前释放的缓冲区的使用。它还在每个包含0xfeedfacefeedfaceULL的缓冲区之后启用一个8字节的红区。当对象被释放时，它被填充为0xdeadbeef。分配对象时，校验0xdeadbeef模式，替换为0xbadcafe。每次分配或释放缓冲区时，都会检查红区。对于具有构造函数或析构函数或析构函数的缓存，umem_cache_alloc(3MALLOC)和umem_cache_free(3MALLOC)分别应用缓存的构造函数和析构函数。而不是缓存构造对象。析构函数中是否存在断言（ 3C ）来验证缓冲区是否处于构造状态，可以用来检测任何在错误状态下返回的对象。详情请参见umem_cache_create(3MALLOC)。冗长的库在中止之前将错误描述写入标准错误。这些消息没有本地化。UMEM_LOGGING要启用，应将此变量设置为以逗号分隔的内存日志列表。可用的日志包括：事务[=size]如果设置了审计调试选项（请参阅UMEM_DEBUG），则先前事务的审计结构将输入到此日志中。内容【=大小】如果设置了审计调试选项，则对象的内容将在释放时记录到此日志中。如果未设置“contents”调试选项，则每个释放的缓冲区将保存256字节。失败【=大小】每次失败的分配都会记录在此日志中。对于这些选项中的任何一种，如果未指定size，则使用默认值64k。size参数必须是整数，可以与K、M、G或T限定，分别指定千字节、兆字节、千兆字节或TB。未列出的日志或大小为0或无效的日志将被禁用。如果在初始化期间无法分配请求的存储量，则禁用该日志。二、glibc内存检测reference:https://www.cnblogs.com/arnoldlu/p/10827884.htmlhttps://murphypei.github.io/blog/2019/01/linux-heap  glibc内存分配Glibc中自带了一些Heap consistency checking机制。** (1)  MALLOC_CHECK_环境变量(double free)**\t检测内容：重复释放、头覆盖、尾覆盖。      MALLOC_CHECK_=3 ./test    0 - 不产生错误信息，也不中止这个程序1 - 产生错误信息，但是不中止这个程序2 - 不产生错误信息，但是中止这个程序3 - 产生错误信息，并中止这个程序        不能检测内存未释放    验证：double free场景    #include &lt;stdio.h&gt;#include &lt;stdlib.h&gt;int main(){        int *p = (int *)malloc(10);        int a;        free(p);        a = 0;        free(p);        return 0;}        结果：    [root@localhost mem_leak_way]# LIBC_FATAL_STDERR_=1 MALLOC_CHECK_=3 ./testfree(): invalid pointerAborted[root@localhost mem_leak_way]# LIBC_FATAL_STDERR_=1 MALLOC_CHECK_=4 ./testfree(): double free detected in tcache 2Aborted      (2) mcheck​\t与MALLOC_CHECK环境量功能差不多，但是需要重新编译代码。\t检测内容：重复释放、头覆盖、尾覆盖。      mcheck是Glibc中的堆内存一致性检查机制.    不能检测内存未释放    验证：    #include &lt;stdio.h&gt;#include &lt;stdlib.h&gt;#include &lt;mcheck.h&gt;  ///// 头文件int main(){        //int *p = (int *)malloc(10);        int *p1 = (int *)malloc(10);        ///////再在要开始检查的地方加上////////////        if (mcheck(NULL) != 0) {                   fprintf(stderr, \"mcheck() failed\\n\");                exit(EXIT_FAILURE);        }        int a;        //free(p);        a = 0;        //free(p);        return 0;}        结果：    double free场景：    [root@localhost mem_leak_way]# ./bug memory clobbered before allocated blockAborted      (3)mprobe检查：double free、 头覆盖、尾覆盖;与mcheck一致；#include &lt;mcheck.h&gt; //函数模型enum mcheck_status mprobe(void *ptr);#include &lt;stdio.h&gt;#include &lt;malloc.h&gt;#include &lt;mcheck.h&gt;#include &lt;errno.h&gt;#include &lt;string.h&gt;void abortfun(enum mcheck_status mstatus){    switch(mstatus) {\t\tcase MCHECK_FREE: fprintf(stderr, \"Block freed twice.\\n\"); break;\t\tcase MCHECK_HEAD: fprintf(stderr, \"Memory before the block was clobbered.\\n\"); break;\t\tcase MCHECK_TAIL: fprintf(stderr, \"Memory after the block was clobbered.\\n\"); break;\t\tdefault: fprintf(stderr, \"Block is fine.\\n\");    }}void main(void){    char *s = NULL;    if(mcheck(abortfun) != 0) //使用时，注册处理函数    {        fprintf(stderr, \"mcheck:%s\\n\", strerror(errno));        return;    }    s = malloc(32);    mprobe(s);------------------------------正确    mprobe(s-1);----------------------------错误，返回MCHECK_HEAD错误类型。    mprobe(s+32);---------------------------错误，返回MCHECK_HEAD错误类型。    free(s);}(4)-lmcheck编译选项在编译的时候加上-lmcheck，不需要修改代码就可以对malloc()/free()进行检查； 但是需要重新编译代码！！！！检查：double free、 头覆盖、尾覆盖。 与mcheck一致；(5)mtrace （mtrace、muntrace、MALLOC_TRACE)检查： 重复释放、泄漏mtrace()和muntrace()函数分别在程序中打开和关闭对内存分配调用进行跟踪的功能。这两个函数要与环境变量MALLOC_TRACE搭配使用，该变量定义了写入跟踪信息的文件名。#include &lt;stdlib.h&gt;#include &lt;stdio.h&gt;#include &lt;mcheck.h&gt; //需要的头文件int main(int argc, char **argv){        mtrace(); //开始trace        char * p = malloc(100);        p = malloc(1000);       \tfree(p);        muntrace(); //结束trace        return 0;}gcc -g test-mtrace.c -o test-mtraceexport MALLOC_TRACE=/home/test/mtrace.logmtrace记录的申请释放流程：= Start@ ./test-mtrace:[0x400684] + 0xc076a0 0x64@ ./test-mtrace:[0x400692] + 0xc07710 0x3e8@ ./test-mtrace:[0x4006a2] - 0xc07710= End配套mtrace命令可以分析具体的泄漏位置。[root@localhost test]# mtrace test-mtrace mtrace.log Memory not freed:-----------------           Address     Size     Caller0x0000000000c076a0     0x64  at /home/test/test-mtrace.c:8三、gperftools（tcmalloc）内存检查机制reference:http://goog-perftools.sourceforge.net/doc/tcmalloc.htmlhttps://blog.csdn.net/breaksoftware/article/details/81234967http://www.cppblog.com/markqian86/archive/2018/08/24/215870.aspx检查内容： 内存泄漏 heap-check增强部分： 可以找到程序的内存使用热点。 heap-porfiler[root@localhost test]# gcc test.c  -ltcmalloc -g -o test-tcmalloc[root@localhost test]# HEAPCHECK=normal ./test-tcmalloc &amp;[1] 42880[root@localhost test]# No live heap object at 0x7f8366695168 to ignoreWARNING: Perftools heap leak checker is active -- Performance may sufferHave memory regions w/o callers: might report false leaksLeak check _main_ detected leaks of 100 bytes in 2 objectsThe 2 largest leaks:*** WARNING: Cannot convert addresses to symbols in output below.*** Reason: Cannot find 'pprof' (is PPROF_PATH set correctly?)*** If you cannot fix this, try running pprof directly.Leak of 50 bytes in 1 objects allocated from:\t@ 400657 \t@ 7f83662a96a3 \t@ 40052e Leak of 50 bytes in 1 objects allocated from:\t@ 4005f8 \t@ 400660 \t@ 7f83662a96a3 \t@ 40052e If the preceding stack traces are not enough to find the leaks, try running THIS shell command:pprof ./test-tcmalloc \"/tmp/test-tcmalloc.42880._main_-end.heap\" --inuse_objects --lines --heapcheck  --edgefraction=1e-10 --nodefraction=1e-10 --gvIf you are still puzzled about why the leaks are there, try rerunning this program with HEAP_CHECK_TEST_POINTER_ALIGNMENT=1 and/or with HEAP_CHECK_MAX_POINTER_OFFSET=-1If the leak report occurs in a small fraction of runs, try running with TCMALLOC_MAX_FREE_QUEUE_SIZE of few hundred MB or with TCMALLOC_RECLAIM_MEMORY=false, it might help find leaExiting with error code (instead of crashing) because of whole-program memory leaks    TCMALLOC_DEBUG=&lt;level&gt;       调试级别，取值为1-2         MALLOCSTATS=&lt;level&gt;                    设置显示内存使用状态级别，取值为1-2         HEAPPROFILE=&lt;pre&gt;                     指定内存泄露检查的数据导出文件         HEAPCHECK=&lt;type&gt;                        堆检查类型，type=normal/strict/draconianTcMalloc库还可以进行内存泄露的检查，使用这个功能有两种方法：1）将tcmalloc库链接到程序中，注意应该将tcmalloc库最后链接到程序中；2）设置LD_PRELOAD=”libtcmalloc.so”/HEAPCHECK=normal，这样就不需重新编译程序打开检查功能，有两种方式可以开启泄露检查功能：1）  使用环境变量，对整个程序进行检查： HEAPCHECK=normal /bin/ls2）  在源代码中插入检查点，这样可以控制只检查程序的某些部分，代码如下：HeapProfileLeakCheckerchecker(\"foo\");        // 开始检查Foo();                                                                         // 需要检查的部分assert(checker.NoLeaks());                                 // 结束检查调用checker建立一个内存快照，在调用checker.NoLeaks建立另一个快照，然后进行比较，如果内存有增长或者任意变化，NoLeaks函数返回false，并输出一个信息告诉你如何使用pprof工具来分析具体的内存泄露。    执行内存检查:         #LD_PRELOAD=libtcmalloc.so HEAPCHECK=strict HEAPPROFILE=memtm ./a.out执行完成后会输出检查的结果，如果有泄露，pprof会输出泄露多少个字节，有多少次分配，也会输出详细的列表指出在什么地方分配和分配多少次。         比较两个快照：         #pprof --base=profile.0001.heap 程序名 profile.0002.heap    已知内存泄漏时，关闭内存泄露检查的代码：void *mark =HeapLeakChecker::GetDisableChecksStart();&lt;leaky code&gt;           //不做泄漏检查的部分HeapLeakChecker::DisableChecksToHereFrom(mark);         注：在某些libc中程序可能要关闭检查才能正常工作。         注：不能检查数组删除的内存泄露，比如：char *str = new char[100]; delete str;。四、jemalloc内存检查机制reference:https://zhuanlan.zhihu.com/p/48957114https://blog.intzero.net/tools/jemalloc.htmlhttps://github.com/jemalloc/jemalloc/wiki/Use-Case:-Leak-CheckingMALLOC_CONF=prof_leak:true,lg_prof_sample:0,prof_final:true \\LD_PRELOAD=${JEMALLOC_PATH}/lib/libjemalloc.so.2 w&lt;jemalloc&gt;: Leak summary: 267184 bytes, 473 objects, 20 contexts&lt;jemalloc&gt;: Run jeprof on \"jeprof.19678.0.f.heap\" for leak detailjeprof --show_bytes `which w` jeprof.19678.0.f.heap    Using local file /usr/bin/w.Using local file jeprof.19678.0.f.heap.Welcome to jeprof!  For help, type 'help'.(jeprof) topTotal: 267184 B  258032  96.6%  96.6%   258032  96.6% _3_2_5    3616   1.4%  97.9%     3616   1.4% _nl_intern_locale_data    2048   0.8%  98.7%     2208   0.8% __tzfile_read    1024   0.4%  99.1%     1024   0.4% getpwnam    1024   0.4%  99.5%     1072   0.4% getpwuid     448   0.2%  99.6%      448   0.2% __gconv_lookup_cache     384   0.1%  99.8%      384   0.1% getutent     224   0.1%  99.9%      224   0.1% strdup     160   0.1%  99.9%      160   0.1% __tzstring     128   0.0% 100.0%     3760   1.4% _nl_load_locale_from_archive      48   0.0% 100.0%       48   0.0% get_mappingjeprof --show_bytes --pdf `which w` jeprof.19678.0.f.heap &gt; w.pdf五、valgrind内存检查机制https://blog.csdn.net/CODINGCS/article/details/50357263六、ASan内存检查机制reference:https://blog.csdn.net/lyj22/article/details/109459428?utm_medium=distribute.pc_relevant_t0.none-task-blog-BlogCommendFromMachineLearnPai2-1.control&amp;depth_1-utm_source=distribute.pc_relevant_t0.none-task-blog-BlogCommendFromMachineLearnPai2-1.controlexport ASAN_OPTIONS=halt_on_error=0 //使进程检测出内存错误的时候别退出export ASAN_OPTIONS=alloc_dealloc_mismatch=0 //不检测内存不匹配的情况，例如 new [] 与delete point 不匹配asan的选项很多，可以根据需要设置ASAN_OPTIONS的选项，其他选项可以自行百度export LD_PRELOAD=/usr/lib64/libasan.so.5.0.0 //预加载运行库，替换系统库libc中内存分配函数LD_PRELOAD是Linux系统的一个环境变量，它可以影响程序的运行时的链接（Runtime linker），它允许你定义在程序运行前优先加载的动态链接库，这个环境变量是必须的，因为libasan.so.5.0.0会替换掉libc中malloc和free函数的实现，所以需要将该库进行预加载。至此，所有工作完成，直接运行所需要测试的程序即可，程序会打印出检测出来的内存问题。七、Memwatch内存检查机制reference:https://blog.csdn.net/shangguanyunlan/article/details/68951525https://blog.csdn.net/embrace_forest/article/details/52048694?utm_medium=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-2.control&amp;depth_1-utm_source=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-2.controlmemwatch根本是不需要安装的，因为它只是一组C程序代码。需要做的是：1、在代码中加入 memwatch.c 和 memwatch.h，一起编译、链接2、编译时定义宏 DMEMWATCH、DMW_STDIO，即在编译程序时加上选项-DMEMWATCH -DMW_STDIO5.1 MemWatch的内存处理memWatch将全部分配的内存用0xFE填充，所以，假设你看到错误的数据是用0xFE填充的，那就是你没有初始化数据。例外是calloc()，它会直接把分配的内存用0*填充。MemWatch将全部已释放的内存用0xFD填充(zapped with 0xFD).假设你发现你使用的数据是用0xFD填充的，那你就使用的是已释放的内存。在这样的情况，注意MemWatch会马上把一个“释放了的块信息“填在释放了的数据前。这个块包含关于内存在哪儿释放的信息，以可读的文本形式存放，格式为*“FBIfilename(line)\"*。如*:\"FBI&lt;267&gt;test.c(12)\".*使用*FBI*会减少*free()*的速度，所以默认是关闭的。使用*mwFreeBufferInfo(1)*开启。为了帮助跟踪野指针的写情况，MemWatch能提供no-mans-land（NML）内存填充。no-mans-land将使用0xFC填充.当no-mans-land开启时，MemWatch转变释放的内存为NML填充状态。5.2 初始化和结束处理一般来说，在程序中使用MemWatch的功能，须要手动加入mwInit()进行初始化，并用相应的mwTerm ()进行结束处理。当然，假设没有手动调用mwInit()，MemWatch能自己主动初始化.假设是这样的情形，memwatch会使用atext()注冊mwTerm()用于atexit-queue.对于使用自己主动初始化技术有一个告诫;假设你手动调用atexit()以进行清理工作，memwatch可能在你的程序结束前就终止。为了安全起见，请显式使用mwInit()和mwTerm().涉及的函数主要有：mwInit()  mwTerm()  mwAbort()5.3 MemWatch的I/O*操作对于一般的操作，MemWatch创建memwatch.log文件。有时，该文件不能被创建;MemWatch会试图创建memwatNN.log文件，NN在01~99之间。假设你不能使用日志，或者不想使用，也没有问题。仅仅要使用类型为“void func(int c)”的參数调用mwSetOutFunc()，然后全部的输出都会按字节定向到该函数.当ASSERT或者VERIFY失败时，MemWatch也有Abort/Retry/Ignore处理机制。默认的处理机制没有I/O操作，可是会自己主动中断程序。你能够使用不论什么其它Abort/Retry/Ignore的处理机制,仅仅要以參数“void func(int c)”调用mwSetAriFunc()。后面在1.2使用一节会具体解说。涉及的函数主要有：mwTrace()     mwPuts()    mwSetOutFunc() mwSetAriFunc()mwSetAriAction()  mwAriHandler() mwBreakOut()八、Dr.Memory内存检查机制重量级内存监测工具之一，用于检测如未初始化内存访问，越界访问，已释放内存访问，double free，memory leak以及Windows上的handle leak, GDI API usage error等。它支持Windows, Linux和Mac操作系统， IA-32和AMD64平台，和其它基于binary instrumentation的工具一样，它不需要改目标程序的binary。有个缺点是目前只针对x86上的32位程序。貌似目前正在往ARM上port。其优点是对程序的正常执行影响小，和Valgrind相比，性能更好。官网为http://www.drmemory.org/。Dr. Memory基于DynamioRIO Binary Translator。原始代码不会直接运行，而是会经过translation后生成code cache，这些code cache会调用shared instrumentation来做内存检测。下载后即可直接使用。首先编译要检测的测试程序： $ g++ -m32 -g -Wall problem.cpp -o bug -fno-inline -fno-omit-frame-pointer (在64位host上编译32位程序需要安装libc6-dev-i386和g++-multilib) 然后把Dr.Memory的bin加入PATH，如： $ export PATH=/home/jzj/tools/DrMemory-Linux-1.8.0-8/bin:$PATH 之后就可以使用Dr.Memory启动目标程序： \\$ drmemory – ./bug 九、Electric Fence内存检查机制Electric Fence主要用于追踪buffer overflow的读和写。它利用硬件来抓住越界访问的指令。其原理是为每一次内存申请额外申请一个page或一组page，然后把这些buffer范围外的page设为不可读写。这样，如果程序访问这些区域，由于页表中这个额外page的权限是不可读写，会产生段错误。那些被free()释放的内存也会被设为不可访问，因此访问也会产生段错误。因为读写权限以页为单位，所以如果多的页放在申请内存区域后，可防止overflow。如果要防止underflow，就得用环境变量EF_PROTECT_BELOW在区域前加保护页。因为Electric Fence至少需要丙个页来满足内存分配申请，因此内存使用会非常大，好处是它利用了硬件来捕获非法访问，因此速度快。也算是空间换时间吧。十、Dmalloc内存检查机制比较经典的内存检测工具，虽然N年没更新了。dmalloc通过在分配区域增加padding magic number的做法来检测非法访问，因此它能够检测到问题但不能检测出哪条指令出的错。Dmalloc只能检测越界写，但不能检测越界读。另外，Dmalloc只检测堆上用malloc系函数（而不是sbrk()或mmap()）分配的内存，而无法对栈内存和静态内存进行检测。 本质上它也是通过hook malloc(), realloc(), calloc()，free()等内存管理函数，还有strcat(), strcpy()等内存操作函数，来检测内存问题。它支持x86, ARM平台，语言上支持C/C++，并且支持多线程。十一、各种内存检测的差异"
  },
  
  {
    "title": "NEON Instruction",
    "url": "/posts/NEON-Instruction/",
    "categories": "Tools, NEON",
    "tags": "NEON",
    "date": "2021-03-21 00:00:00 +0000",
    





    
    "snippet": "1、NEON加速之memcpy在ARM平台的优化https://www.codeleading.com/article/8021520306/ NEON加速之memcpy在ARM平台的优化",
    "content": "1、NEON加速之memcpy在ARM平台的优化https://www.codeleading.com/article/8021520306/ NEON加速之memcpy在ARM平台的优化"
  },
  
  {
    "title": "libumem Introduce",
    "url": "/posts/libumem-Introduce/",
    "categories": "Package, libumem",
    "tags": "libumem",
    "date": "2021-03-21 00:00:00 +0000",
    





    
    "snippet": "一款你值得拥有的内存问题定位神器一 背景介绍​      使用C语言开发时，对于内存资源的申请和释放时非常常见的场景，但这也给广大程序带来了很多困扰，一旦出现如越界访问，重复释放，use after free，内存泄露等问题时，定位起来非常麻烦。​\t因为这个原因，现有的大部分内存管理框架或多或少的都会提供一些内存调测能力，协助定位问题。但是目前用起来不是太难使用，就是约束限制太强，使用体验太...",
    "content": "一款你值得拥有的内存问题定位神器一 背景介绍​      使用C语言开发时，对于内存资源的申请和释放时非常常见的场景，但这也给广大程序带来了很多困扰，一旦出现如越界访问，重复释放，use after free，内存泄露等问题时，定位起来非常麻烦。​\t因为这个原因，现有的大部分内存管理框架或多或少的都会提供一些内存调测能力，协助定位问题。但是目前用起来不是太难使用，就是约束限制太强，使用体验太差，因此到现在也没有出现网红款，今天我们就给大家带来一款内存调测神器：libumem。​\tlibumem类似于linux上的ptmalloc/tcmalloc等用户态内存管理框架，提供高效的内存管理功能，同时提供了非常丰富及高效的调测信息记录功能，配合mdb工具，可以轻松观察程序内存的分配情况和定位内存泄漏的问题。​\tlibumem最初在Solaris 9中提供，OmniTI  lab将此软件移植到其他流行的操作系统，如linux，我们基于OmniTI的工作成果上，将此配套调测工具(mdb)适配移植到openEuler上，可以轻松使用该工具来定位和调试我们的内存问题。二 libumem和Linux现有对比libumem和Linux现有用户态内存管理框架调测能力对比2.1 调测能力对比  libumem相比于其他用户态内存框架，支持更多的内存调测能力，更容易解决内存问题。  libumem不需要用户程序重编，提供兼容ptmalloc的接口，方便用户使用。            library      memory overrun      double free      use after free      wild free      access uninited      read invalid memory      memory leak      use after return      stack overflow                  libumem      Yes      Yes      Yes      -      Yes      -      Yes      -      -              ptmalloc(Glibc)      -      Yes      -      Yes      -      -      Yes      -      Yes(if use memcpy, strcpy, etc)              TCMalloc(Gperftools)      -      -      -      -      -      -      Yes      -      -              Jemalloc      -      -      -      -      -      -      Yes(build with –enable-prof)      -      -      2.2 调测性能对比测试对象: libumem、ptmalloc(glibc)、 tcmalloc(gperftools)、jemalloc(facebook)。各内存管理框架的调测功能使用方法:            library      version      enable memory Debugger(Common use)                  ptmalloc(Glibc)      glibc-2.28      export MALLOC_CHECK_=3;export MTRACE=/root/mtrace.log(配合进程代码修改)              tcMalloc(Gperftools)      gperftools 2.7.90      export HEAPCHECK=normal              jemalloc      Jemalloc 5.1.0      export MALLOC_CONF=prof_leak:true,lg_prof_sample:0,prof_final:true(jemalloc build with –enable-prof)              libumem      libumem-1.0      export UMEM_DEBUG=default; epxort UMEM_LOGGING=transaction      2.2.1 测试环境及测试工具  测试环境：硬件环境：X86_64 CPU 2.3GHz 16G内存虚拟机; OS版本：openEuler 20.03 LTS版本  测试工具：libMicro 工具，测试malloc的性能。2.2.2 测试结果内存管理框架调测功能全开情况，在单线程和多线程的条件下，申请内存size &lt; 10k以内，libumem申请效率最优；三 libumem及相关调测工具的使用目前libumem只支持x86_64, 后续会增加arm64支持；libumem的调测需要配合mdb工具使用，mdb目前支持libumem调测的命令如下：findleaks                - search for potential memory leaksugrep                    - search user address space for a pointerumalog                   - display umem transaction log and stack tracesumastat                  - umem allocator statsumausers                 - display current medium and large users of the umem allocatorumem_cache               - print a umem cacheumem_debug               - toggle umem dcmd/walk debuggingumem_log                 - dump umem transaction logumem_malloc_dist         - report distribution of outstanding malloc()sumem_malloc_info         - report information about malloc()s by cacheumem_status              - Print umem status and message bufferumem_verify              - check integrity of umem-managed memoryvmem                     - print a vmem_tvmem_seg                 - print or filter a vmem_segbufctl                   - print or filter a bufctlbufctl_audit             - print a bufctl_auditallocdby                 - given a thread, print its allocated buffers3.1  libumem使用(1) libumem构建代码仓: https://gitee.com/src-openeuler/libumem, 构建完成后直接rpm安装。[root@localhost ~]#  git clone git@gitee.com:src-openeuler/libumem.git[root@localhost ~]#  rpmbuild -ba -D '_sourcedir `pwd`' libumem.spec(2) libumem使用示例代码：这段代码中存在两处内存泄漏，一处内存破坏(use after free)。#include &lt;stdlib.h&gt;#include &lt;stdio.h&gt;#include &lt;unistd.h&gt;void test_leak_malloc(void){        char *p = malloc(50); //not free        p = malloc(100);        free(p);}void test_UAF(void){        char *p = malloc(50);         free(p);        *p = 1; // use after freed}void main(void){        char *p = malloc(50); //not free        test_leak_malloc();        test_UAF();        pause();        return;}[root@localhost ~]# gcc -g test.c -o testlibumem通过LD_PRELOAD环境变量使用方法：[root@localhost ~]# UMEM_DEBUG=default, UMEM_LOGGING=transaction LD_PRELOAD=/usr/local/lib/libumem.so.0 ./test&amp;//安装libumem-devel后,man umem_debug查看UMEM_DEBUG、UMEM_LOGGING的含义。3.2 调测功能使用(1) mdb工具构建代码仓: https://github.com/openEuler-Computing/mdb[root@localhost ~]# git clone https://github.com/openEuler-Computing/mdb.git[root@localhost ~]# yum install byacc flex libbsd-devel elfutils-libelf-devel zlib-devel libumem-devel [root@localhost ~]# cd mdb/common; make all -j 4; make install(2) 定位内存泄漏[root@localhost ~]# mdb -p `pidof test` //使用mdb attach到test进程(mdb -p pid)loading modules: [ libdl-2.28.so libpthread-2.28.so libc-2.28.so libumem.so.0.0.0 ld-2.28.so ]::findleaks -d    CACHE             LEAKED           BUFCTL CALLER00007f3db1bba048       1 00007f3db1b3e7e0 main+0x1200007f3db1bba048       1 00007f3db1b3e8c0 test_leak_malloc+0x12------------------------------------------------------------------------           Total       2 buffers, 160 bytesumem_alloc_80 leak: 1 buffer, 80 bytes            ADDR          BUFADDR        TIMESTAMP           THREAD                            CACHE          LASTLOG         CONTENTS    7f3db1b3e7e0     7f3db1b6bf60 60116209000b4637      -1312650368                     7f3db1bba048     7f3db1bf8300                0                 libumem.so.0.0.0`umem_alloc+0x98                 libumem.so.0.0.0`malloc+0x39                 main+0x12 //memory leak here                 libc-2.28.so`__libc_start_main+0xf3                 _start+0x2eumem_alloc_80 leak: 1 buffer, 80 bytes            ADDR          BUFADDR        TIMESTAMP           THREAD                            CACHE          LASTLOG         CONTENTS    7f3db1b3e8c0     7f3db1b6bef0 60116209000b463c      -1312650368                     7f3db1bba048     7f3db1bf83c0                0                 libumem.so.0.0.0`umem_alloc+0x98                 libumem.so.0.0.0`malloc+0x39                 test_leak_malloc+0x12 //memory leak here                 main+0x1b                 libc-2.28.so`__libc_start_main+0xf3                 _start+0x2e(3)定位内存破环常见的内存破坏: use after free, double free, memory overrun, out-of-bounds array write.::umem_verifyCache Name                      Addr             Cache Integrity     ...umem_alloc_80                       7f3db1bba048 1 corrupt bufferumem_alloc_96                       7f3db1bb9048 clean...7f3db1bba048::umem_verifySummary for cache 'umem_alloc_80'  buffer 7f3db1b6be80 (free) seems corrupted, at 7f3db1b6be90 //memory corrupted appear in freed address 7f3db1b6be80通过umalog命令可以查看到申请的调用栈：T-0.000000005  addr=7f3db1b6be80  umem_alloc_80 //test_UAF malloc(50) addr=7f3db1b6be80          libumem.so.0.0.0`umem_alloc+0x98         libumem.so.0.0.0`malloc+0x39         test_UAF+0x12         main+0x20         libc-2.28.so`__libc_start_main+0xf3         _start+0x2e综合信息可以知道test_UAF中出现use after free的情况；通过以上评测结果和demo应用，相信你 已经的libumem以及mdb工具有了初步的了解，期望你来做更多的尝试…四  更多内容关注OpenEuler如果内存调测工具对你有用，太好了！ 请传播它，让更多人使用，调试和增强它。libumem地址：https://gitee.com/src-openeuler/libumem配套调测工具的地址： https://github.com/openEuler-Computing/mdb"
  },
  
  {
    "title": "Linux Heterogeneous memory management (HMM)",
    "url": "/posts/kernel-hmm/",
    "categories": "linux, HMM",
    "tags": "HMM",
    "date": "2021-03-04 04:10:00 +0000",
    





    
    "snippet": "一、HMM是什么？Reference：异构内存管理 Heterogeneous Memory Management (HMM)翻译于：https://elixir.bootlin.com/linux/v5.5-rc2/source/Documentation/vm/hmm.rst提供基础设施和帮助程序以将非常规内存（设备内存，如板上 GPU 内存）集成到常规内核路径中，其基石是此类内存的专用...",
    "content": "一、HMM是什么？Reference：异构内存管理 Heterogeneous Memory Management (HMM)翻译于：https://elixir.bootlin.com/linux/v5.5-rc2/source/Documentation/vm/hmm.rst提供基础设施和帮助程序以将非常规内存（设备内存，如板上 GPU 内存）集成到常规内核路径中，其基石是此类内存的专用结构页面（请参阅本文档的第 5 至 7 节）。HMM 还为 SVM（共享虚拟内存）提供了可选的帮助程序，即允许设备透明地访问与 CPU 一致的程序地址，这意味着 CPU 上的任何有效指针也是该设备的有效指针。这对于简化高级异构计算的使用变得必不可少，其中 GPU、DSP 或 FPGA 用于代表进程执行各种计算。本文档分为以下部分：在第一部分中，我揭示了与使用特定于设备的内存分配器相关的问题。在第二部分中，我揭示了许多平台固有的硬件限制。第三部分概述了 HMM 设计。第四部分解释了 CPU 页表镜像的工作原理以及 HMM 在这种情况下的目的。第五部分处理内核中如何表示设备内存。最后，最后一节介绍了一个新的迁移助手，它允许利用设备 DMA 引擎。1 特定设备内存分配器使用特定于设备的内存分配器的问题设备有大量的板载内存，历来都是专有驱动的API管理，使得驱动程序的内存使用与常规应用内存使用断开，存在分裂。1、大型程序需要依赖大量的库，使得程序维护复杂2、复杂数据，例如：复杂数据集（列表、树……），在驱动与应用之间copy的话，由于重复的数据集和地址，这很容易出错并且程序更难调试。3、由于各种内存副本，大型项目会受到这种影响并浪费资源。复制每个库 API 以接受由每个设备特定分配器分配的输入或输出内存不是一个可行的选择。这将导致库入口点的组合爆炸。随着高级语言结构（在 C++ 中，但在其他语言中）的进步，编译器现在可以在没有程序员知识的情况下利用 GPU 和其他设备。某些编译器识别的模式仅适用于共享地址空间。对所有其他模式使用共享地址空间也更合理。2 IO总线与设备内存特性I/O 总线、设备内存特性io总线的访问存在缓存一致性问题，以及访问带宽问题。虽然已经有新的协议加入PCIE中，希望来解决前面问题。但并不是所有都支持。为了使共享地址空间有意义，我们不仅必须允许设备访问任何内存，而且还必须允许任何内存在设备使用时迁移到设备内存（在发生时阻止 CPU 访问）。3 共享地址空间及迁移共享地址空间和迁移Hmm提供两个功能：1、统一虚拟地址空间：通过复制设备页表中的 CPU 页表来共享地址空间，因此对于进程地址空间中的任何有效主内存地址，相同的地址指向相同的物理内存；2、ZONE_DEVICE 内存：它允许为设备内存的每个页面分配一个结构页面，管理设备内存。4 地址空间镜像实现地址空间镜像实现和API1、页表同步：mmu_interval_notifier_insert2、设备驱动程序想要填充一个虚拟地址范围：hmm_range_fault例子： int driver_populate_range(...) {      struct hmm_range range;      ...      range.notifier = &amp;interval_sub;      range.start = ...;      range.end = ...;      range.hmm_pfns = ...;      if (!mmget_not_zero(interval_sub-&gt;notifier.mm))          return -EFAULT; again:      range.notifier_seq = mmu_interval_read_begin(&amp;interval_sub);      mmap_read_lock(mm);      ret = hmm_range_fault(&amp;range);      if (ret) {          mmap_read_unlock(mm);          if (ret == -EBUSY)                 goto again;          return ret;      }      mmap_read_unlock(mm);      take_lock(driver-&gt;update);      if (mmu_interval_read_retry(&amp;ni, range.notifier_seq) {          release_lock(driver-&gt;update);          goto again;      }      /* Use pfns array content to update device page table,       * under the update lock */      release_lock(driver-&gt;update);      return 0; }5 内存迁移移入和移出设备内存由于 CPU 无法直接访问设备内存，因此设备驱动程序必须使用硬件 DMA 或设备特定的加载/存储指令来迁移数据。migrate_vma_setup()、migrate_vma_pages() 和 migrate_vma_finalize() 函数旨在使驱动程序更易于编写并集中跨驱动程序的通用代码。6 内存记账内存 cgroup (memcg) 和 rss 记帐目前，设备内存被视为 rss 计数器中的任何常规页面（如果设备页面用于匿名，则为匿名，如果设备页面用于文件支持页面，则为文件，如果设备页面用于共享内存，则为 shmem）。这是为了保持现有应用程序的故意选择，这些应用程序可能在不知情的情况下开始使用设备内存，运行不受影响。一个缺点是 OOM 杀手可能会杀死使用大量设备内存而不是大量常规系统内存的应用程序，因此不会释放太多系统内存。在决定以不同方式计算设备内存之前，我们希望收集更多关于应用程序和系统在存在设备内存的情况下在内存压力下如何反应的真实世界经验。对内存 cgroup 做出了相同的决定。设备内存页面根据相同的内存 cgroup 计算，常规页面将被计算在内。这确实简化了进出设备内存的迁移。这也意味着从设备内存迁移回常规内存不会失败，因为它会超过内存 cgroup 限制。一旦我们对设备内存的使用方式及其对内存资源控制的影响有了更多的了解，我们可能会在后面重新考虑这个选择。二、深入https://www.kernel.org/doc/html/latest/vm/hmm.htmlhttps://www.jianshu.com/p/7e2f9b8d59caHMM的讨论从社团的一个问题开始：像GPU这样的设备需要哪些功能以便能够支持HMM？ 答案是，它需要某种页表结构，可用于设置每页内存的访问权限。 例如，这取决于在相关页面中找到哪种类型的代码，设置权限使得其可以执行在CPU或GPU上（但不是在两者上）。 HMM还需要能够防止两个处理器的同时写入，因此GPU需要能够处理故障（handle faults）。1 硬件功能(1)像GPU这样的设备需要哪些功能以便能够支持HMM？一致的设备内存节点CDM coherent device memory nodes？http://www.voidcn.com/article/p-gtgnskkx-bad.html异构内存管理（HMM）让设备的驱动程序可以为受制于自身内存管理的进程来镜像地址空间。正如Red Hat的开发人员杰尔姆·格利瑟（Jérôme Glisse）解释（https://lkml.org/lkml/2017/4/21/872），这项功能让GPU之类的硬件设备更容易直接访问进程的内存，没有复制任何内容所带来的额外开销。它也并不侵犯现代操作系统所提供的内存保护功能。势必会从HMM获得最大好处的一类应用就是基于GPU的机器学习。诸如OpenCL和CUDA之类的机器学习库的速度到时有望得到HMM的提升。HMM做到这点的方式与针对基于GPU的机器学习进行的提速几乎一模一样，也就是说让数据留在原地、靠近GPU，在那里直接处理数据，然后传输尽可能少的数据。让HMM适用于Linux中面临几个障碍。首先是内核支持，而在相当长的时间里，内核对HMM的支持一直情况不明朗。早在2014年，HMM最初是作为Linux内核补丁集（patchset）提出来的，Red Hat和英伟达都是关键开发商。涉及的工作量并不小，但是开发人员认为，可以提交代码，说不定可以加入到未来发布的几个内核版本。第二个障碍是视频驱动程序支持，英伟达一致在单独搞这项工作。据格利瑟声称，AMD GPU可能也会支持HMM，所以这种特别的优化不会仅限于英伟达GPU。AMD一直在提升其在GPU市场的实力，因此可能会在同一块晶片上整合GPU处理和CPU处理（http://www.infoworld.com/article/3099204/hardware/amd-mulls-a-cpugpu-super-chip-in-a-server-reboot.html）。然而，软件生态系统仍然明显青睐英伟达；将来需要另外几个像HMM这样与厂商中立的项目，以及与CUDA所提供的性能不相上下的OpenCL性能，才可能获得切实的选择。第三个障碍是硬件支持，因为HMM需要有一种可再现的页面故障（replayable page faults）硬件功能才能发挥作用。目前只有英伟达的Pascal高端GPU系列支持这项功能。从某种意义上来说，这是好消息，因为它意味着英伟达只需要为某一个硬件提供驱动程序支持――它需要完成的工作量较小，就可以让HMM正常使用起来。一旦HMM实施到位，使用GPU实例的公共云提供商将面临压力：需要支持最新最好一代的GPU。不是仅仅把老式的英伟达Kepler显卡换成最先进的Pascal GPU就完事。由于后续的每一代GPU会显得更脱颖而出，像HMM这样的支持优化将带来战略优势。2 replayable page faults(2)硬件支持：replayable page faults硬件功能是什么？https://on-demand.gputechconf.com/gtc/2017/presentation/s7764_john-hubbardgpus-using-hmm-blur-the-lines-between-cpu-and-gpu.pdf3 How HMM works?https://nvidia.github.io/open-gpu-doc/manuals/turing/tu104/dev_mmu_fault.ref.txt2  -  GPU FAULT BUFFER======================================This chapter describes the format of the GPU replayable andnon-replayable fault reporting buffer used to report page faults.    This fault buffer is written to by GMMU based on buffer location infoset in GMMU registers (NV_PFB_PRI_MMU_REPLAY_FAULT_BUFFER_LO/HI andNV_PFB_PRI_MMU_NON_REPLAY_FAULT_BUFFER_LO/HI). The replayable faultbuffer is managed by the UVM driver. The non-replayable fault bufferis managed by RM.    The buffer can overflow. There is status maintained in GMMU registerfor that. If the buffer has overflowed the GPU will stop writing out new faultentries and proceed to drop entries until SW resets the overflowstatus (normally after processing the existing fault packets and soGET PTR is changed). This is done to prevent the GPU from overwritingunprocessed entries.  When faults are dropped they are not lost forreplayable faults as the requets are buffered in MMU replay buffer;however, non-replayable faults are lost as those requests are notbuffered for further processing; when SW triggers a replay event therequests for the dropped replayable faults will be replayed, faultagain, and then be reported in the fault buffer.缓冲区可能溢出。GMMU寄存器中保存了这种状态。如果缓冲区溢出，GPU将停止写入新的故障条目，并继续丢弃条目，直到SW重置溢出状态（通常在处理现有的故障数据包之后，因此GET PTR被更改）。这样做是为了防止GPU覆盖未处理的条目。当故障丢弃时，它们不会因为可重放的错误而丢失，因为请求被缓存在MMU重放缓冲区中；但是，由于这些请求没有缓存以便进一步处理，非重放的错误会丢失；当SW触发重放事件时，对丢弃的可重放故障的请求将被重放，再次发生故障，然后在故障缓冲区中报告。replayable page faultshttps://smartech.gatech.edu/bitstream/handle/1853/62741/KIM-DISSERTATION-2020.pdfhttps://www.redhat.com/files/summit/session-assets/2017/S104078-hubbard.pdf三 疑问(1)driver如何收到GPU运行的pagefault? 为什么gpu会产生page faults?  GPU有单独的MMU？GPU page fault:https://winddoing.github.io/post/793.htmlGPU 页错误A GPU page fault commonly occurs under one of these conditions. An application mistakenly executes work on the GPU that references a deleted object. This is one of the top reasons for an unexpected device removal. An application mistakenly executes work on the GPU that accesses an evicted resource, or a non-resident tile.GPU 页面错误通常在下列情况之一下发生：1) 应用程序在 GPU 上错误地执行了应用已删除的对象的作业。 这是意外删除设备的主要原因之一。2) 应用程序错误地在 GPU 上执行了访问已逐出的资源或非驻留磁贴的作业。3) 着色器引用未初始化的或过时的描述符。4) 着色器索引超出根绑定末尾。```chttps://www.zhihu.com/question/381126048链接：https://www.zhihu.com/question/381126048/answer/1093535046现在的CPU，是通过将需要GPU执行的命令写入内存（主存），然后通知GPU命令开始的地址与长度，来与GPU协作的。GPU可见的内存一般分为两部分：和CPU共享的（一般为主存的一部分），以及独占的（一般为显存）。GPU执行的程序以及相关参数（如顶点坐标），一般放在共享的内存里面，因为这些是需要CPU不断更新的。GPU绘图所需资源（如贴图），由CPU从外存（如硬盘）读入之后，先临时放在共享内存上，然后通知GPU将其转移到GPU专有内存（显存）当中。现代GPU在绘图命令之外，一般还至少有一个专门的用来转移数据的命令队列，可以和绘图命令队列并行执行。GPU的执行结果（绘制的画面）一般直接写入显存当中的特定区域（屏幕缓冲区），然后由专门的ScanOut电路（包括在GPU当中或者显卡上）对其完成最终的数字信号处理之后（如色空间转换，Gamma调整等）输出给显示设备。因此，如果CPU想要读取GPU计算的结果，需要通知GPU将结果传输回共享内存区域，这通常有较大的性能开销。http://www.irisa.fr/alf/downloads/ADA/Tanasic_ExceptionGPUs_Micro17.pdfEcient Exception Handling Support for GPUsGPU有独立的MMU。(2)CPU如何识别是设备内存的page fault？中断通知driver， 处理faults.四、总结支持HMM的要求（1）设备支持handles faults能力，支持类似MMU页表能力​\t 通过CPU和device的页表设置来保证设备和CPU只有一个在访问虚拟地址（2）设备支持replay faults的；​\t\t驱动一般通过中断通知driver处理faults, driver需要存储replayed fault(page faults)，driver处理完fault后需要replay触发faults的语句。五、HMM VS DSM1 HMM（1）设备支持handles faults能力，支持类似MMU页表能力（2）设备支持replay faults的2 DSM(1) 由于线程共享相同的虚拟地址空间，因此所有线程必须具有相同的内存视图。3 HMM   VS   DSM                   前置条件      优势                  HMM      (1) 支持handles faults，支持类似MMU页表能力，可以设置not present含义(2) 支持handles faults之后replay fault的方法。                     DSM      (1) 所有va都是相同的内存视图Main memory需要预留和device memory完全镜像的内存。要支持相同的地址翻译硬件设备。(2) page coherency机制需要消息通知或者监控手段。      1、数据没有发生写，不需要同步，可以直接访问。      "
  },
  
  {
    "title": "Kernel Samepage Merging (KSM)",
    "url": "/posts/linux-ksm/",
    "categories": "linux, KSM",
    "tags": "KSM",
    "date": "2021-03-03 00:00:00 +0000",
    





    
    "snippet": "一、KSM机制https://zhuanlan.zhihu.com/p/102469328详细的代码流程图https://www.kernelnote.com/entry/linux-ksm-merge详细的代码分析​\t内核采用虚拟内存管理技术为每个进程分配独立的虚拟内存地址空间。而物理内存的分配是由进程去访问虚拟地址时产生缺页异常 (Page Fault) 来触发。一个进程的虚拟地址空间在...",
    "content": "一、KSM机制https://zhuanlan.zhihu.com/p/102469328详细的代码流程图https://www.kernelnote.com/entry/linux-ksm-merge详细的代码分析​\t内核采用虚拟内存管理技术为每个进程分配独立的虚拟内存地址空间。而物理内存的分配是由进程去访问虚拟地址时产生缺页异常 (Page Fault) 来触发。一个进程的虚拟地址空间在内核中用内存描述符struct mm_struct进行表示，而进程的虚拟地址空间又被划分为多个虚拟内存区域struct vm_area_struct，简称vma。另外，进程描述符由struct task_struct中的mm域记录。KSM后常驻一个名叫ksmd非实时线程。它会执行 ksm.c 源码里的ksm_do_scan接口定时扫描被标记为MMF_VM_MERGEABLE的mm_struct[内存描述符]，调用cmp_and_merge_page识别并合并内容完全一样的物理页，扫描的间隔和每次扫描的页数分别由/sys/kernel/mm/ksm/pages_to_scan、/sys/kernel/mm/ksm/sleep_millisecs控制。用户层可以通过系统调用madvise(addr,length,MADV_MERGEABLE)对一块页对齐的内存标记为可用于 KSM 合并。此外由于madvise系统调用会通过内核源码 madvise.c 里的madvise_behavior接口对内存区域 vma 中的内存进行标记，如果该区间和周围的内存区间标记不同，那么会分配新的vma，而内核对进程持有的vma是有限制的，分配的 vma 数目必须小于/proc/sys/vm/max_map_count里的限制，一旦超出，那么会引发OOM Killer导致进程crash。如果调大max_map_count产生过多的vma会导致系统的性能下降，我们应该根据自身业务的规模进行合理调整，同时有必要加上监控预警。https://maggie262.github.io/2020/11/20/ksm/KSM数据结构关系图：https://www.cnblogs.com/arnoldlu/p/8335541.htmlksm_do_scan    scan_get_next_rmap_item---------------------选取合适的匿名页面    cmp_and_merge_page--------------------------将页面与root_stable_tree/root_unstable_tree中页面进行比较，判断是否能合并        stable_tree_search----------------------搜索stable红黑树并查找是否有和page内容一致的节点        try_to_merge_with_ksm_page--------------尝试将候选页合并到KSM页面中        stable_tree_append        unstable_tree_search_insert-------------搜索unstable红黑树中是否有和该页内容相同的节点        try_to_merge_two_pages------------------若在unstable红黑树中找到和当前页内容相同节点，尝试合并这两页面成为一个KSM页面        stable_tree_append----------------------将合并的两个页面对应rmap_item添加到stable节点哈希表中        break_cow    KSM页面和匿名页面的区别分两种情况，匿名页是父子进程VMA共享同一个匿名页面；ksm是不相干的进程VMA共享同一个匿名页面。二、反向映射https://os.51cto.com/art/202011/632380.htm目的：为了找到一个物理页面对应的页表项.用途：内存回收，内存碎片整理，CMA, 巨型页，页迁移等各个场景中都能发现反向映射所做的关键性的工作。1 反向映射发展2.反向映射分类据结构1、fork流程中会存在反向映射的建立，可以熟悉建立流程SYSCALL_DEFINE0(fork)kernel_clonecopy_processcopy_mmdump_mmdup_mmap\t-&gt;|anon_vma_fork 匿名映射反向映射创建\t-&gt;|vma_interval_tree_insert_after\t文件映射反向映射创建2、内存回收或者页表迁移，会通过反向映射查找对应的pte，可以熟悉查找流程.    try_to_unmap    -&gt;|rmap_walk    \t-&gt;|rmap_walk_ksm if PageKsm(page)  ksm页    \t-&gt;|rmap_walk_anon if PageAnon(page) 匿名页    \t-&gt;|rmap_walk_file page cache页(1)匿名反向映射​\t匿名页的共享主要发生在父进程fork子进程的时候，父fork子进程时，会复制所有vma给子进程，并通过调用dup_mmap-&gt;anon_vma_fork建立子进程的rmap以及和长辈进程rmap关系结构：主要通过anon_vma这个数据结构体中的红黑树将共享父进程的页的所有子进程的vma联系起来(通过anon_vma_chain 来联系对应的vma和av)，当然这个关系建立比较复杂，涉及到vma,avc和av这些数据结构体。而在缺页异常do_anonymous_page的时候将page和vma相关联try_to_unmap //mm/rmap.c -&gt;rmap_walk   -&gt;rmap_walk_anon      -&gt;anon_vma_interval_tree_foreach(avc, &amp;anon_vma-&gt;rb_root,pgoff_start, pgoff_end)          -&gt;rwc-&gt;rmap_one             -&gt;try_to_unmap_one 对于候选页，会拿到候选页相关联的anon_vma，然后从anon_vma的红黑树中遍历到所有共享这个页的vma，然后对于每一个vma通过try_to_unmap_one来处理相对应的页表项，将映射关系解除。(2)文件反向映射​\t文件页的共享主要发生在多个进程共享libc库，同一个库文件可以只需要读取到page cache一次，然后通过各个进程的页表映射到各个进程的vma中。管理共享文件页的所以vma是通过address_space的区间树来管理，在mmap或者fork的时候将vma加入到这颗区间树中：发生文件映射缺页异常的时候，将page和address_space相关联。try_to_unmap //mm/rmap.c -&gt;rmap_walk   -&gt;rmap_walk_file     -&gt;vma_interval_tree_foreach(vma, &amp;mapping&gt;i_mmap,pgoff_start, pgoff_end)           -&gt;rwc-&gt;rmap_one对于每一个候选的文件页，如果是映射页，就会遍历page所对应的address_space的区间树，对于每一个满足条件的vma，调用try_to_unmap_one来找到pte并解除映射关系。(3)KSM反向映射​\t\t遍历ksm机制中两课红黑树，一棵是stable tree,一棵是unstable tree， 然后通过匿名映射的反向映射查找对应的vma。try_to_unmap //mm/rmap.c -&gt;rmap_walk    -&gt;rmap_walk_ksm  //mm/ksm.c         -&gt; hlist_for_each_entry(rmap_item, &amp;stable_node-&gt;hlist, hlist)     -&gt;anon_vma_interval_tree_foreach(vmac, &amp;anon_vma-&gt;rb_root,0, ULONG_MAX)        -&gt;rwc-&gt;rmap_one 3.总结匿名页，文件页和ksm页的反向映射,分别通过page所对应的的vma, address_space, stable_node结构来查找vma三、额外知识：https://blog.csdn.net/Z_Stand/article/details/102222612 文件IO与内存映射：page cache页高速缓存i page cache level0视图ii. page cache作用​\t提高文件系统性能，内核利用一部分物理内存分配出缓冲区，用于缓存系统操作和数据文件，当内核收到读写的请求时，内核先去缓存区找是否有请求的数据，有就直接返回，如果没有则通过驱动程序直接操作磁盘。​\t缓存机制优点：减少系统调用次数，降低CPU上下文切换和磁盘访问频率。iii. 文件读写读文件流程如下数据结构关联:inode -&gt; i_mapping 指向address_space对象,address_space-&gt;host指向inode数据结构关联:page-&gt;mapping 指向页缓存owner的address_space系统调用传参:文件描述符+文件偏移地址操作系统找到文件address_space，根据偏移量到页缓存中查找page若查找到，返回数据到用户空间否则，内核新建一个page并加入到页缓存，数据从磁盘载入该项调用readpage方法将数据返回给用户空间    写文件流程如下：数据结构关联:inode -&gt; i_mapping 指向address_space对象,address_space-&gt;host指向inode数据结构关联:page-&gt;mapping 指向页缓存owner的address_space系统调用传参:文件描述符+文件偏移地址操作系统找到文件address_space，根据偏移量到页缓存中查找page若查找到，将数据写入到该缓存中，该页成为脏页若没有查找到，向缓存的计数树管理的页面中添加一个新的页面，并将用户空间的数据写入到该页面当数据满足页缓存的时间或空间原理时，使用pdflush后台回写例程来将脏页数据会写到磁盘https://xgwang0.github.io/2018/12/24/Linux-FileSystem_File-Read_Write-Process/https://blog.csdn.net/Frecon/article/details/80153535?ops_request_misc=%257B%2522request%255Fid%2522%253A%2522169106404316800182147077%2522%252C%2522scm%2522%253A%252220140713.130102334.pc%255Fblog.%2522%257D&amp;request_id=169106404316800182147077&amp;biz_id=0&amp;utm_medium=distribute.pc_search_result.none-task-blog-2~blog~first_rank_ecpm_v1~rank_v31_ecpm-1-80153535-null-null.268^v1^koosearch&amp;utm_term=%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F&amp;spm=1018.2226.3001.4450文件读写iv. page cache控制​\tsysctl 参数： dirty_ratio和dirty_background_ratiov. 文件读写 与 文件映射https://www.cnblogs.com/charlesblc/p/6263665.html而使用mmap操作文件中，创建新的虚拟内存区域和建立文件磁盘地址和虚拟内存区域映射这两步，没有任何文件拷贝操作。而之后访问数据时发现内存中并无数据而发起的缺页异常过程，可以通过已经建立好的映射关系，只使用一次数据拷贝，就从磁盘中将数据传入内存的用户空间中，供进程使用。总而言之，常规文件操作需要从磁盘到页缓存再到用户主存的两次数据拷贝。而mmap操控文件，只需要从磁盘到用户主存的一次数据拷贝过程。说白了，mmap的关键点是实现了用户空间和内核空间的数据直接交互而省去了空间不同**数据不通的繁琐过程。因此mmap效率更高。mmap优点总结由上文讨论可知，mmap优点共有一下几点：1、对文件的读取操作跨过了页缓存，减少了数据的拷贝次数，用内存读写取代I/O读写，提高了文件读取效率。2、实现了用户空间和内核空间的高效交互方式。两空间的各自修改操作可以直接反映在映射的区域内，从而被对方空间及时捕捉。3、提供进程间共享内存及相互通信的方式。不管是父子进程还是无亲缘关系的进程，都可以将自身用户空间映射到同一个文件或匿名映射到同一片区域。从而通过各自对映射区域的改动，达到进程间通信和进程间共享的目的。     同时，如果进程A和进程B都映射了区域C，当A第一次读取C时通过缺页从磁盘复制文件页到内存中；但当B     再读C的相同页面时，虽然也会产生缺页异常，但是不再需要从磁盘中复制文件过来，而可直接使用已经保     存在内存中的文件数据。4、可用于实现高效的大规模数据传输。内存空间不足，是制约大数据操作的一个方面，解决方案往往是借助硬盘空间协助操作，补充内存的不足。但是进一步会造成大量的文件I/O操作，极大影响效率。这个问题可以通过mmap映射很好的解决。换句话说，但凡是需要用磁盘空间代替内存的时候，mmap都可以发挥其功效。"
  },
  
  {
    "title": "Peripherals Bus Delivery",
    "url": "/posts/Peripherals-Bus-Delivery/",
    "categories": "linux, Bus",
    "tags": "Bus",
    "date": "2021-03-03 00:00:00 +0000",
    





    
    "snippet": "一、HCCSCache一致性总线HCCS，可以实现CPU和CPU之间的高速互联，通信速率高达每秒30GT，是业界主流CPU互联速率的2倍多。通过多CPU互联，我们率先实现256个物理核的NUMA架构，从而推出业界首款兼容ARM架构的最强算力4路服务器。异构计算的兴起，使得CPU与NPU之间的互联协议也很关键。华为创新性的将HCCS同样应用于CPU与NPU的高速互联，构建了xPU间的统一Cac...",
    "content": "一、HCCSCache一致性总线HCCS，可以实现CPU和CPU之间的高速互联，通信速率高达每秒30GT，是业界主流CPU互联速率的2倍多。通过多CPU互联，我们率先实现256个物理核的NUMA架构，从而推出业界首款兼容ARM架构的最强算力4路服务器。异构计算的兴起，使得CPU与NPU之间的互联协议也很关键。华为创新性的将HCCS同样应用于CPU与NPU的高速互联，构建了xPU间的统一Cache一致性架构，xPU之间可以进行直接内存访问，实现高速数据交互。同时基于此架构，可实现通用算力和AI算力的灵活组合，打造最强算力的异构计算服务器。二、HBM  HIGH Bandwidth memoryhttps://china.xilinx.com/support/documentation/white_papers/c_wp485-hbm.pdf硅与硅的堆叠结构允许通过非常小、分布非常密集的微凸块来连接相邻的硅器件三、CXLhttps://zhuanlan.zhihu.com/p/65435956https://www.techdesignforums.com/practice/technique/compute-express-link-cxl-protocols/The CXL standard defines three protocols that are dynamically multiplexed together before being transported via a standard PCIe 5.0 PHY at 32GT/s.The CXL.io protocol is an enhanced version of a PCIe 5.0 protocol that can be used for initialization, link-up, device discovery and enumeration, and register access. It provides a non-coherent load/store interface for I/O devices.The CXL.cache protocol defines interactions between a host and a device, allowing attached CXL devices to efficiently cache host memory with extremely low latency using a request and  response approach.The CXL.mem protocol provides a host processor with access to the memory of an attached device using load and store commands, with the host CPU acting as a master and the CXL device acting as a subordinate. This approach can support both volatile and persistent memory architectures.https://www.synopsys.com/designware-ip/technical-bulletin/compute-express-link-standard-2019q3.html"
  },
  
  {
    "title": "user space slab memory allocator - libumem",
    "url": "/posts/sunos-libumem/",
    "categories": "Package, libumem",
    "tags": "libumem",
    "date": "2021-02-03 00:00:00 +0000",
    





    
    "snippet": "对应github：https://github.com/luochenglcs/libumemreference:https://arrowpig1979.wordpress.com/2008/08/16/%e4%bd%bf%e7%94%a8libumem%e5%ae%9a%e4%bd%8dmemory-leak%e5%92%8cmemory-corruption%ef%bc%884%ef%...",
    "content": "对应github：https://github.com/luochenglcs/libumemreference:https://arrowpig1979.wordpress.com/2008/08/16/%e4%bd%bf%e7%94%a8libumem%e5%ae%9a%e4%bd%8dmemory-leak%e5%92%8cmemory-corruption%ef%bc%884%ef%bc%89/https://www.codenong.com/8287649/一、libumem介绍libumem是一个运行在用户模式的内存分配程序库，包含在Solaris 9及以后的版本中。libumem不仅能够优化程序的内存分配，而且还提供了内存分配调试和记录的功能，配合mdb工具，可以轻松观察程序内存的分配情况和定位内存泄漏的问题。libumem使用Slab概念。Slab是Slab Allocator中一个基本内存单元，代表一个或者多个虚拟内存中的页（Page），通常会被分割成为多个大小等同的Chunks，即Buffer。Buffer含有用户所使用的数据，以及一些额外的信息（取决于环境变量的设置）。这些额外的信息对我们调试，检测内存泄漏非常有用。下面就是 Buffer 的一个基本结构：Metadata Section，提供内存分配的长度信息，在32位程序应用中为8个字节。User Data Section，用户使用的内存区域，存储用户数据。Redzone Section，8个字节，隔离User Data和Debug Meta Data。Debug Metadata，8个字节。前面四个字节为指针，指向一个umem_bufctl_audit结构，记录内存分配时候的堆栈。此结构的定义可以在/usr/include/umem_impl.h找到。后面的四个字节为校验位，与前面字节一起来判断这个buffer是否被破坏。https://hosam.wordpress.com/opensolaris-open-source-from-sun-microsystems-inc/二、libumem的维测特性1 linux目前的内存调测手段1.glibc内存检测2.valgrind内存检查机制3、gperftools内存检查机制4、ASan内存检查机制5、Memwatch内存检查机制6、Dr.Memory内存检查机制9、Electric Fence内存检查机制8、Dmalloc内存检查机制2 libumem的内存调测需要和mdb工具配合，我们先看下面的例子：#include &lt;stdlib.h&gt;#include &lt;stdio.h&gt;#include &lt;unistd.h&gt;void test_leak_malloc(void){        char *p = malloc(50);        p = malloc(100);        free(p);}void test_UAF(void){        char *p = malloc(50);        free(p);        *p = 1;}void main(void){        char *p = malloc(50);        test_leak_malloc();        test_UAF();        pause();        return;}gcc -g test.c -o testUMEM_DEBUG=default, UMEM_LOGGING=transaction LD_PRELOAD=/usr/local/lib/libumem.so.0 ./test&amp;//使用 man umem_debug查看UMEM_DEBUG、UMEM_LOGGING的含义。[root@localhost ~]# mdb -p `pidof test` //使用mdb attach到test进程loading modules: [ libgcc_s-8-20191121.so.1 libdl-2.28.so libpthread-2.28.so libc-2.28.so libumem.so.0.0.0 ld-2.28.so ]::findleaks -dBYTES             LEAKED         VMEM_SEG CALLER16384                  6     7f3daf3af000 MMAP4096                   1     7f3db1c40000 MMAP8192                   1     7f3db1c3c000 MMAP8192                   1     7f3db1c28000 MMAP33595392               1     7f3dafa0c000 MMAP16384                  1     7f3daf771000 MMAP------------------------------------------------------------------------           Total       6 oversized leaks, 33648640 bytesCACHE             LEAKED           BUFCTL CALLER00007f3db1bba048       1 00007f3db1b3e7e0 main+0x12  //内存泄漏100007f3db1bba048       1 00007f3db1b3e8c0 test_leak_malloc+0x12  //内存泄漏2------------------------------------------------------------------------           Total       2 buffers, 160 bytesmmap(2) leak: [7f3daf3af000, 7f3daf3b3000), 16384 bytesmmap(2) leak: [7f3db1c40000, 7f3db1c41000), 4096 bytesmmap(2) leak: [7f3db1c3c000, 7f3db1c3e000), 8192 bytesmmap(2) leak: [7f3db1c28000, 7f3db1c2a000), 8192 bytesmmap(2) leak: [7f3dafa0c000, 7f3db1a16000), 33595392 bytesmmap(2) leak: [7f3daf771000, 7f3daf775000), 16384 bytesumem_alloc_80 leak: 1 buffer, 80 bytes            ADDR          BUFADDR        TIMESTAMP           THREAD                            CACHE          LASTLOG         CONTENTS    7f3db1b3e7e0     7f3db1b6bf60 60116209000b4637      -1312650368                     7f3db1bba048     7f3db1bf8300                0                 libumem.so.0.0.0`umem_alloc+0x98                 libumem.so.0.0.0`malloc+0x39 //泄漏内存的申请流程                 main+0x12                 libc-2.28.so`__libc_start_main+0xf3                 _start+0x2eumem_alloc_80 leak: 1 buffer, 80 bytes            ADDR          BUFADDR        TIMESTAMP           THREAD                            CACHE          LASTLOG         CONTENTS    7f3db1b3e8c0     7f3db1b6bef0 60116209000b463c      -1312650368                     7f3db1bba048     7f3db1bf83c0                0                 libumem.so.0.0.0`umem_alloc+0x98                 libumem.so.0.0.0`malloc+0x39                 test_leak_malloc+0x12 //泄漏内存的申请流程                 main+0x1b                 libc-2.28.so`__libc_start_main+0xf3                 _start+0x2e通过findleaks -d可以查看到内存泄漏的调用栈和信息；T-0.000000000  addr=7f3db1b6be80  umem_alloc_80 //test_UAF free addr=7f3db1b6be80         test_UAF+0x22         main+0x20         libc-2.28.so`__libc_start_main+0xf3         _start+0x2eT-0.000000005  addr=7f3db1b6be80  umem_alloc_80 //test_UAF malloc(50) addr=7f3db1b6be80          libumem.so.0.0.0`umem_alloc+0x98         libumem.so.0.0.0`malloc+0x39         test_UAF+0x12         main+0x20         libc-2.28.so`__libc_start_main+0xf3         _start+0x2eT-0.000000060  addr=7f3db1b6af40  umem_alloc_128 //test_leak_malloc free addr=7f3db1b6af40         test_leak_malloc+0x30         main+0x1b         libc-2.28.so`__libc_start_main+0xf3         _start+0x2eT-0.000000067  addr=7f3db1b6af40  umem_alloc_128 //test_leak_malloc malloc(100) addr=7f3db1b6af40         libumem.so.0.0.0`umem_alloc+0x98         libumem.so.0.0.0`malloc+0x39         test_leak_malloc+0x20         main+0x1b         libc-2.28.so`__libc_start_main+0xf3         _start+0x2e             T-0.000000182  addr=7f3db1b6bef0  umem_alloc_80 //test_leak_malloc malloc(50) addr=7f3db1b6bef0         libumem.so.0.0.0`umem_alloc+0x98         libumem.so.0.0.0`malloc+0x39          test_leak_malloc+0x12                 main+0x1b                             libc-2.28.so`__libc_start_main+0xf3         _start+0x2e                                                        T-0.000000187  addr=7f3db1b6bf60  umem_alloc_80 //main malloc(50) addr=7f3db1b6bf60         libumem.so.0.0.0`umem_alloc+0x98         libumem.so.0.0.0`malloc+0x39          main+0x12                             libc-2.28.so`__libc_start_main+0xf3         _start+0x2e                  通过umalog命令可以看到具体分配的细节；从上面也可以看到有两处申请未释放。memory corruption的处理；通过memory corruption的有user after free, double free, array bound write…::umem_verifyCache Name                      Addr             Cache Integrity     ...umem_alloc_80                       7f3db1bba048 1 corrupt bufferumem_alloc_96                       7f3db1bb9048 clean...7f3db1bba048::umem_verifySummary for cache 'umem_alloc_80'  buffer 7f3db1b6be80 (free) seems corrupted, at 7f3db1b6be90 //这里已经free的7f3db1b6be80地址出现corrupted通过上面umalog命令可以查看到申请的调用栈：T-0.000000005  addr=7f3db1b6be80  umem_alloc_80 //test_UAF malloc(50) addr=7f3db1b6be80          libumem.so.0.0.0`umem_alloc+0x98         libumem.so.0.0.0`malloc+0x39         test_UAF+0x12         main+0x20         libc-2.28.so`__libc_start_main+0xf3         _start+0x2e综合信息可以知道test_UAF中出现use after free的情况；ps：目前libumem支持调用栈的getstack的代码还没有合入； 后面需要合入社区代码还有很多待完善的地方。"
  },
  
  {
    "title": "Linux System Error Interrupt",
    "url": "/posts/linux-SEI/",
    "categories": "linux, SEI",
    "tags": "SEI",
    "date": "2021-02-03 00:00:00 +0000",
    





    
    "snippet": "一、SEI1 what is SEI?SEI中断是什么？SEI exception\t#define *SEI*() __set_PRIMASK(0) //打开总中断el1_sei2 do_serrorhttps://patchwork.kernel.org/project/linux-arm-kernel/patch/20171019145807.23251-11-james.morse@a...",
    "content": "一、SEI1 what is SEI?SEI中断是什么？SEI exception\t#define *SEI*() __set_PRIMASK(0) //打开总中断el1_sei2 do_serrorhttps://patchwork.kernel.org/project/linux-arm-kernel/patch/20171019145807.23251-11-james.morse@arm.com///arch/arm64/kernel/entry.Sel1_error:\tkernel_entry 1\tmrs\tx1, esr_el1\tenable_dbg\tmov\tx0, sp\tbl\tdo_serror\tkernel_exit 1ENDPROC(el1_error)el0_error:\tkernel_entry 0el0_error_naked:\tmrs\tx1, esr_el1\tenable_dbg\tmov\tx0, sp\tbl\tdo_serror\tenable_daif\tct_user_exit\tb\tret_to_userENDPROC(el0_error)//arch/arm64/kernel/traps.casmlinkage void do_serror(struct pt_regs *regs, unsigned int esr){\tconst bool was_in_nmi = in_nmi();\tif (!was_in_nmi)\t\tnmi_enter();\t/* non-RAS errors are not containable */\tif (!arm64_is_ras_serror(esr) || arm64_is_fatal_ras_serror(regs, esr))\t\tarm64_serror_panic(regs, esr);\tif (!was_in_nmi)\t\tnmi_exit();}SError是ARM的一种什么异常，AArch64(ARM64)架构中，主要包括如下4中类型的异常：https://blog.csdn.net/shenhuxi_yu/article/details/81212008  Synchronous exception(同步异常)，“同步”可以理解为：发生异常的指令为导致异常的指令，即当导致异常发生的指令执行时能立即触发异常。 包括ARM架构中定义的所有Aborts异常，如：指令异常、数据异常、对齐异常等。  SError，System Error，是一种异步异常，后面再仔细说明。  IRQ，普通的中断，是异步异常。  FIQ，高优先级的中断，是异步异常。SError本质上是一种异步外部abort（asynchronous external abort）。所谓异步，就说是发生异常时硬件(相关的寄存器)不能提供有效信息用于分析定位，异常发生时的指令，并不是导致异常的指令。外部意味着异常来自于外部存储系统(相较于CPU来说，MMU是内部的)。通常是硬件触发的问题，比如硬件的clock出问题或者硬件本身的问题导致的bus访问硬件时出现问题。Linux内核中，对SError进行了捕获，设置了相应的中断向量，当并未做实际的处理，只是上报异常，并终止进程会内核，因为对于内核来说，SError是致命的，内核自身无法做相应的修复操作，内核不知道具体原因，也不知道如何修复。二、问题(1) SEI是指 system Error Interupt？  怎么知道当前的fault 地址？​\t系统错误异常:  生成异常的原因保存在寄存器ESR_EL1（异常症状寄存器， Exception Syndrome Register）。(2)pagefault 缺页异常？ SEI中断和缺页异常之间的关系？​\t同步异常 :错误地址保存在寄存器FAR_EL1（错误地址寄存器，Fault Address Register）, 生成异常的原因保存在寄存器ESR_EL1（异常症状寄存器， Exception Syndrome Register）."
  },
  
  {
    "title": "C++ try-catch",
    "url": "/posts/c++-try-catch/",
    "categories": "Tools, try-catch",
    "tags": "try-catch",
    "date": "2021-02-03 00:00:00 +0000",
    





    
    "snippet": "一try-catch信息汇总：1、windows上可以扩展捕获SEGV异常的实现； linux标准C++上没有windows: https://www.codeproject.com/Articles/207464/Exception-Handling-in-Visual-Cplusplus2、linux上实现捕捉信号的方式\t（1）main-&gt; setjump -&gt; signal...",
    "content": "一try-catch信息汇总：1、windows上可以扩展捕获SEGV异常的实现； linux标准C++上没有windows: https://www.codeproject.com/Articles/207464/Exception-Handling-in-Visual-Cplusplus2、linux上实现捕捉信号的方式\t（1）main-&gt; setjump -&gt; signal_handle -&gt;longjump -&gt;catch\t(2) signal -&gt; signale_handle -&gt; throw err -&gt;catch//不推荐1 try-catch segv：1) 基本上是基于setjump和longjump和信号处理函数实现。2) 将信号转化为异常，注册信号处理函数，Throw SIGERR1)基本上是基于setjump和longjump和信号处理函数实现。https://www.xspdf.com/resolution/52100043.htmlC++ try-catch crashC++ catching all exceptions, try{ // } catch () { // } will catch all C++ exceptions, but it should be considered bad design. You can use c++11's new current_exception mechanism, but if you don't Someone should add that one cannot catch \"crashes\" in C++ code. A try-catch-finally block is made up of the following sections: Any code that may throw an exception is placed inside the try block. If an exception is thrown, the catch block is entered, and the program can do the appropriate operation to recover or to alert the user.Catch Segmentation fault in c++, Errors like segmentation faults are lower-level, and try-catch ignores these The appropriate thing to do is not to handle the crash like you would an This process in C++ is much easier than C, for example new throw an  c++ try-catch crash-reports. share | improve this question | follow | | | | edited Nov 27 '14 at 4:17. paisanco. 3,631 6 6 gold badges 23 23 silver badges 30 30catch() is not catching an exception, my program is still crashing , block is not catching errors maybe it is because of a Windows error. Windows defines in a C-style fashion - this is because Win32 was written in C both C++ exception handing and SEH perhaps you could try the following  Both C and C++ programs can use the structured exception handling (SEH) mechanism in the Windows operating system. The concepts in SEH resemble those in C++ exceptions, except that SEH uses the __try, __except, and __finally constructs instead of try and catch. In the Microsoft C++ compiler (MSVC), C++ exceptions are implemented for SEH.https://github.com/printfn/segfaulting通过setjump和longjump捕捉SEGV后跳转。 // 这个应该不是我们需要的void catch_segfault(int signal, siginfo_t *si, void *arg) {    printf(\"Caught segfault at address %p (%zu)\\n\", si-&gt;si_addr, (size_t)si-&gt;si_addr);    longjmp(env_buffer, 1);}https://blog.csdn.net/kongxiangwang/article/details/8237384?utm_medium=distribute.pc_relevant_bbs_down.none-task-blog-baidujs-2.nonecase&amp;depth_1-utm_source=distribute.pc_relevant_bbs_down.none-task-blog-baidujs-2.nonecase //windows上有对应的try-catch 扩展来捕获异常访问。https://blog.csdn.net/jekenzhuang/article/details/79737147?utm_medium=distribute.pc_relevant_bbs_down.none-task--2~all~first_rank_v2~rank_v29-2.nonecase&amp;depth_1-utm_source=distribute.pc_relevant_bbs_down.none-task--2~all~first_rank_v2~rank_v29-2.nonecase//try-catch流程2)将信号转化为异常，注册信号处理函数，Throw SIGERR//注册信号处理函数， Throw errorhttps://www.jianshu.com/p/4e14ba11fe78//但是sun的手册不建议 信号处理函数中抛出异常。https://docs.oracle.com/cd/E19205-01/820-1214/bkahb/index.html2、C++标准的异常https://blog.csdn.net/daoming1112/article/details/54973549表是对上面层次结构中出现的每个异常的说明：            异常      描述                  std::exception      该异常是所有标准 C++ 异常的父类。              std::bad_alloc      该异常可以通过 new 抛出。              std::bad_cast      该异常可以通过 dynamic_cast 抛出。              std::bad_exception      这在处理 C++ 程序中无法预期的异常时非常有用。              std::bad_typeid      该异常可以通过 typeid 抛出。              std::logic_error      理论上可以通过读取代码来检测到的异常。              std::domain_error      当使用了一个无效的数学域时，会抛出该异常。              std::invalid_argument      当使用了无效的参数时，会抛出该异常。              std::length_error      当创建了太长的 std::string 时，会抛出该异常。              std::out_of_range      该异常可以通过方法抛出，例如 std::vector 和 std::bitset&lt;&gt;::operator。              std::runtime_error      理论上不可以通过读取代码来检测到的异常。              std::overflow_error      当发生数学上溢时，会抛出该异常。              std::range_error      当尝试存储超出范围的值时，会抛出该异常。              std::underflow_error      当发生数学下溢时，会抛出该异常。      3、自定义异常"
  },
  
  {
    "title": "Remote Direct Memory Access (RDMA)",
    "url": "/posts/linux-rmda/",
    "categories": "linux, RDMA",
    "tags": "RDMA",
    "date": "2021-01-26 00:00:00 +0000",
    





    
    "snippet": "RDMAReferences:https://zhuanlan.zhihu.com/p/55142557 RDMA技术详解（一）：RDMA概述https://community.mellanox.com/s/article/what-is-rdma-x   What is RDMA?[https://zh.wikipedia.org/wiki/%E5%9F%BA%E4%BA%8E%E8%9E...",
    "content": "RDMAReferences:https://zhuanlan.zhihu.com/p/55142557 RDMA技术详解（一）：RDMA概述https://community.mellanox.com/s/article/what-is-rdma-x   What is RDMA?[https://zh.wikipedia.org/wiki/%E5%9F%BA%E4%BA%8E%E8%9E%8D%E5%90%88%E4%BB%A5%E5%A4%AA%E7%BD%91%E7%9A%84RDMA](https://zh.wikipedia.org/wiki/基于融合以太网的RDMA)一、 RDMA​\tRemote Direct Memory Access (RDMA) is the ability of accessing (read, write) memory on a remote machine without interrupting the processing of the CPU(s) on that system.1 RDMA的优势  零拷贝(Zero-copy) - 应用程序能够直接执行数据传输，在不涉及到网络软件栈的情况下。数据能够被直接发送到缓冲区或者能够直接从缓冲区里接收，而不需要被复制到网络层。  内核旁路(Kernel bypass) - 应用程序可以直接在用户态执行数据传输，不需要在内核态与用户态之间做上下文切换。  不需要CPU干预(No CPU involvement) - 应用程序可以访问远程主机内存而不消耗远程主机中的任何CPU。远程主机内存能够被读取而不需要远程主机上的进程（或CPU)参与。远程主机的CPU的缓存(cache)不会被访问的内存内容所填充。  消息基于事务(Message based transactions) - 数据被处理为离散消息而不是流，消除了应用程序将流切割为不同消息/事务的需求。  支持分散/聚合条目(Scatter/gather entries support) - RDMA原生态支持分散/聚合。也就是说，读取多个内存缓冲区然后作为一个流发出去或者接收一个流然后写入到多个内存缓冲区里去。2 RDMA 三种不同的硬件实现RDMA作为一种host-offload, host-bypass技术，使低延迟、高带宽的直接的内存到内存的数据通信成为了可能。目前支持RDMA的网络协议有：  InfiniBand(IB): 从一开始就支持RDMA的新一代网络协议。由于这是一种新的网络技术，因此需要支持该技术的网卡和交换机。  RDMA过融合以太网(RoCE): 即RDMA over Ethernet, 允许通过以太网执行RDMA的网络协议。这允许在标准以太网基础架构(交换机)上使用RDMA，只不过网卡必须是支持RoCE的特殊的NIC。  互联网广域RDMA协议(iWARP): 即RDMA over TCP, 允许通过TCP执行RDMA的网络协议。这允许在标准以太网基础架构(交换机)上使用RDMA，只不过网卡要求是支持iWARP(如果使用CPU offload的话)的NIC。否则，所有iWARP栈都可以在软件中实现，但是失去了大部分的RDMA性能优势。3 Memory Registration(MR) | 内存注册RDMA 就是用来对内存进行数据传输。那么怎样才能对内存进行传输，很简单，注册。 因为RDMA硬件对用来做数据传输的内存是有特殊要求的。  在数据传输过程中，应用程序不能修改数据所在的内存。      **操作系统不能对数据所在的内存进行page out操作 -- 物理地址和虚拟地址的映射必须是固定不变的。**  注意无论是DMA或者RDMA都要求物理地址连续，这是由DMA引擎所决定的。 那么怎么进行内存注册呢？  创建两个key (local和remote)指向需要操作的内存区域  注册的keys是数据传输请求的一部分注册一个Memory Region之后，这个时候这个Memory Region也就有了它自己的属性：  context : RDMA操作上下文  addr : MR被注册的Buffer地址  length : MR被注册的Buffer长度  lkey：MR被注册的本地key  rkey：MR被注册的远程key对Memrory Registration：Memory Registration只是RDMA中对内存保护的一种措施，只有将要操作的内存注册到RDMA Memory Region中，这快操作的内存就交给RDMA 保护域来操作了。这个时候我们就可以对这快内存进行操作，至于操作的起始地址、操作Buffer的长度，可以根据程序的具体需求进行操作。我们只要保证接受方的Buffer 接受的长度大于等于发送的Buffer长度。4 RDMA队列：发送队列(SQ)和接收队列(RQ)，完成队列(CQ)。其中，SQ和RQ通常成对创建，被称为Queue Pairs(QP)。 属于生产者-消费者模式；二、 RoCE三、 what is ODP ?"
  },
  
  {
    "title": "Kernel Address Space Layout Randomization (KASLR)",
    "url": "/posts/linux-kaslr/",
    "categories": "linux, kaslr",
    "tags": "kaslr",
    "date": "2020-11-24 00:00:00 +0000",
    





    
    "snippet": "一、KASLR内核地址随机化二、kaslr-seed地址随机化种子kaslr-seedkaslr-seed-----------This property is used when booting with CONFIG_RANDOMIZE_BASE as theentropy used to randomize the kernel image base address location....",
    "content": "一、KASLR内核地址随机化二、kaslr-seed地址随机化种子kaslr-seedkaslr-seed-----------This property is used when booting with CONFIG_RANDOMIZE_BASE as theentropy used to randomize the kernel image base address location. Sinceit is used directly, this value is intended only for KASLR, and shouldnot be used for other purposes (as it may leak information about KASLRoffsets). It is parsed as a u64 value, e.g./ {\tchosen {\t\tkaslr-seed = &lt;0xfeedbeef 0xc0def00d&gt;;\t};};Note that if this property is set from UEFI (or a bootloader in EFImode) when EFI_RNG_PROTOCOL is supported, it will be overwritten bythe Linux EFI stub (which will populate the property itself, usingEFI_RNG_PROTOCOL).config RANDOMIZE_BASE\tbool \"Randomize the address of the kernel image\"\tselect ARM64_MODULE_PLTS if MODULES\tselect RELOCATABLE\thelp\t  Randomizes the virtual address at which the kernel image is\t  loaded, as a security feature that deters exploit attempts\t  relying on knowledge of the location of kernel internals.\t  It is the bootloader's job to provide entropy, by passing a\t  random u64 value in /chosen/kaslr-seed at kernel entry.\t  When booting via the UEFI stub, it will invoke the firmware's\t  EFI_RNG_PROTOCOL implementation (if available) to supply entropy\t  to the kernel proper. In addition, it will randomise the physical\t  location of the kernel Image as well.kaslr_early_init\t-&gt;|get_kaslr_seed1 EFI_RNG_PROTOCOLefi_entry    -&gt;|handle_kernel_image        -&gt;|efi_get_random_bytes   -&gt;|update_fdt//driver/firmware/efi/libstub/arm64-stub.cefi_status_t handle_kernel_image(efi_system_table_t *sys_table_arg, ...) {    \t...    \tif (IS_ENABLED(CONFIG_RANDOMIZE_BASE)) {\t\tif (!nokaslr()) {\t\t\tstatus = efi_get_random_bytes(sys_table_arg,\t\t\t\t\t\t      sizeof(phys_seed),\t\t\t\t\t\t      (u8 *)&amp;phys_seed);\t\t\tif (status == EFI_NOT_FOUND) {\t\t\t\tpr_efi(sys_table_arg, \"EFI_RNG_PROTOCOL unavailable, no randomness supplied\\n\");\t\t\t} else if (status != EFI_SUCCESS) {\t\t\t\tpr_efi_err(sys_table_arg, \"efi_get_random_bytes() failed\\n\");\t\t\t\treturn status;\t\t\t}\t\t} else {\t\t\tpr_efi(sys_table_arg, \"KASLR disabled on kernel command line\\n\");\t\t}\t}   \t...}efi_status_t efi_get_random_bytes(efi_system_table_t *sys_table_arg,\t\t\t\t  unsigned long size, u8 *out){\tefi_guid_t rng_proto = EFI_RNG_PROTOCOL_GUID;\tefi_status_t status;\tstruct efi_rng_protocol *rng;\tstatus = efi_call_early(locate_protocol, &amp;rng_proto, NULL,\t\t\t\t(void **)&amp;rng);\tif (status != EFI_SUCCESS)\t\treturn status;\treturn rng-&gt;get_rng(rng, NULL, size, out);}1&gt; locate_protocolhttps://blog.csdn.net/yhb1047818384/article/details/865133512&gt; head.Shttps://zhuanlan.zhihu.com/p/99557658"
  },
  
  {
    "title": "Vim cscope使用",
    "url": "/posts/tools-vim-cscope/",
    "categories": "Tools, vim",
    "tags": "vim",
    "date": "2020-10-23 00:00:00 +0000",
    





    
    "snippet": "在ubuntu下的安装与配置如下——一、ctags 插件a)  功能：对浏览代码非常的方便, 可以在函数, 变量之间跳来跳去等等等等 (更多说明请百度或谷歌一下）b)   安装配置：终端下输入  sudo apt-get install ctags如果没发现该软件包就用   sudo apt-get install exuberant-ctags  就行了……如果还不行可以到官网下载源码手动...",
    "content": "在ubuntu下的安装与配置如下——一、ctags 插件a)  功能：对浏览代码非常的方便, 可以在函数, 变量之间跳来跳去等等等等 (更多说明请百度或谷歌一下）b)   安装配置：终端下输入  sudo apt-get install ctags如果没发现该软件包就用   sudo apt-get install exuberant-ctags  就行了……如果还不行可以到官网下载源码手动编译安装,有点麻烦是不是？不要嫌麻烦，这也是一个学习的机会，如果遇到其他类似的你也可以仿照这里的例子，再配合压缩包里的README文件就能手动安装了，你说是不是，呵呵。下载地址   http://nchc.dl.sourceforge.net/project/ctags/ctags/5.8/ctags-5.8.tar.gz下载解压后$ cd ctags-5.8$ ./configure$ make# make install  // 需要root权限使用 ctags –hlep  命令简单测试一下安装成功了没  &gt;^_^&lt;c) 使用方法：然后去你的源码目录, 如果你的源码是多层的目录, 就去最上层的目录, 在该目录下运行命令: ctags -R     其中-R表示递归遍历我现在以 linux-kernel 的源码目录做演示$ cd  ~/ linux-kernel$ ctags -R    （如果是kernel源码的话还可以用 make tags）此时在/home/ linux-kernel/目录下会生成一个 tags 文件, 现在用vim打开即输入vim 然后Shift + :  然后再在vim末行运行命令，      set tags=/home/bob/linux-kernel/tags   （最前面的：是提示符，不必输入）  每次都要输入这个才能使tags生效，我很懒，所以把该命令加入到~/.vimrc中, 你也可以将这句话放到~/.vimrc中去,如果你经常在这个    工程目录编程的话.再如果你经常在不同工程间编程, 可以在.vimrc中加上:​      set tags=tags;   “  其中 ; 不能没有​     set autochdird)  使用举例：把光标定位到某一函数名上或者宏上, 按下 Ctrl + ], vim就可以自动切换到该函数定义处!要返回只需要按下Ctrl + o  或者 Ctrl + t.    是不是很方便吖。二、 cscope 插件a) 功能：可以对函数以及部分类型定义进行跳转(更多说明请百度或谷歌一下）b) 安装配置：sudo apt-get install cscope这个源里应该有了，如果没有请到其官网 http://sourceforge.net/projects/cscope/files/  下载源码安装，具体安装方法和 ctags 一样的，我就不罗嗦啦！d)使用举例：在终端下，转到你源码的所在目录然后$cscope -Rbkq  说明一下参数：​    R 表示把所有子目录里的文件也建立索引　　 b 表示cscope不启动自带的用户界面，而仅仅建立符号数据库　   q 生成cscope.in.out和cscope.po.out文件，加快cscope的索引速度　　 k 在生成索引文件时，不搜索/usr/include目录之后会在当前目录生成几个文件， cscope.in.out和cscope.po.out文件,cscope.outvim的normal模式下输入:cs add cscope.out不会吧，每次都要输入这些命令，烦死人了，有没有捷径呢？想偷懒总有人找到方法的,sudo gedit  ~/.vimrc   ；然后在该文件下添加如下代码： if filereadable(“cscope.out”)   cs add cscope.out endif 这样每次打开vim就可以直接使用cscope了。再试试把下面的内容复制到~/.vimrc里，这样就可以利用相应的快捷键进行不同的查找了.if has(“cscope”)​      set cscopetag  “ 使支持用 Ctrl+]  和 Ctrl+t 快捷键在代码间跳来跳去​      “ check cscope for definition of a symbol before checking ctags:​      “ set to 1 if you want the reverse search order.​       set csto=1​       “ add any cscope database in current directory​       if filereadable(“cscope.out”)​         cs add cscope.out​       “ else add the database pointed to by environment variable​       elseif $CSCOPE_DB !=””​         cs add $CSCOPE_DB​       endif​       “ show msg when any other cscope db added​       set cscopeverbose​       nmap s :cs find s =expand(\"\")​       nmap g :cs find g =expand(\"\")​       nmap c :cs find c =expand(\"\")​       nmap t :cs find t =expand(\"\")​       nmap e :cs find e =expand(\"\")​       nmap f :cs find f =expand(\"\")​       nmap i :cs find i ^=expand(\"\")$​       nmap d :cs find d =expand(\"\")​     endif附常用的命令：：cs find s —- 查找C语言符号，即查找函数名、宏、枚举值等出现的地方　　：cs find g —- 查找函数、宏、枚举等定义的位置，类似ctags所提供的功能　　：cs find d —- 查找本函数调用的函数：cs find c —- 查找调用本函数的函数　　：cs find t: —- 查找指定的字符串　　：cs find e —- 查找egrep模式，相当于egrep功能，但查找速度快多了　　：cs find f —- 查找并打开文件，类似vim的find功能　　：cs find i —- 查找包含本文件的文Ctrl+]将跳到光标所在变量或函数的定义处 Ctrl+T返回更多帮助在vim末行命令模式下输入cs 或 cscope获得帮助信息。更多的例子如下首先进入源码目录, 在linux终端中输入以下命令以创建cscope数据库:​    $ find ~/work/..Project/ -name “.h” -o -name “.cpp” &gt; cscope.files​    $ cscope -bkq -i cscope.files如果是在windows环境中, 则换成如下命令:​    dir /s /b *.cpp *.h &gt; cscope.files​     cscope -b -q -k -i cscope.files然后, 用vim打开一个源文件(如: vim main.cpp),打开后, 第一件事就是导入cscope数据库了:​     :cs add /home/yourname/workpace/cscope.out /home/yourname/workpacecscope数据库导入成功后, 就可以利用上面定义的快捷键进行相关的查找,三、 taglist 插件a) 功能: 高效地浏览源码, 其功能就像vc中的workpace, 那里面列出了当前文件中的所有宏等等。b) 安装就不需要了，简单配置一下就行了，但需要ctags的支持，下载地址  http://www.vim.org/scripts/download_script.php?src_id=7701下载后，解压缩后里面有两个目录 plugin和doc ，然后分别把plugin/taglist.vim复制到~/.vim/plugin目录下,把doc/taglist.txt复制到~/.vim/doc目录下，ok！记得把下面的加入到~/.vimrc 中哦” 按F8按钮，在窗口的左侧出现taglist的窗口,像vc的左侧的workpacennoremap   :TlistToggle” :Tlist        调用TagListlet Tlist_Show_One_File=0           “ 只显示当前文件的tagslet Tlist_Exit_OnlyWindow=1          “ 如果Taglist窗口是最后一个窗口则退出Vimlet Tlist_Use_Right_Window=1         “ 在右侧窗口中显示let Tlist_File_Fold_Auto_Close=1       “ 自动折叠d) 使用举例：这个就不用多说了，自己按F8试试就知道了，直接用鼠标就能操作。在taglist窗口中，还可以使用下面的快捷键：     跳到光标下tag所定义的位置，用鼠标双击此tag功能也一样o       在一个新打开的窗口中显示光标下tag    显示光标下tag的原型定义u       更新taglist窗口中的tags       更改排序方式，在按名字排序和按出现顺序排序间切换x       taglist窗口放大和缩小，方便查看较长的tag\\+       打开一个折叠，同zo\\-       将tag折叠起来，同zc\\*       打开所有的折叠，同zR=       将所有tag折叠起来，同zM[[      跳到前一个文件]]      跳到后一个文件q       关闭taglist窗口     显示帮助可以用“:TlistOpen”打开taglist窗口，用“:TlistClose”关闭taglist窗口。或者使用“:TlistToggle”在打开和关闭间切换。在我的vimrc中定义了下面的映射，使用“,tl”键就可以打开/关闭taglist窗口：```map  tl :TlistToogle```"
  },
  
  {
    "title": "Modular Debugger (MDB)",
    "url": "/posts/sunos-mdb/",
    "categories": "Package, mdb",
    "tags": "mdb",
    "date": "2020-10-20 00:00:00 +0000",
    





    
    "snippet": "适用于linux系统的mdb：https://github.com/luochenglcs/mdbIf the code is useful to you - great !. Spread it around and get people to use, debug and enhance it.一、libumem_ready赋值umem_update_variables    \t-&gt...",
    "content": "适用于linux系统的mdb：https://github.com/luochenglcs/mdbIf the code is useful to you - great !. Spread it around and get people to use, debug and enhance it.一、libumem_ready赋值umem_update_variables    \t-&gt;|umem_set_standalone  == -1 ? libumem_ready : UMEM_READVAR(umem_ready);umem_set_standalone    -&gt;|mdb_lookup_by_obj    \t-&gt;|lookup_minimal_symbol(\"umem_alloc\",NULL, NULL)UMEM_READVAR(umem_ready)\t-&gt;|umem_lookup_by_name    \t-&gt;mdb_lookup_by_obj    \t\t-&gt;lookup_minimal_symbol(\"umem_ready\", NULL, NULL) //http://agentzh.org/misc/code/gdb/minsyms.c.html#L163/* Look through all the current minimal symbol tables and find the   first minimal symbol that matches NAME.  If OBJF is non-NULL, limit   the search to that objfile.  If SFILE is non-NULL, the only file-scope   symbols considered will be from that source file (global symbols are   still preferred).  Returns a pointer to the minimal symbol that   matches, or NULL if no match is found.   Note:  One instance where there may be duplicate minimal symbols with   the same name is when the symbol tables for a shared library and the   symbol tables for an executable contain global symbols with the same   names (the dynamic linker deals with the duplication).   It's also possible to have minimal symbols with different mangled   names, but identical demangled names.  For example, the GNU C++ v3   ABI requires the generation of two (or perhaps three) copies of   constructor functions --- \"in-charge\", \"not-in-charge\", and   \"allocate\" copies; destructors may be duplicated as well.   Obviously, there must be distinct mangled names for each of these,   but the demangled names are all the same: S::S or S::~S.  */struct bound_minimal_symbol‌lookup_minimal_symbol (const char *name, const char *sfile,                       struct objfile *objf){    ...}二、重点函数1 leaky_subr_estimateleaky_subr_estimate(*estp) //est是个数    -&gt;|mdb_walk(\"umem_cache\", (mdb_walk_cb_t)leaky_estimate, estp)    \t-&gt;|mdb_pwalk(\"umem_cache\", (mdb_walk_cb_t)leaky_estimate, estp, NULL)    \t\t-&gt;|mdb_walker_lookup(\"umem_cache\") -&gt; mdb_iwalker_t *iwp    \t\t-&gt;|walk_common(mdb_wcb_create(iwp, func, data, addr))        -&gt;|mdb_walk(\"vmem\", (mdb_walk_cb_t)leaky_estimate_vmem, estp)mdb_wcb_t *mdb_wcb_create(mdb_iwalker_t *iwp, mdb_walk_cb_t cb, void *data, uintptr_t addr){\tmdb_wcb_t *wcb = mdb_zalloc(sizeof (mdb_wcb_t), UM_SLEEP);\twcb-&gt;w_buftag = WCB_TAG_INITIAL;\twcb-&gt;w_walker = iwp;\twcb-&gt;w_state.walk_callback = cb;\twcb-&gt;w_state.walk_cbdata = data;\twcb-&gt;w_state.walk_addr = addr;\twcb-&gt;w_state.walk_arg = iwp-&gt;iwlk_init_arg;\treturn (wcb);}"
  },
  
  {
    "title": "Kernel userfaultfd",
    "url": "/posts/linux-userfaultfd/",
    "categories": "linux, userfaultfd",
    "tags": "userfaultfd",
    "date": "2020-09-24 00:00:00 +0000",
    





    
    "snippet": "Userfault只支持匿名页，hugetlb、共享内存；一、软件流程1 初始化调用__NR_userfaultfd syscall初始化调用syscall初始化建立匿名inode文件，并初始化file-&gt;private_data,并返回用户态文件fd。      用户态：    uffd = syscall(__NR_userfaultfd, O_CLOEXEC | O_NONBLO...",
    "content": "Userfault只支持匿名页，hugetlb、共享内存；一、软件流程1 初始化调用__NR_userfaultfd syscall初始化调用syscall初始化建立匿名inode文件，并初始化file-&gt;private_data,并返回用户态文件fd。      用户态：    uffd = syscall(__NR_userfaultfd, O_CLOEXEC | O_NONBLOCK);            内核态：    d = anon_inode_getfd(\"[userfaultfd]\", &amp;userfaultfd_fops, ctx,  \t              O_RDWR | (flags &amp; UFFD_SHARED_FCNTL_FLAGS));           2、设置监视区ioctl的UFFDIO_REGISTER选项注册监视区域；      用户态：    uffdio_register.range.start = (unsigned long)start;  uffdio_register.range.len = size;  uffdio_register.mode = UFFDIO_REGISTER_MODE_MISSING      | UFFDIO_REGISTER_MODE_USWAP;;  if (ioctl(uffd, UFFDIO_REGISTER, &amp;uffdio_register) == -1)      errExit(\"ioctl-UFFDIO_REGISTER\");          2.内核：这里会对监控的区域拆除合并，从非监控区域拆分，合并到已经监控的区域，并新增vm_flags;    //（1）flag的对应关系：if (uffdio_register.mode &amp; UFFDIO_REGISTER_MODE_MISSING)      vm_flags |= VM_UFFD_MISSING;  if (uffdio_register.mode &amp; UFFDIO_REGISTER_MODE_WP) {      vm_flags |= VM_UFFD_WP;          new_flags = (vma-&gt;vm_flags &amp; ~vm_flags) | vm_flags;  //（2）将新增的监控区域与已有的监控区域做合并prev = vma_merge(mm, prev, start, vma_end, new_flags,                   vma-&gt;anon_vma, vma-&gt;vm_file, vma-&gt;vm_pgoff,                   vma_policy(vma),                   ((struct vm_userfaultfd_ctx){ ctx }));  if (prev) {      vma = prev;      goto next;  }  //(3)如果无法合并，可能需要拆分if (vma-&gt;vm_start &lt; start) {      ret = split_vma(mm, vma, start, 1);      if (ret)          break;  }  if (vma-&gt;vm_end &gt; end) {      ret = split_vma(mm, vma, end, 0);      if (ret)          break;  }  next:  /* * In the vma_merge() successful mprotect-like case 8: * the next vma was merged into the current one and * the current one has not been updated yet. */  vma-&gt;vm_flags = new_flags;  //+USERFAULT_FD_FLAG: VM_UFFD_MISSINGvma-&gt;vm_userfaultfd_ctx.ctx = ctx;       3、poll event用户态poll函数轮询uffd，并对轮询到的UFFD_EVENT_PAGEFAULT事件(event)用拷贝(ioctl的UFFDIO_COPY选项)进行处理。      UFFD_EVENT_PAGEFAULT事件(event)Page_fault流程中判断是否是userfaultfd_missing，如果是的话，执行userfault_msg唤醒用户态poll进程，并发送消息。    static inline bool userfaultfd_missing(struct vm_area_struct *vma)  {      return vma-&gt;vm_flags &amp; VM_UFFD_MISSING;  }              用户态通过UFFDIO_COPY选项在用户态申请Page传入内核，内核执行mcopy_atomic完成补页mfill_atomic_pte和用户态page内容的拷贝。    dst_pmd = mm_alloc_pmd(dst_mm, dst_addr);  if (unlikely(!dst_pmd)) {      err = -ENOMEM;      break;  }       dst_pmdval = pmd_read_atomic(dst_pmd);  /*  * If the dst_pmd is mapped as THP don't \t * override it and just be strict. \t */  if (unlikely(pmd_trans_huge(dst_pmdval))) {  \terr = -EEXIST;  \tbreak;  }  if (unlikely(pmd_none(dst_pmdval)) &amp;&amp;  \tunlikely(__pte_alloc(dst_mm, dst_pmd, dst_addr))) {  \terr = -ENOMEM;  \tbreak;  }  /* If an huge pmd materialized from under us fail */  if (unlikely(pmd_trans_huge(*dst_pmd))) {  \terr = -EFAULT;  \tbreak;  }       BUG_ON(pmd_none(*dst_pmd));  BUG_ON(pmd_trans_huge(*dst_pmd));       err = mfill_atomic_pte(dst_mm, dst_pmd, dst_vma, dst_addr,  \t\t\t   src_addr, &amp;page, zeropage);          //2）用户态传入的page内容copypage_kaddr = kmap(page);  err = copy_from_user(page_kaddr,            (const void __user *) src_addr,  \t\t PAGE_SIZE);        二、userfaultfd waitQhttps://blog.csdn.net/u012218309/article/details/81148083 linux等待队列 wait_queue的使用http://gityuan.com/2018/12/02/linux-wait-queue/ 源码解读Linux等待队列/* * Start with fault_pending_wqh and fault_wqh so they're more likely * to be in the same cacheline. */struct userfaultfd_ctx {\t/* waitqueue head for the pending (i.e. not read) userfaults */\twait_queue_head_t fault_pending_wqh;\t/* waitqueue head for the userfaults */\twait_queue_head_t fault_wqh;\t/* waitqueue head for the pseudo fd to wakeup poll/read */\twait_queue_head_t fd_wqh;\t/* waitqueue head for events */\twait_queue_head_t event_wqh;\t/* a refile sequence protected by fault_pending_wqh lock */\tstruct seqcount refile_seq;\t/* pseudo fd refcounting */\tatomic_t refcount;\t/* userfaultfd syscall flags */\tunsigned int flags;\t/* features requested from the userspace */\tunsigned int features;\t/* state machine */\tenum userfaultfd_state state;\t/* released */\tbool released;\t/* memory mappings are changing because of non-cooperative event */\tbool mmap_changing;\t/* mm with one ore more vmas attached to this userfaultfd_ctx */\tstruct mm_struct *mm;};      wait_queue_head_t fault_pending_wqh =&gt; pending (i.e. not read) userfaults    未读取页错误等待队列，线程触发页错误异常以后，等到userfaultfd读取页错误事件；    1)fault_pending_wqh    handle_userfault     -&gt;| __add_wait_queue(&amp;ctx-&gt;fault_pending_wqh, &amp;uwq.wq);        uwq的结构体内容：    ctx = vmf-&gt;vma-&gt;vm_userfaultfd_ctx.ctx;...init_waitqueue_func_entry(&amp;uwq.wq, userfaultfd_wake_function);uwq.wq.private = current;uwq.msg = userfault_msg(vmf-&gt;address, vmf-&gt;flags, reason,                        ctx-&gt;features);uwq.ctx = ctx;uwq.waken = false;        2)struct seqcount refile_seq    顺序锁，用来保护fault_pending_wqh和fault_wqh等待队列；        wait_queue_head_t fault_wqh =&gt; userfaults    已读取页错误的等待队列，userfaultfd已读取页错误事件，还没有唤醒触发页错误异常的线程；        wait_queue_head_t fd_wqh =&gt; the pseudo fd to wakeup poll/read    文件描述符等待队列，userfaultfd等待事件发生；        wait_queue_head_t event_wqh =&gt;  events Q    事件等待队列，等待userfaultfd读取事件；  三、userfaultfd优化：1）userfaultfd文档有推荐PROT_NONE + SIGSEGV的方法优点：1、不需要socket/poll通信；2、不走handle_userfault的流程。缺点：1、SIGSEGV信号占用；2、vma碎片PS:      内核高精度时延测量方法：\t\t  asm volatile(“mrs %0, cntvct_el0” : “=r” (ed) :: “memory”);      1、\t获取ARM的cntvct_el0累加寄存器，计算路径上的时延差值；      2、\t定时器的时钟源，通过CNTFRQ_EL0寄存器获取为50Mhz，即20ns;"
  },
  
  {
    "title": "numad systemctl start failed",
    "url": "/posts/numad-start-failed/",
    "categories": "Package, numad",
    "tags": "numad",
    "date": "2020-09-17 06:10:00 +0000",
    





    
    "snippet": "1 systemct start failed1、R9 x86环境systemctl启动失败● numad.service - numad - The NUMA daemon that manages application locality.   Loaded: loaded (/usr/lib/systemd/system/numad.service; disabled; vendor ...",
    "content": "1 systemct start failed1、R9 x86环境systemctl启动失败● numad.service - numad - The NUMA daemon that manages application locality.   Loaded: loaded (/usr/lib/systemd/system/numad.service; disabled; vendor preset: disabled)   Active: failed (Result: exit-code) since Wed 2020-09-16 11:08:09 CST; 2min 17s ago     Docs: man:numad  Process: 618176 ExecStart=/usr/bin/numad -i 15 (code=exited, status=1/FAILURE)Sep 16 11:08:09 localhost.localdomain systemd[1]: Starting numad - The NUMA daemon that manages application locality....Sep 16 11:08:09 localhost.localdomain numad[618176]: Wed Sep 16 11:08:09 2020: Cannot open numad log file (errno: 13) -- using stderrSep 16 11:08:09 localhost.localdomain numad[618176]: Wed Sep 16 11:08:09 2020: msgget failedSep 16 11:08:09 localhost.localdomain systemd[1]: numad.service: Control process exited, code=exited, status=1/FAILURESep 16 11:08:09 localhost.localdomain systemd[1]: numad.service: Failed with result 'exit-code'.Sep 16 11:08:09 localhost.localdomain systemd[1]: Failed to start numad - The NUMA daemon that manages application locality..[root@localhost testEL_Numad_FUN.001]# systemctl start numadJob for numad.service failed because the control process exited with error code.查看numad的代码：https://pagure.io/numad/blob/master/f/numad.c// errno:13 - #define EACCES 13 /* Permission denied */#define VAR_LOG_FILE \"/var/log/numad.log\"void open_log_file() {    log_fs = fopen(VAR_LOG_FILE, \"a\");    if (log_fs == NULL) {        log_fs = stderr;        numad_log(LOG_ERR, \"Cannot open numad log file (errno: %d) -- using stderr\\n\", errno);    }}发现失败原因是，fopen(“/var/log/numad.log”, “a”)没有权限。查看audit的日志发现fopen失败；selinux维护了一个系统的访问权限表 access vector cache；auditd服务会监控所有的异常访问 记到audit日志里面将selinux关闭后，通过systemd启动正常；打开selinux，通过systemd启动失败，只能手动直接命令，绕过systemd audit审计。"
  },
  
  {
    "title": "Kernel Probe (kprobe)",
    "url": "/posts/linux-kprobe/",
    "categories": "linux, kprobe",
    "tags": "kprobe",
    "date": "2020-09-14 00:00:00 +0000",
    





    
    "snippet": "1 kprobe2 debugfs kprobe tracekprobe trace 使用debugfs的trace功能 p[:[GRP/]EVENT] [MOD:]SYM[+offs]|MEMADDR [FETCHARGS]  : Set a probe r[MAXACTIVE][:[GRP/]EVENT] [MOD:]SYM[+0] [FETCHARGS]  : Set a return...",
    "content": "1 kprobe2 debugfs kprobe tracekprobe trace 使用debugfs的trace功能 p[:[GRP/]EVENT] [MOD:]SYM[+offs]|MEMADDR [FETCHARGS]  : Set a probe r[MAXACTIVE][:[GRP/]EVENT] [MOD:]SYM[+0] [FETCHARGS]  : Set a return probe -:[GRP/]EVENT                                         : Clear a probeGRP            : Group name. If omitted, use \"kprobes\" for it.EVENT          : Event name. If omitted, the event name is generated                 based on SYM+offs or MEMADDR.MOD            : Module name which has given SYM.SYM[+offs]     : Symbol+offset where the probe is inserted.MEMADDR        : Address where the probe is inserted.MAXACTIVE      : Maximum number of instances of the specified function that                 can be probed simultaneously, or 0 for the default value                 as defined in Documentation/staging/kprobes.rst section 1.3.1.FETCHARGS      : Arguments. Each probe can have up to 128 args. %REG          : Fetch register REG @ADDR         : Fetch memory at ADDR (ADDR should be in kernel) @SYM[+|-offs] : Fetch memory at SYM +|- offs (SYM should be a data symbol) $stackN       : Fetch Nth entry of stack (N &gt;= 0) $stack        : Fetch stack address. $argN         : Fetch the Nth function argument. (N &gt;= 1) (\\*1) $retval       : Fetch return value.(\\*2) $comm         : Fetch current task comm. +|-[u]OFFS(FETCHARG) : Fetch memory at FETCHARG +|- OFFS address.(\\*3)(\\*4) \\IMM          : Store an immediate value to the argument. NAME=FETCHARG : Set NAME as the argument name of FETCHARG. FETCHARG:TYPE : Set TYPE as the type of FETCHARG. Currently, basic types                 (u8/u16/u32/u64/s8/s16/s32/s64), hexadecimal types                 (x8/x16/x32/x64), \"string\", \"ustring\" and bitfield                 are supported. (\\*1) only for the probe on function entry (offs == 0). (\\*2) only for return probe. (\\*3) this is useful for fetching a field of data structures. (\\*4) \"u\" means user-space dereference. See :ref:`user_mem_access`.     echo 'p:myprobe follow_page_mask vma=%x0 address=%x1 flags=%x2 page_mask=%x3'&gt;&gt;kprobe_eventsecho 'r:myprobe_ret follow_page_mask ret=$retval '&gt;&gt;kprobe_events      echo 0 &gt; events/kprobes/enableecho &gt;kprobe_eventsecho 'r:__sys_accept4_ret __sys_accept4 ret=$retval:s32' &gt;&gt;kprobe_eventsecho 'p:__sys_accept4 __sys_accept4 fd=%x0'&gt;&gt;kprobe_eventsecho 'fd==0x9' &gt;&gt;events/kprobes/__sys_accept4/filterecho 1 &gt; events/kprobes/enable3 kernel modules kprobe内核模块通过kprobe实现函数注入#include &lt;linux/kernel.h&gt;#include &lt;linux/module.h&gt;#include &lt;linux/kprobes.h&gt;#define MAX_SYMBOL_LEN    64static char symbol[MAX_SYMBOL_LEN] = \"follow_page_mask\";module_param_string(symbol, symbol, sizeof(symbol), 0644);/* For each probe you need to allocate a kprobe structure */static struct kprobe kp = {    .symbol_name    = symbol,};/* kprobe pre_handler: called just before the probed instruction is executed */static int handler_pre(struct kprobe *p, struct pt_regs *regs){\treturn 0;}/* kprobe post_handler: called after the probed instruction is executed */static void handler_post(struct kprobe *p, struct pt_regs *regs,                unsigned long flags){\treturn;}/* * fault_handler: this is called if an exception is generated for any * instruction within the pre- or post-handler, or when Kprobes * single-steps the probed instruction. */static int handler_fault(struct kprobe *p, struct pt_regs *regs, int trapnr){    pr_info(\"fault_handler: p-&gt;addr = %pF, trap #%dn\", p-&gt;addr, trapnr);    /* Return 0 because we don't handle the fault. */    return 0;}static int __init kprobe_init(void){    int ret;    kp.pre_handler = handler_pre;    kp.post_handler = handler_post;    kp.fault_handler = handler_fault;    ret = register_kprobe(&amp;kp);    if (ret &lt; 0) {        pr_err(\"register_kprobe failed, returned %d\\n\", ret);        return ret;    }    pr_info(\"Planted kprobe at %pF\\n\", kp.addr);    return 0;}static void __exit kprobe_exit(void){    unregister_kprobe(&amp;kp);    pr_info(\"kprobe at %pF unregistered\\n\", kp.addr);}module_init(kprobe_init)module_exit(kprobe_exit)MODULE_LICENSE(\"GPL\");"
  },
  
  {
    "title": "The Kernel Concurrency Sanitizer (KCSAN)",
    "url": "/posts/linux-kcsan/",
    "categories": "linux, kcsan",
    "tags": "kcsan",
    "date": "2020-09-11 00:00:00 +0000",
    





    
    "snippet": "1 kcasan2 使用",
    "content": "1 kcasan2 使用"
  }
  
]

